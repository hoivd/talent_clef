{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import thư viện","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torchmetrics.retrieval import RetrievalMAP\nfrom datetime import datetime\nimport os\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport google.generativeai as genai\nimport os\nimport wandb\nimport ast\nimport subprocess\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:35:56.189473Z","iopub.execute_input":"2025-03-23T06:35:56.190753Z","iopub.status.idle":"2025-03-23T06:36:21.575808Z","shell.execute_reply.started":"2025-03-23T06:35:56.190709Z","shell.execute_reply":"2025-03-23T06:36:21.575137Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ngemini_api = user_secrets.get_secret(\"gemini_api\")\ngit_token = user_secrets.get_secret(\"git_token\")\nwandp_api = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:36:21.576903Z","iopub.execute_input":"2025-03-23T06:36:21.577134Z","iopub.status.idle":"2025-03-23T06:36:22.391804Z","shell.execute_reply.started":"2025-03-23T06:36:21.577114Z","shell.execute_reply":"2025-03-23T06:36:22.390911Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!git clone https://hoivd:{git_token}@github.com/hoivd/talent_clef\n\n# Đăng nhập W&B\nwandb.login(key=wandp_api)\n\n# Cấu hình API Key\ngenai.configure(api_key=gemini_api)  # Lấy từ biến môi trường\n\n# Khởi tạo model\nmodel_20 = genai.GenerativeModel(\"gemini-2.0-flash\")\n\n!git clone https://github.com/TalentCLEF/talentclef25_evaluation_script.git\n!pip install -r \"/kaggle/working/talentclef25_evaluation_script/requirements.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:36:22.393653Z","iopub.execute_input":"2025-03-23T06:36:22.393972Z","iopub.status.idle":"2025-03-23T06:37:00.778581Z","shell.execute_reply.started":"2025-03-23T06:36:22.393941Z","shell.execute_reply":"2025-03-23T06:37:00.777681Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'talent_clef'...\nremote: Enumerating objects: 255, done.\u001b[K\nremote: Counting objects: 100% (2/2), done.\u001b[K\nremote: Compressing objects: 100% (2/2), done.\u001b[K\nremote: Total 255 (delta 0), reused 0 (delta 0), pack-reused 253 (from 2)\u001b[K\nReceiving objects: 100% (255/255), 200.40 MiB | 19.08 MiB/s, done.\nResolving deltas: 100% (54/54), done.\nUpdating files: 100% (71/71), done.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoivinh20789\u001b[0m (\u001b[33mhoivinh20789-uit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Cloning into 'talentclef25_evaluation_script'...\nremote: Enumerating objects: 27, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nReceiving objects: 100% (27/27), 10.10 KiB | 10.10 MiB/s, done.\nremote: Total 27 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nResolving deltas: 100% (10/10), done.\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.2.3)\nCollecting ranx (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.60.0)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.67.1)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.13.1)\nCollecting ir-datasets (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (13.9.4)\nRequirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10.12)\nCollecting lz4 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting cbor2 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.2)\nCollecting fastparquet (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54.1->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.17.0)\nCollecting cramjam>=2.3 (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cramjam-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2024.12.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (24.2)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.3)\nCollecting inscriptis>=2.2.0 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (5.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (6.0.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.32.3)\nCollecting trec-car-tools>=2.5.4 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\nCollecting warc3-wet>=0.2.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\nCollecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting zlib-state>=0.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting ijson>=3.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting unlzw3>=0.2.1 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (19.0.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.19.1)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.2)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.7.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.6)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.1.31)\nCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor-1.0.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nDownloading ranx-0.3.20-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cramjam-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\nDownloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\nDownloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\nDownloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nBuilding wheels for collected packages: warc3-wet-clueweb09, cbor\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=dbf86e55a11a989a0f1fac913e4fed84cebbc6d9cc3f2733d717a312b47b4d1d\n  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53431 sha256=39f5d7b256bbfceb967f6e29b544b423942f19cd1c2f9207e16acf7ceaa5c3ec\n  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\nSuccessfully built warc3-wet-clueweb09 cbor\nInstalling collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, cramjam, cbor2, inscriptis, trec-car-tools, ir-datasets, fastparquet, ranx\nSuccessfully installed cbor-1.0.0 cbor2-5.6.5 cramjam-2.9.1 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.3 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Chuẩn bị dữ liệu","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"\nYou are a recruitment expert. Based on the following skill information:  \n- skillType: skill/competence  \n- reuseLevel: sector-specific  \n- preferredLabel: manage musical staff  \n- altLabels: manage staff of music\\ncoordinate duties of musical staff\\nmanage music staff\\ndirect musical staff\n- description: Assign and manage staff tasks in areas such as scoring, arranging, copying music and vocal coaching.  \nWrite a 50-word paragraph summarizing the information into a complete description. The paragraph must:  \n1) Highlight the skill type and industry-specific nature,  \n2) Emphasize the skill label and description,  \n3) Use concise, professional recruitment language, avoiding information beyond the provided data.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:00.780162Z","iopub.execute_input":"2025-03-23T06:37:00.781410Z","iopub.status.idle":"2025-03-23T06:37:00.785533Z","shell.execute_reply.started":"2025-03-23T06:37:00.781383Z","shell.execute_reply":"2025-03-23T06:37:00.784672Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"corpus_path = \"/kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements\"  # Thay thế bằng đường dẫn file của bạn\nqueries_path = \"/kaggle/working/talent_clef/data/TaskA/validation/english/queries\"\nqrels_path = \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\"\ntrain_path = \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"\n\ndf_corpus = pd.read_csv(corpus_path, sep='\\t', encoding='utf-8')\ndf_queries = pd.read_csv(queries_path, sep='\\t', encoding='utf-8')\ndf_qrels = pd.read_csv(qrels_path, sep='\\t', names = ['q_id', 'iter', 'c_id', 'relevance'], encoding='utf-8')\ndf_train = pd.read_csv(train_path, encoding='utf-8')\ndf_train['jobtitles'] = df_train['jobtitles'].apply(lambda x: ast.literal_eval(x))\nprint(df_corpus.head())\nprint(df_queries.head())\nprint(df_qrels.head())\nprint(df_train.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:00.786442Z","iopub.execute_input":"2025-03-23T06:37:00.786809Z","iopub.status.idle":"2025-03-23T06:37:01.725615Z","shell.execute_reply.started":"2025-03-23T06:37:00.786787Z","shell.execute_reply":"2025-03-23T06:37:01.724864Z"}},"outputs":[{"name":"stdout","text":"   c_id                          jobtitle\n0     1                recording engineer\n1     2              director of taxation\n2     3  technical support representative\n3     4                        hr manager\n4     5           computer graphic artist\n   q_id             jobtitle\n0     1                nanny\n1     2    food technologist\n2     3   broadcast engineer\n3     4  automation engineer\n4     5         veterinarian\n   q_id  iter  c_id  relevance\n0     1     0   143          1\n1     1     0   150          1\n2     1     0   764          1\n3     1     0   870          1\n4     1     0  1464          1\n   tid                                             skills  \\\n0    0  {'organise rehearsals': ['essential', 'This se...   \n1    1  {'non-ferrous metal processing': ['optional', ...   \n2    2  {'interpret circuit diagrams': ['optional', 'T...   \n3    3  {'design electrical systems': ['optional', 'A ...   \n4    4  {'property management software': ['essential',...   \n\n                                           jobtitles  \\\n0  [director of technical arts, technical supervi...   \n1  [draw machine operative, wiredrawing  machine ...   \n2  [precision device QC inspector, precision devi...   \n3  [air traffic safety technician, air traffic sa...   \n4  [yield manager, hospitality revenues manager, ...   \n\n                                          skills_gen  \n0  Overview: The essential skills for performing ...  \n1  Overview: The skills crucial for success encom...  \n2  Overview: The essential skills include quality...  \n3  Overview: The essential skills include aircraf...  \n4  Overview: The skills encompassed include prope...  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"cids = df_corpus['c_id'].tolist()\ncorpus = df_corpus['jobtitle'].tolist()\nqids = df_queries['q_id'].tolist()\nqueries = df_queries['jobtitle'].tolist()\njobtitles = df_train['jobtitles'].tolist()\nskills = df_train['skills_gen'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.726423Z","iopub.execute_input":"2025-03-23T06:37:01.726762Z","iopub.status.idle":"2025-03-23T06:37:01.730984Z","shell.execute_reply.started":"2025-03-23T06:37:01.726738Z","shell.execute_reply":"2025-03-23T06:37:01.730265Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"all_jobtitles = [title for sublist in df_train['jobtitles'] for title in sublist]\n\n# Lọc df1\ndf_queries_filterd = df_queries[df_queries['jobtitle'].isin(all_jobtitles)]\nprint(\"df_queries_filterd:\")\nprint(df_queries_filterd)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.731825Z","iopub.execute_input":"2025-03-23T06:37:01.732035Z","iopub.status.idle":"2025-03-23T06:37:01.763574Z","shell.execute_reply.started":"2025-03-23T06:37:01.732018Z","shell.execute_reply":"2025-03-23T06:37:01.762751Z"}},"outputs":[{"name":"stdout","text":"df_queries_filterd:\n     q_id             jobtitle\n0       1                nanny\n1       2    food technologist\n2       3   broadcast engineer\n3       4  automation engineer\n6       7        acupuncturist\n..    ...                  ...\n98     99               dancer\n99    100          dog groomer\n102   103           agronomist\n103   104  biomedical engineer\n104   105            publisher\n\n[66 rows x 2 columns]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"filtered_jobtitles = df_queries_filterd['jobtitle'].tolist()\n\n# Lọc df2: kiểm tra xem jobtitles có giao với filtered_jobtitles không\ndf_train_filtered = df_train[df_train['jobtitles'].apply(lambda x: any(title in filtered_jobtitles for title in x))]\nprint(\"df_train_filtered:\")\nprint(df_train_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.766106Z","iopub.execute_input":"2025-03-23T06:37:01.766304Z","iopub.status.idle":"2025-03-23T06:37:01.803174Z","shell.execute_reply.started":"2025-03-23T06:37:01.766287Z","shell.execute_reply":"2025-03-23T06:37:01.802500Z"}},"outputs":[{"name":"stdout","text":"df_train_filtered:\n       tid                                             skills  \\\n29      29  {'draft scientific or academic papers and tech...   \n43      43  {'Haskell': ['optional', 'Haskell expertise, a...   \n85      85  {'advise on construction materials': ['optiona...   \n103    103  {'understand the architecture of a live perfor...   \n131    131  {'workplace sanitation': ['essential', 'This c...   \n...    ...                                                ...   \n2728  2728  {'medico-biological and medical sciences relat...   \n2811  2811  {'replace faucets': ['essential', 'This sector...   \n2907  2907  {'prepare exercise session': ['essential', 'Th...   \n2955  2955  {'create collection conservation plan': ['esse...   \n2981  2981  {'communicate with customers': ['optional', 'T...   \n\n                                              jobtitles  \\\n29    [BME adviser, BME specialist, biomedical engin...   \n43    [telecommunications engineers, communications ...   \n85    [metallurgy test technician, metallurgy resear...   \n103   [dancer & singer, singer and dancer, ballet an...   \n131   [nanny, mother's helper, live-in baby sitter, ...   \n...                                                 ...   \n2728  [community dentist, associate dental practitio...   \n2811  [plumber, plumbeer, plummer, pipeworker, gas f...   \n2907  [personal fitness trainer, personal coach, wel...   \n2955  [archivist and records manager, cultural archi...   \n2981  [analog design engineer, integrated circuit en...   \n\n                                             skills_gen  \n29    Overview: This document outlines a range of sk...  \n43    Overview: The essential skills required encomp...  \n85    Overview: The skills essential for success inc...  \n103   Overview: The landscape of performing arts ski...  \n131   Overview: The diverse skill set includes workp...  \n...                                                 ...  \n2728  Overview: The essential skills encompass medic...  \n2811  Overview: The essential skills include replace...  \n2907  Overview: The fitness domain encompasses a wid...  \n2955  Overview: The essential skills for success inc...  \n2981  Overview: The essential skills include communi...  \n\n[77 rows x 4 columns]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"df_queries_filterd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.804435Z","iopub.execute_input":"2025-03-23T06:37:01.804653Z","iopub.status.idle":"2025-03-23T06:37:01.820245Z","shell.execute_reply.started":"2025-03-23T06:37:01.804619Z","shell.execute_reply":"2025-03-23T06:37:01.819560Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"     q_id             jobtitle\n0       1                nanny\n1       2    food technologist\n2       3   broadcast engineer\n3       4  automation engineer\n6       7        acupuncturist\n..    ...                  ...\n98     99               dancer\n99    100          dog groomer\n102   103           agronomist\n103   104  biomedical engineer\n104   105            publisher\n\n[66 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q_id</th>\n      <th>jobtitle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>nanny</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>food technologist</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>broadcast engineer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>automation engineer</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>acupuncturist</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>99</td>\n      <td>dancer</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>100</td>\n      <td>dog groomer</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>103</td>\n      <td>agronomist</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>104</td>\n      <td>biomedical engineer</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>105</td>\n      <td>publisher</td>\n    </tr>\n  </tbody>\n</table>\n<p>66 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df_train_expand = df_train_filtered.explode('jobtitles').rename(columns={'jobtitles': 'jobtitle'})\n\n# Bước 4: Ghép df1_filtered với df2_expanded dựa trên jobtitle\nresult = pd.merge(df_queries_filterd, df_train_expand, on='jobtitle', how='inner')\n\n# In kết quả\nprint(\"Kết quả ghép:\")\nresult.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-23T06:37:01.820960Z","iopub.execute_input":"2025-03-23T06:37:01.821207Z","iopub.status.idle":"2025-03-23T06:37:01.848553Z","shell.execute_reply.started":"2025-03-23T06:37:01.821187Z","shell.execute_reply":"2025-03-23T06:37:01.847793Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Kết quả ghép:\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   q_id             jobtitle   tid  \\\n0     1                nanny   131   \n1     2    food technologist   929   \n2     3   broadcast engineer    43   \n3     4  automation engineer  2264   \n4     7        acupuncturist   577   \n\n                                              skills  \\\n0  {'workplace sanitation': ['essential', 'This c...   \n1  {'keep food laboratory inventory': ['optional'...   \n2  {'Haskell': ['optional', 'Haskell expertise, a...   \n3  {'draft scientific or academic papers and tech...   \n4  {'select acupuncture points': ['essential', 'T...   \n\n                                          skills_gen  \n0  Overview: The diverse skill set includes workp...  \n1  Overview: The essential skills include leading...  \n2  Overview: The essential skills required encomp...  \n3  Overview: The skills encompass a broad range f...  \n4  Overview: The diverse skillset includes essent...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q_id</th>\n      <th>jobtitle</th>\n      <th>tid</th>\n      <th>skills</th>\n      <th>skills_gen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>nanny</td>\n      <td>131</td>\n      <td>{'workplace sanitation': ['essential', 'This c...</td>\n      <td>Overview: The diverse skill set includes workp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>food technologist</td>\n      <td>929</td>\n      <td>{'keep food laboratory inventory': ['optional'...</td>\n      <td>Overview: The essential skills include leading...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>broadcast engineer</td>\n      <td>43</td>\n      <td>{'Haskell': ['optional', 'Haskell expertise, a...</td>\n      <td>Overview: The essential skills required encomp...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>automation engineer</td>\n      <td>2264</td>\n      <td>{'draft scientific or academic papers and tech...</td>\n      <td>Overview: The skills encompass a broad range f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>acupuncturist</td>\n      <td>577</td>\n      <td>{'select acupuncture points': ['essential', 'T...</td>\n      <td>Overview: The diverse skillset includes essent...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"result = result[['q_id', 'jobtitle', 'skills_gen']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.849428Z","iopub.execute_input":"2025-03-23T06:37:01.849706Z","iopub.status.idle":"2025-03-23T06:37:01.853586Z","shell.execute_reply.started":"2025-03-23T06:37:01.849666Z","shell.execute_reply":"2025-03-23T06:37:01.852837Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"result.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.854448Z","iopub.execute_input":"2025-03-23T06:37:01.854760Z","iopub.status.idle":"2025-03-23T06:37:01.872359Z","shell.execute_reply.started":"2025-03-23T06:37:01.854733Z","shell.execute_reply":"2025-03-23T06:37:01.871559Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(80, 3)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def gop_cid(group):\n    relevane_cids =  set(group['c_id'].tolist())\n    un_relevance_cids = set(cids) - relevane_cids\n    return list(un_relevance_cids)\nunrelevance_df = df_qrels.groupby('q_id').apply(gop_cid).reset_index(name=\"un_relate_cids\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.873176Z","iopub.execute_input":"2025-03-23T06:37:01.873406Z","iopub.status.idle":"2025-03-23T06:37:01.903416Z","shell.execute_reply.started":"2025-03-23T06:37:01.873379Z","shell.execute_reply":"2025-03-23T06:37:01.902591Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-13-4cf5f0d997bc>:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  unrelevance_df = df_qrels.groupby('q_id').apply(gop_cid).reset_index(name=\"un_relate_cids\")\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"unrelevance_df ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.904163Z","iopub.execute_input":"2025-03-23T06:37:01.904408Z","iopub.status.idle":"2025-03-23T06:37:01.917697Z","shell.execute_reply.started":"2025-03-23T06:37:01.904390Z","shell.execute_reply":"2025-03-23T06:37:01.917079Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"     q_id                                     un_relate_cids\n0       1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n1       2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n2       3  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n3       4  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n4       5  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n..    ...                                                ...\n100   101  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n101   102  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n102   103  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n103   104  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n104   105  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n\n[105 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q_id</th>\n      <th>un_relate_cids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>101</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>102</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>103</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>104</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>105</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n    </tr>\n  </tbody>\n</table>\n<p>105 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"unrelevance_df = pd.merge(unrelevance_df, result, on='q_id', how='inner')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.918471Z","iopub.execute_input":"2025-03-23T06:37:01.918781Z","iopub.status.idle":"2025-03-23T06:37:01.932904Z","shell.execute_reply.started":"2025-03-23T06:37:01.918747Z","shell.execute_reply":"2025-03-23T06:37:01.932223Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"unrelevance_df['unrelated_jobtitles'] = unrelevance_df[\"un_relate_cids\"].apply(lambda x: [corpus[cid - 1] for cid in x])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.933628Z","iopub.execute_input":"2025-03-23T06:37:01.933945Z","iopub.status.idle":"2025-03-23T06:37:01.963160Z","shell.execute_reply.started":"2025-03-23T06:37:01.933882Z","shell.execute_reply":"2025-03-23T06:37:01.962504Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"unrelated_jobtitles = unrelevance_df['unrelated_jobtitles'].tolist()\nunrelate_skills = unrelevance_df['skills_gen'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.963930Z","iopub.execute_input":"2025-03-23T06:37:01.964175Z","iopub.status.idle":"2025-03-23T06:37:01.974894Z","shell.execute_reply.started":"2025-03-23T06:37:01.964147Z","shell.execute_reply":"2025-03-23T06:37:01.974121Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Chuẩn bị mô hình","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import InputExample\n\ntrain_examples = []\n\nfor idx, lst_jobtitles in enumerate(unrelated_jobtitles):\n    for jobtitle in lst_jobtitles:\n        train_examples.append(\n            InputExample(texts=[jobtitle, unrelate_skills[idx]], label=0) \n        )\n\n\nfor idx, lst_jobtitles in enumerate(jobtitles):\n    for jobtitle in lst_jobtitles:\n        train_examples.append(\n            InputExample(texts=[jobtitle, skills[idx]], label=1.0) \n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:01.975748Z","iopub.execute_input":"2025-03-23T06:37:01.976025Z","iopub.status.idle":"2025-03-23T06:37:03.068797Z","shell.execute_reply.started":"2025-03-23T06:37:01.975995Z","shell.execute_reply":"2025-03-23T06:37:03.068084Z"},"_kg_hide-output":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"loss_function = \"\"\nnum_epochs = \"\"\nmodel_name = \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:03.069514Z","iopub.execute_input":"2025-03-23T06:37:03.069735Z","iopub.status.idle":"2025-03-23T06:37:03.073456Z","shell.execute_reply.started":"2025-03-23T06:37:03.069717Z","shell.execute_reply":"2025-03-23T06:37:03.072518Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device sử dụng:\", device)\n\n# Tải mô hình\nmodel_name = 'sentence-transformers/all-MiniLM-L6-v2'\nmodel = SentenceTransformer(model_name, device=device)\n\n\n# Khởi tạo hàm mất mát\ntrain_loss = losses.MultipleNegativesRankingLoss(model)\nloss_function = \"MultipleNegativesRankingLoss\"\n# Tính tổng số batch\ntotal_batches = len(train_dataloader)  # 2000 mẫu / 16 = 125 batch\n\nnum_epochs = 3\noutput_path = f\"/kaggle/working/talent_clef/model/{model_name}/epoch_{num_epochs}\"\n\n# Tạo thư mục nếu chưa có\nos.makedirs(output_path, exist_ok=True)\n\n# Huấn luyện với callback\nmodel.fit(\n    train_objectives=[(train_dataloader, train_loss)],\n    epochs=num_epochs,\n    warmup_steps=100,\n    output_path=output_path,\n    show_progress_bar=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:37:03.074276Z","iopub.execute_input":"2025-03-23T06:37:03.074539Z"}},"outputs":[{"name":"stdout","text":"Device sử dụng: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b3eecf7790248cb99e4c0bbbdab8153"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f92ac5995b34f3ca2a3f5df221147c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c74350771d4750abfe248cba94e905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afaf9edcddc04230966efd256f830b2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb1962a4d2f4e9d9e1e867fe07c3ef7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b43ede4f044faabc0487c57a61e661"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b181d919e3344a99ba542f0c6fe0eebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b4ee298f54429fac0944a0c6fa5da3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff7f4833b9e0405988cd5518f4e13702"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9757905d3d24e75a12695302e7115a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b503c92fbc2b4fa59747c555ff4184e1"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# import zipfile\n# output_path = \"/kaggle/working/agne/jobBERT-de\"\n# zip_path = \"/kaggle/working/agne/jobBERT-de.zip\"\n# with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, _, files in os.walk(output_path):\n#         for file in files:\n#             file_path = os.path.join(root, file)\n#             # Đặt tên file trong ZIP không bao gồm đường dẫn gốc\n#             zipf.write(file_path, os.path.relpath(file_path, output_path))\n\n# print(f\"Mô hình đã được huấn luyện và lưu vào: {output_path}\")\n# print(f\"Thư mục đã được nén thành: {zip_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corpus_embeddings = model.encode(corpus)\nquery_embeddings = model.encode(queries)\n\ncorpus_embeddings = torch.tensor(corpus_embeddings)\nquery_embeddings = torch.tensor(query_embeddings)\n\nground_truths = dict()\nfor qid in qids:\n    ground_truths[qid] = df_qrels[(df_qrels['q_id']) == 1 & (df_qrels['relevance'] == 1)]['c_id'].tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"language = 'en-en'\n\nclass SimilarityModel(nn.Module):\n    def __init__(self, corpus_embeddings, corpus_cids):\n        super(SimilarityModel, self).__init__()\n        self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n        self.corpus_cids = corpus_cids              # List of CIDs\n\n    def forward(self, question_embedding):\n        # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n        question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n        \n        # Compute cosine similarity\n        similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n        \n        # Get the top_n indices with the highest cosine similarity values\n        sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n        \n        \n        # Return top_n_ids, sorted similarities, and sorted indices\n        return sorted_similarities, sorted_indices\n        \n# Example device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n# Initialize the similarity model\ncorpus_embeddings = corpus_embeddings.to(device)\n\nsimilarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\nif torch.cuda.device_count() > 1:\n    similarity_model = nn.DataParallel(similarity_model)\n\n\n# Tạo thư mục (bao gồm cả thư mục con nếu cần)\nfolder_name = f\"/kaggle/working/talent_clef/predict/{model_name}/{datetime.now().strftime('%d-%m-%Y_%H.%M.%S')}\"\nos.makedirs(folder_name, exist_ok=True)\n\nfile_path = f\"{folder_name}/run_{language}.trec\"\n\nwith open(file_path, \"w\", encoding=\"utf-8\") as f:\n    for qid, query_embedding in enumerate(query_embeddings):\n        # Convert question_embedding to tensor and move to the device\n        query_embedding = query_embedding.to(device)\n        \n        # Get the top_n most relevant CIDs\n        sorted_similarities, sorted_indices = similarity_model(query_embedding)\n        results = []\n        for idx in range(len(sorted_similarities)):\n            doc_id = sorted_indices[idx]\n            score = sorted_similarities[idx]\n            rank = idx\n            results.append(f\"{qid + 1} Q0 {doc_id + 1} {rank+1} {score:.4f} 4Huiter\")\n\n        f.write(\"\\n\".join(results) + \"\\n\")   \n\nqrels_file = \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\"\nrun_file = file_path\n\ncommand = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_file, \"--run\", run_file]\nresult = subprocess.run(command, capture_output=True, text=True)\nprint(result.stdout)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_metrics(result, language=\"en-en\"):\n    stdout = result.stdout\n    map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n    mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n    ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n    precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n    precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n    precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n\n    metrics = {}\n    metrics[language] = {\n        \"map\": map_value,\n        \"mrr\": mrr,\n        \"ndcg\": ndcg,\n        \"precision@5\": precision_5,\n        \"precision@10\": precision_10,\n        \"precision@100\": precision_100\n    }\n    return metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = extract_metrics(result, language)\nprint(metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Lưu thông tin mô hình","metadata":{}},{"cell_type":"markdown","source":"## Nhập thông tin mô hình","metadata":{}},{"cell_type":"code","source":"model_name = model_name\nloss = loss_function\nmap_values = [lang['map'] for lang in metrics.values()]\naverage_map = sum(map_values) / len(map_values)\nepochs = num_epochs\ntraining_time = None\nnotes = \"Test\"\n\n# Tạo dữ liệu mới\ndata = {\n    \"model_name\": [model_name],\n    \"Avg result\": [average_map],\n    \"en-en result\": [metrics.get(\"en-en\", \"\")],\n    \"es-es result\": [metrics.get(\"es-es\", \"\")],\n    \"de-de result\": [metrics.get(\"de-de\", \"\")],\n    \"zh-zh result\": [metrics.get(\"zh-zh\", \"\")],\n    \"en-es result\": [metrics.get(\"en-es\", \"\")],\n    \"en-de result\": [metrics.get(\"en-de\", \"\")],\n    \"en-zh result\": [metrics.get(\"en-zh\", \"\")],\n    \"loss\": [loss],\n    \"epochs\": [epochs],\n    \"training_time (s)\": [training_time],\n    \"date\": [datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")],\n    \"notes\": [notes]\n}\n\nprint(data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo DataFrame từ dữ liệu mới\ndf_new = pd.DataFrame(data)\n\n# Định nghĩa thư mục và đường dẫn file\nfolder_name = \"/kaggle/working/talent_clef/results\"\nfile_name = \"model_info.csv\"\nfile_path = os.path.join(folder_name, file_name)\n\n# Tạo thư mục nếu chưa có\nos.makedirs(folder_name, exist_ok=True)\n\n# Kiểm tra xem file đã tồn tại chưa\nif os.path.exists(file_path):\n    # Đọc file cũ\n    df_existing = pd.read_csv(file_path)\n    # Thêm dữ liệu mới vào file cũ\n    df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n    # Lưu lại file\n    df_updated.to_csv(file_path, index=False)\n    print(f\"Đã thêm dữ liệu vào file: {file_path}\")\nelse:\n    # Nếu file chưa tồn tại, tạo file mới\n    df_new.to_csv(file_path, index=False)\n    print(f\"Đã tạo file mới: {file_path}\")\n\n# Kiểm tra nội dung file (trên Kaggle)\n!cat {file_path}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Lưu thông tin trên GitHub","metadata":{}},{"cell_type":"code","source":"cd talent_clef","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git config --global user.email \"hoivd79@gmail.com\"\n!git config --global user.name \"Dang Vinh Hoi\"\n!git status\n!git add .\n!git commit -m \"updated\"\n!git push","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd ..","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}