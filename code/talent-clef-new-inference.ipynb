{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torchmetrics.retrieval import RetrievalMAP\nimport os\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport google.generativeai as genai\nimport os\nimport wandb\nimport ast\nimport subprocess\nimport pickle\nimport shutil\nimport datetime\nimport pytz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:09.315839Z","iopub.execute_input":"2025-04-19T14:46:09.316520Z","iopub.status.idle":"2025-04-19T14:46:39.770669Z","shell.execute_reply.started":"2025-04-19T14:46:09.316493Z","shell.execute_reply":"2025-04-19T14:46:39.770164Z"}},"outputs":[{"name":"stderr","text":"2025-04-19 14:46:22.430581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745073982.641963      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745073982.695387      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# PositiveExampleMining","metadata":{}},{"cell_type":"code","source":"class MiningPosExample:\n    def __init__(self):\n        self.data = None  # Khá»Ÿi táº¡o thuá»™c tÃ­nh self.data lÃ  None\n\n     # PhÆ°Æ¡ng thá»©c __len__ Ä‘á»ƒ tráº£ vá» sá»‘ dÃ²ng cá»§a data\n    def __len__(self):\n        if self.data is not None:\n            return len(self.data)\n        return 0  # Náº¿u self.data chÆ°a Ä‘Æ°á»£c gÃ¡n (None), tráº£ vá» 0\n    \n    # PhÆ°Æ¡ng thá»©c __getitem__ Ä‘á»ƒ truy xuáº¥t má»™t dÃ²ng trong data theo chá»‰ sá»‘\n    def __getitem__(self, index):\n        if self.data is not None:\n            return self.data.iloc[index]\n        raise IndexError(\"Index out of range\")  # Náº¿u self.data lÃ  None, raise lá»—i\n        \n    def mining_pos_example(self, data_file):\n        # Äá»c dá»¯ liá»‡u tá»« file (giáº£ sá»­ lÃ  file CSV)\n        df = pd.read_csv(data_file)\n        df['jobtitles'] = df['jobtitles'].apply(ast.literal_eval)\n        # Láº¥y cÃ¡c cá»™t 'jobtitles' vÃ  'skills_gen', sau Ä‘Ã³ \"phÃ¢n ná»•\" danh sÃ¡ch trong cá»™t 'jobtitles'\n        new_df = df[['jobtitles', 'skills_gen']].explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n        \n        # ThÃªm cá»™t 'label' vá»›i giÃ¡ trá»‹ toÃ n bá»™ lÃ  1\n        new_df['label'] = 1\n        \n        # LÆ°u káº¿t quáº£ vÃ o self.data\n        self.data = new_df\n        \n        return new_df\n\n    def get_data(self):\n        return self.data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.771988Z","iopub.execute_input":"2025-04-19T14:46:39.772248Z","iopub.status.idle":"2025-04-19T14:46:39.778129Z","shell.execute_reply.started":"2025-04-19T14:46:39.772225Z","shell.execute_reply":"2025-04-19T14:46:39.777406Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# DataPrepare","metadata":{}},{"cell_type":"code","source":"class DataPreparer:\n    def prepare_train_data(self, train_data_org_file):\n        print(\"Äá»c dá»¯ liá»‡u train_org:\")\n        \n        pos_miner = MiningPosExample()\n        pos_example_df = pos_miner.mining_pos_example(train_data_org_file)\n        print(pos_example_df.head())\n\n        train_df = pos_example_df\n        print(f\"Cá»™t dá»¯ liá»‡u: {train_df.columns}\")\n        print(\"Xuáº¥t dá»¯ liá»‡u train sau khi chuáº©n bá»‹:\")\n        train_file = \"/kaggle/working/train.csv\"\n        utils.write_csv(train_df, train_file)\n        return train_df, train_file\n\n    def prepare_inference_data(self, corpus_path, queries_path, lang):\n        print(\"Äá»c dá»¯ liá»‡u inference:\")\n        corpus_df = utils.read_tsv(corpus_path)\n        queries_df = utils.read_tsv(queries_path)\n        \n        print(\"Xuáº¥t dá»¯ liá»‡u inference:\")\n        corpus_out_path = f\"/kaggle/working/corpus_{lang}.csv\"\n        queries_out_path = f\"/kaggle/working/queries_{lang}.csv\"\n        utils.write_csv(corpus_df, corpus_out_path)\n        utils.write_csv(queries_df, queries_out_path)\n        return corpus_out_path, queries_out_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.778882Z","iopub.execute_input":"2025-04-19T14:46:39.779134Z","iopub.status.idle":"2025-04-19T14:46:39.793548Z","shell.execute_reply.started":"2025-04-19T14:46:39.779118Z","shell.execute_reply":"2025-04-19T14:46:39.792865Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Dataset():\n    def __init__(self, data):\n        self.data = []\n        for jobtitle, skill, label in data:\n            self.data.append(InputExample(texts = [jobtitle, skill], label=label))\n\n    def __len__(self) -> int:\n        \"\"\"Tráº£ vá» sá»‘ lÆ°á»£ng máº«u trong dataset.\"\"\"\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n    @staticmethod\n    def load_train_data(train_path):\n        train_df = utils.read_csv(train_path)\n        jobtitles =  train_df['jobtitle'].tolist()\n        skills =  train_df['skill'].tolist()\n        labels = train_df['label'].tolist()\n\n        data = []\n        for idx, jobtitle in enumerate(jobtitles):\n            data.append((jobtitle, skills[idx], labels[idx]))\n        return data\n        \n    @staticmethod  \n    def load_inference_data(corpus_path, queries_path):\n        corpus_df = utils.read_csv(corpus_path)\n        queries_df = utils.read_csv(queries_path)\n        \n        cids_l = corpus_df['c_id'].tolist()\n        corpus_l = corpus_df['jobtitle'].tolist()\n        qids_l = queries_df['q_id'].tolist()\n        queries_l = queries_df['jobtitle'].tolist()\n\n        corpus = {\"cid\": cids_l,\n                \"jobtitle\": corpus_l\n                }\n\n        queries = {\"qid\": qids_l,\n                \"jobtitle\": queries_l\n                }\n        return corpus, queries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.795275Z","iopub.execute_input":"2025-04-19T14:46:39.795513Z","iopub.status.idle":"2025-04-19T14:46:39.812206Z","shell.execute_reply.started":"2025-04-19T14:46:39.795497Z","shell.execute_reply":"2025-04-19T14:46:39.811568Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# BiEncoder","metadata":{}},{"cell_type":"code","source":"class BiEncoder:\n    def __init__(self, model_name=None, model_path=None):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(\"Device sá»­ dá»¥ng:\", device)\n        \n        try:\n            if model_path is None:\n                print(f\"Táº£i mÃ´ hÃ¬nh tá»« Hugging Face vá»›i tÃªn: {model_name}\")\n                self.model = SentenceTransformer(model_name)\n            else:\n                print(f\"Táº£i mÃ´ hÃ¬nh tá»« Ä‘Æ°á»ng dáº«n cá»¥c bá»™: {model_path}\")\n                self.model = SentenceTransformer(model_path)\n            \n            # Äáº·t mÃ´ hÃ¬nh lÃªn thiáº¿t bá»‹\n            self.model = self.model.to(device)\n            print(\"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\")\n        \n        except Exception as e:\n            print(f\"Lá»—i khi khá»Ÿi táº¡o mÃ´ hÃ¬nh: {e}\")\n            raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.812985Z","iopub.execute_input":"2025-04-19T14:46:39.813257Z","iopub.status.idle":"2025-04-19T14:46:39.830018Z","shell.execute_reply.started":"2025-04-19T14:46:39.813232Z","shell.execute_reply":"2025-04-19T14:46:39.829319Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# BiTrainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model_name, model_path=None):\n        self.bi_encoder = BiEncoder(model_name, model_path)\n\n    def train(self, dataset, loss, params):\n        print(\"Khá»Ÿi táº¡o dataset:\")\n        train_dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n\n        print(\"Báº¯t Ä‘áº§u train: \")\n\n         # Khá»Ÿi táº¡o hÃ m máº¥t mÃ¡t\n        train_loss = loss(self.bi_encoder.model)\n        \n        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³\n        os.makedirs(params['output_path'], exist_ok=True)\n        \n        # Huáº¥n luyá»‡n vá»›i callback\n        self.bi_encoder.model.fit(\n            train_objectives=[(train_dataloader, train_loss)],\n            epochs=params['num_epochs'],\n            warmup_steps=params['warmup_steps'],\n            output_path=params[\"output_path\"],\n            show_progress_bar=True\n        )\n\n        return self.bi_encoder.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.830785Z","iopub.execute_input":"2025-04-19T14:46:39.831012Z","iopub.status.idle":"2025-04-19T14:46:39.847484Z","shell.execute_reply.started":"2025-04-19T14:46:39.830997Z","shell.execute_reply":"2025-04-19T14:46:39.846919Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"class Inference:\n    def __init__(self, model):\n        self.model = model\n\n    def embed(self, texts):\n        print(\"Báº¯t Ä‘áº§u cháº¡y embeddings...\")\n        texts_embedding = self.model.encode(texts)\n        texts_embedding = torch.tensor(texts_embedding)\n\n        return texts_embedding\n\n    def infer(self, corpus, queries):    \n        class SimilarityModel(nn.Module):\n            def __init__(self, corpus_embeddings, corpus_cids):\n                super(SimilarityModel, self).__init__()\n                self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n                self.corpus_cids = corpus_cids              # List of CIDs\n        \n            def forward(self, question_embedding):\n                # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n                question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n                \n                # Compute cosine similarity\n                similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n                similarities[similarities == 1] = float('-inf')\n\n                # Get the top_n indices with the highest cosine similarity values\n                sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n                \n                \n                # Return top_n_ids, sorted similarities, and sorted indices\n                return sorted_similarities, sorted_indices\n                \n        # Example device setup\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n\n        # Initialize the similarity model\n        corpus_embeddings = corpus[\"embedding\"].to(device)\n        cids = corpus['cid']\n\n        query_embeddings = queries['embedding'].to(device)\n        qids = queries['qid']\n        \n        similarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\n        if torch.cuda.device_count() > 1:\n            similarity_model = nn.DataParallel(similarity_model)\n\n        self.predictions = []\n        for qid, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"Processing queries\"):\n            # Convert question_embedding to tensor and move to the device\n            query_embedding = query_embedding.to(device)\n            \n            # Get the top_n most relevant CIDs\n            sorted_similarities, sorted_indices = similarity_model(query_embedding)\n            results = []\n            for idx in range(len(sorted_similarities)):\n                doc_id = sorted_indices[idx].item()\n                score = sorted_similarities[idx].item()\n                rank = idx\n                row = (qid + 1, \"Q0\", doc_id + 1, rank + 1, score, \"4Huiter\")\n                results.append(row)\n            self.predictions.append(results)\n        return self.predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.848210Z","iopub.execute_input":"2025-04-19T14:46:39.848495Z","iopub.status.idle":"2025-04-19T14:46:39.866482Z","shell.execute_reply.started":"2025-04-19T14:46:39.848478Z","shell.execute_reply":"2025-04-19T14:46:39.865962Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# RetrievalApp","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\nfrom datetime import datetime\n\nclass RetrievalApp:\n    def __init__(self, model_name, model_path=None):\n        self.model = BiEncoder(model_name, model_path).model\n        print(\"Load mÃ´ hÃ¬nh.....\")\n        self.model_name = model_name\n        self.model_path = model_path\n    \n    def prepare_data(self, data_file):\n        \"\"\"\n        Chuáº©n bá»‹ dá»¯ liá»‡u: chuáº©n bá»‹ cÃ¡c corpus vÃ  queries cho tá»«ng ngÃ´n ngá»¯.\n        \"\"\"\n        print(\"Chuáº©n bá»‹ data: ......\")\n        preparer = DataPreparer()\n        corpus_file = dict()\n        queries_file = dict()\n        langs = list(data_file['corpus'].keys())\n        \n        for lang in langs:\n            print(f\"Chuáº©n bá»‹ data {lang}:.....\")\n            corpus_file_org = data_file['corpus'][lang]\n            queries_file_org = data_file['queries'][lang]\n            corpus_file[lang], queries_file[lang] = preparer.prepare_inference_data(corpus_file_org, queries_file_org, lang)\n        \n        return langs, corpus_file, queries_file\n\n    def inference(self, langs, corpus_file, queries_file):\n        \"\"\"\n        Thá»±c hiá»‡n inference cho tá»«ng ngÃ´n ngá»¯.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u inference.....\")\n        corpus, queries = dict(), dict()\n        for lang in langs:\n            print(f\"Load data {lang}:.....\")\n            corpus_file_cur = corpus_file[lang]\n            queries_file_cur = queries_file[lang]\n            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n\n        inferencer = Inference(self.model)\n        for lang in langs:\n            print(f\"Inference {lang}:.....\")\n            corpus_cur, queries_cur = corpus[lang], queries[lang]\n            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n\n        return corpus, queries, inferencer\n\n    def predict(self, langs, corpus, queries, inferencer):\n        \"\"\"\n        Thá»±c hiá»‡n dá»± Ä‘oÃ¡n.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n:.....\")\n        predictions = dict()\n        for lang in langs:\n            print(f\"Dá»± Ä‘oÃ¡n {lang}:.....\")\n            corpus_cur, queries_cur = corpus[lang], queries[lang] \n            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n\n        return predictions\n\n    def zip_directory(self, zip_filename, dir_name):\n        \"\"\"\n        NÃ©n thÆ° má»¥c thÃ nh file zip mÃ  khÃ´ng sá»­ dá»¥ng Ä‘a luá»“ng.\n        \"\"\"\n        print(f\"Äang nÃ©n thÆ° má»¥c {dir_name} thÃ nh {zip_filename}...\")\n        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            # Duyá»‡t qua táº¥t cáº£ cÃ¡c file trong thÆ° má»¥c vÃ  nÃ©n chÃºng tuáº§n tá»±\n            for root, dirs, files in os.walk(dir_name):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, dir_name)  # LÆ°u láº¡i cáº¥u trÃºc thÆ° má»¥c gá»‘c\n                    zipf.write(file_path, arcname)\n\n        print(f\"File zip Ä‘Ã£ Ä‘Æ°á»£c táº¡o: {zip_filename}\")\n\n    def save_predictions(self, langs, predictions):\n        \"\"\"\n        LÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ o file vÃ  nÃ©n thÆ° má»¥c.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u xuáº¥t file:....\")\n        predictions_file = dict()\n        folder_name = f\"/kaggle/working/talent_clef/predict/{self.model_name}/{Timer.get()}\"\n        os.makedirs(folder_name, exist_ok=True)\n        for lang in langs:\n            predictions_file[lang] = utils.write_predictions(predictions[lang], folder_name, lang)\n        \n        # NÃ©n thÆ° má»¥c sau khi xuáº¥t file\n        zip_filename = folder_name + \".zip\"\n        self.zip_directory(zip_filename, folder_name)\n        \n        return predictions_file, zip_filename\n\n    def evaluate(self, langs, predictions_file, data):\n        \"\"\"\n        ÄÃ¡nh giÃ¡ káº¿t quáº£ dá»± Ä‘oÃ¡n.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡:.....\")\n        ratings = dict()\n        for lang in langs:\n            print(f\"ÄÃ¡nh giÃ¡ {lang}:.....\")\n            run_file, qrels_file = predictions_file[lang], data['qrels'][lang]\n            ratings[lang] = Evaluate.evaluate(run_file, qrels_file)\n        return ratings\n\n    def __call__(self, data_file):\n        \"\"\"\n        Ná»‘i cÃ¡c hÃ m láº¡i vá»›i nhau vÃ  cháº¡y toÃ n bá»™ quy trÃ¬nh.\n        \"\"\"\n        langs, corpus_file, queries_file = self.prepare_data(data_file)\n        corpus, queries, inferencer = self.inference(langs, corpus_file, queries_file)\n        predictions = self.predict(langs, corpus, queries, inferencer)\n        predictions_file, zip_filename = self.save_predictions(langs, predictions)\n        ratings = self.evaluate(langs, predictions_file, data_file)\n        return ratings, predictions_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:48:50.553596Z","iopub.execute_input":"2025-04-19T14:48:50.554088Z","iopub.status.idle":"2025-04-19T14:48:50.567134Z","shell.execute_reply.started":"2025-04-19T14:48:50.554065Z","shell.execute_reply":"2025-04-19T14:48:50.566464Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\ndef load_git_workspace_wandb():\n    user_secrets = UserSecretsClient()\n    git_token = user_secrets.get_secret(\"github\")\n    wandp_api = user_secrets.get_secret(\"wandb\")\n\n    import subprocess\n\n    # Thay {git_token} báº±ng token thá»±c táº¿ cá»§a báº¡n\n    repo_url = f\"https://hoivd:{git_token}@github.com/hoivd/talent_clef\"\n    \n    # Lá»‡nh git clone\n    command = [\"git\", \"clone\", repo_url]\n    \n    try:\n        # Cháº¡y lá»‡nh vÃ  Ä‘á»£i hoÃ n táº¥t\n        result = subprocess.run(command, check=True, text=True, capture_output=True)\n        print(\"Clone thÃ nh cÃ´ng!\")\n        print(\"Stdout:\", result.stdout)  # In stdout náº¿u cÃ³\n        print(\"Stderr:\", result.stderr)  # In stderr Ä‘á»ƒ tháº¥y tiáº¿n trÃ¬nh\n    except subprocess.CalledProcessError as e:\n        print(\"Lá»—i khi clone repository:\")\n        print(e.stderr)  # In thÃ´ng bÃ¡o lá»—i náº¿u cÃ³\n        # ÄÄƒng nháº­p W&B\n    \n    wandb.login(key=wandp_api)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.887336Z","iopub.execute_input":"2025-04-19T14:46:39.887587Z","iopub.status.idle":"2025-04-19T14:46:39.909459Z","shell.execute_reply.started":"2025-04-19T14:46:39.887571Z","shell.execute_reply":"2025-04-19T14:46:39.908952Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class utils:\n    @staticmethod\n    def read_csv(input_path, columns=None):\n        print(\"Äá»c csv file:\")\n        # Kiá»ƒm tra input_path ngay tá»« Ä‘áº§u\n        if input_path is None:\n            raise ValueError(\"input_path khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng (None). Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n file CSV.\")\n        \n        try:  \n            if columns is None:\n                df = pd.read_csv(input_path, encoding='utf-8')\n            else:\n                df = pd.read_csv(input_path, encoding='utf-8', names=columns)\n            print(f\"Äá»c dá»¯ liá»‡u tá»« {input_path} thÃ nh cÃ´ng\")\n            return df\n        except Exception as e:\n            print(f\"Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« {input_path}: {e}\")\n            raise\n\n\n    @staticmethod\n    def read_tsv(input_path, columns=None):\n        print(\"Äá»c tsv file:\")\n        # Kiá»ƒm tra input_path ngay tá»« Ä‘áº§u\n        if input_path is None:\n            raise ValueError(\"input_path khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng (None). Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n file TSV.\")\n        \n        try:  \n            df = None\n            if columns is None:\n                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')  # ThÃªm sep='\\t' cho TSV\n            else:\n                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8', names=columns)\n            \n            print(f\"Äá»c dá»¯ liá»‡u tá»« {input_path} thÃ nh cÃ´ng\")\n            print(df.head())\n            return df\n        except Exception as e:\n            print(f\"Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« {input_path}: {e}\")\n            raise\n\n    @staticmethod\n    def write_csv(df, output_path):\n        try:\n            # Xuáº¥t ra file CSV\n            df.to_csv(output_path, sep=',', encoding='utf-8', index=False)\n            print(f\"ÄÃ£ xuáº¥t dá»¯ liá»‡u ra {output_path}\")\n        except Exception as e:\n            print(f\"Lá»—i khi xuáº¥t file CSV: {e}\")\n            raise\n\n    @staticmethod\n    def write_predictions(predictions, folder_name, lang):\n        \n        output_path = f\"{folder_name}/run_{lang}.trec\"\n        try:\n            with open(output_path, 'w', encoding='utf-8') as f:\n                for query_predict in predictions: \n                    for line in query_predict:  # rank báº¯t Ä‘áº§u tá»« 1\n                        f.write(' '.join(str(x) for x in line) + '\\n')\n            print(f\"ÄÃ£ xuáº¥t file TREC ra {output_path}\")  \n            return output_path\n        \n        except Exception as e:\n            print(f\"Lá»—i khi xuáº¥t file TREC: {e}\")\n            raise\n\n        return output_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.910997Z","iopub.execute_input":"2025-04-19T14:46:39.911219Z","iopub.status.idle":"2025-04-19T14:46:39.925635Z","shell.execute_reply.started":"2025-04-19T14:46:39.911195Z","shell.execute_reply":"2025-04-19T14:46:39.925101Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"class Evaluate:\n    @staticmethod\n    def evaluate(predictions_path, qrels_path):\n        command = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_path, \"--run\", predictions_path]\n        result = subprocess.run(command, capture_output=True, text=True)\n        print(result.stdout)\n\n        return Evaluate.extract_metrics(result)\n        \n    @staticmethod\n    def extract_metrics(result, language=\"en-en\"):\n        stdout = result.stdout\n        map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n        mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n        ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n        precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n        precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n        precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n    \n        metrics = {\n            \"map\": map_value,\n            \"mrr\": mrr,\n            \"ndcg\": ndcg,\n            \"precision@5\": precision_5,\n            \"precision@10\": precision_10,\n            \"precision@100\": precision_100\n        }\n        return metrics     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.926306Z","iopub.execute_input":"2025-04-19T14:46:39.926464Z","iopub.status.idle":"2025-04-19T14:46:39.946579Z","shell.execute_reply.started":"2025-04-19T14:46:39.926452Z","shell.execute_reply":"2025-04-19T14:46:39.946084Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# ModelLogger","metadata":{}},{"cell_type":"code","source":"class ModelLogger:\n    def __init__(self, model_name, loss_function, num_epochs, metrics, notes=\"\", training_time=None,\n                 folder=\"/kaggle/working/talent_clef/results\", file_name=\"model_info.csv\"):\n        self.model_name = model_name\n        self.loss = loss_function\n        self.epochs = num_epochs\n        self.metrics = metrics\n        self.notes = notes\n        self.training_time = training_time\n        self.folder = folder\n        self.file_path = os.path.join(folder, file_name)\n    \n    def compute_average_map(self):\n        map_values = [lang['map'] for lang in self.metrics.values() if 'map' in lang]\n        return sum(map_values) / len(map_values) if map_values else None\n\n    def to_dict(self):\n        return {\n            \"model_name\": [self.model_name],\n            \"Avg result\": [self.compute_average_map()],\n            \"en-en result\": [self.metrics.get(\"en-en\", \"\")],\n            \"es-es result\": [self.metrics.get(\"es-es\", \"\")],\n            \"de-de result\": [self.metrics.get(\"de-de\", \"\")],\n            \"zh-zh result\": [self.metrics.get(\"zh-zh\", \"\")],\n            \"en-es result\": [self.metrics.get(\"en-es\", \"\")],\n            \"en-de result\": [self.metrics.get(\"en-de\", \"\")],\n            \"en-zh result\": [self.metrics.get(\"en-zh\", \"\")],\n            \"loss\": [self.loss],\n            \"epochs\": [self.epochs],\n            \"training_time (s)\": [self.training_time],\n            \"date\": [Timer.get()],\n            \"notes\": [self.notes]\n        }\n\n    def save(self):\n        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i\n        os.makedirs(self.folder, exist_ok=True)\n\n        # Táº¡o DataFrame tá»« dict\n        df_new = pd.DataFrame(self.to_dict())\n\n        if os.path.exists(self.file_path):\n            df_existing = pd.read_csv(self.file_path)\n            df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n            df_updated.to_csv(self.file_path, index=False)\n            print(f\"âœ… ÄÃ£ thÃªm dá»¯ liá»‡u vÃ o file: {self.file_path}\")\n        else:\n            df_new.to_csv(self.file_path, index=False)\n            print(f\"âœ… ÄÃ£ táº¡o file má»›i: {self.file_path}\")\n\n    def show_log(self):\n        if os.path.exists(self.file_path):\n            print(f\"\\nðŸ“„ Ná»™i dung file log:\")\n            log_df = utils.read_csv(self.file_path)\n            print(log_df)\n        else:\n            print(\"âš ï¸ ChÆ°a cÃ³ file log Ä‘á»ƒ hiá»ƒn thá»‹.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.947284Z","iopub.execute_input":"2025-04-19T14:46:39.947507Z","iopub.status.idle":"2025-04-19T14:46:39.966472Z","shell.execute_reply.started":"2025-04-19T14:46:39.947486Z","shell.execute_reply":"2025-04-19T14:46:39.965958Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Timer","metadata":{}},{"cell_type":"code","source":"class Timer:\n    @staticmethod\n    def get():\n        # Láº¥y mÃºi giá» Viá»‡t Nam (UTC+7)\n        vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n        \n        # Láº¥y thá»i gian hiá»‡n táº¡i á»Ÿ UTC\n        utc_now = datetime.now(pytz.utc)\n        \n        # Chuyá»ƒn thá»i gian UTC sang mÃºi giá» Viá»‡t Nam\n        vietnam_time = utc_now.astimezone(vietnam_timezone)\n        \n        # Tráº£ vá» thá»i gian Ä‘Ã£ Ä‘á»‹nh dáº¡ng theo kiá»ƒu YYYY-MM-DD HH:MM:SS\n        return vietnam_time.strftime(\"%m-%d_%H-%M-%S\")\n\n# Gá»i hÃ m vÃ  in káº¿t quáº£\nprint(Timer.get())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:46:39.967124Z","iopub.execute_input":"2025-04-19T14:46:39.967318Z","iopub.status.idle":"2025-04-19T14:46:40.016481Z","shell.execute_reply.started":"2025-04-19T14:46:39.967304Z","shell.execute_reply":"2025-04-19T14:46:40.015959Z"}},"outputs":[{"name":"stdout","text":"04-19_21-46-40\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Plot Káº¿t Quáº£","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nclass PlotResult:\n    def __init__(self, data, predictions_file):\n        # Khá»Ÿi táº¡o class vá»›i cÃ¡c tham sá»‘ prediction_files vÃ  utils\n        self.corpus_file = data['corpus'] \n        self.queries_file = data['queries']\n        self.predictions_file = predictions_file\n        self.qrels_file = data['qrels']\n        \n        \n    def create_merged_dataframe(self, lang):\n        # Äá»c tá»‡p prediction vÃ  táº¡o DataFrame\n        prediction_file = self.predictions_file[lang]\n        columns = ['q_id', 'iter', 'doc_id', 'rank', 'score', 'run_id']\n        df_results = pd.read_csv(prediction_file, sep='\\s+', header=None, names=columns)\n        \n        # Äá»c cÃ¡c tá»‡p qrels, queries, vÃ  corpus\n        qrels_file = self.qrels_file[lang]\n        queries_file = self.queries_file[lang]\n        corpus_file = self.corpus_file[lang]\n        \n        qrels = utils.read_tsv(qrels_file, ['q_id', 'anchor', 'c_id', 'label'])\n        corpus_df = utils.read_tsv(corpus_file)\n        queries_df = utils.read_tsv(queries_file)\n        \n        # Táº¡o DataFrame dá»± Ä‘oÃ¡n (predictions)\n        predicts = df_results[['q_id', 'doc_id']]\n        \n        # Táº¡o DataFrame káº¿t quáº£ (results) tá»« qrels\n        results = qrels[['q_id', 'c_id']]\n        \n        # Merge giá»¯a predictions vÃ  results\n        merge = pd.merge(predicts, results, left_on=['q_id', 'doc_id'], right_on=['q_id', 'c_id'], how='left')\n        \n        # Merge vá»›i queries_df Ä‘á»ƒ cÃ³ q_jobtitle\n        merge = merge.merge(queries_df, on='q_id').rename(columns={'jobtitle': 'q_jobtitle'})\n        \n        # Merge vá»›i corpus_df Ä‘á»ƒ cÃ³ c_jobtitle\n        merge = merge.merge(corpus_df, left_on='doc_id', right_on='c_id').rename(columns={'jobtitle': 'c_jobtitle', 'c_id_x': 'c_id'}).drop(['c_id_y'], axis=1)\n        \n        # ThÃªm cá»™t 'label', xÃ¡c Ä‘á»‹nh náº¿u doc_id trÃ¹ng vá»›i c_id\n        merge['label'] = merge.apply(lambda row: True if row['doc_id'] == row['c_id'] else False, axis=1)\n        \n        # TÃ­nh sá»‘ káº¿t quáº£ dá»± Ä‘oÃ¡n cho má»—i q_id\n        n_results = merge.groupby('q_id')['c_id'].count()\n        merge['n_results'] = merge['q_id'].map(n_results)\n        \n        return merge\n\n    def print_job_info(self, df):\n        # Láº·p qua tá»«ng nhÃ³m q_id\n        for q_id, group in df.groupby('q_id'):\n            q_jobtitle = group['q_jobtitle'].iloc[0]  # Jobtitle cá»§a q_id\n            n_results = group['n_results'].iloc[0]  # Sá»‘ lÆ°á»£ng káº¿t quáº£ Ä‘Ãºng\n            \n            # Danh sÃ¡ch jobtitle tÃ´i dá»± Ä‘oÃ¡n (doc_id) cÃ¹ng vá»›i dáº¥u tick/ chÃ©o\n            predicted_jobtitles = group[['c_jobtitle', 'label']].head(n_results).reset_index(drop=True)\n            predicted_jobtitles['status'] = predicted_jobtitles['label'].apply(lambda x: \"âœ…\" if x else \"âŒ\")\n            \n            # Táº¡o cá»™t 'predicted_position' chá»©a vá»‹ trÃ­ cá»§a má»—i jobtitle trong danh sÃ¡ch dá»± Ä‘oÃ¡n\n            predicted_jobtitles['predicted_position'] = predicted_jobtitles.index + 1  # Vá»‹ trÃ­ trong thá»© tá»± dá»± Ä‘oÃ¡n\n    \n            # Lá»c káº¿t quáº£ Ä‘Ã£ cho vá»›i label = True (cÃ³ káº¿t quáº£ Ä‘Ãºng)\n            results_given = group[group['label'] == True][['c_jobtitle', 'label']].head(n_results).to_dict(orient='records')\n            \n            # In thÃ´ng tin\n            print(f\"Jobtitle cá»§a q_id {q_id}: {q_jobtitle}\")\n            print(f\"Sá»‘ lÆ°á»£ng jobtitle dá»± Ä‘oÃ¡n: {n_results}\")\n            print(\"Danh sÃ¡ch jobtitle tÃ´i dá»± Ä‘oÃ¡n:\")\n            for idx, row in predicted_jobtitles.iterrows():\n                print(f\"{row['predicted_position']}. {row['c_jobtitle']} {row['status']}\")\n            \n            print(\"Danh sÃ¡ch káº¿t quáº£ Ä‘Ã£ cho (label = True):\")\n            for idx, result in enumerate(results_given, 1):\n                # Kiá»ƒm tra xem jobtitle cÃ³ tá»“n táº¡i trong danh sÃ¡ch dá»± Ä‘oÃ¡n khÃ´ng\n                if result['c_jobtitle'] in predicted_jobtitles['c_jobtitle'].values:\n                    # TÃ¬m vá»‹ trÃ­ cá»§a jobtitle káº¿t quáº£ Ä‘Ã£ cho trong danh sÃ¡ch dá»± Ä‘oÃ¡n\n                    position_in_predicted = predicted_jobtitles[predicted_jobtitles['c_jobtitle'] == result['c_jobtitle']].index[0] + 1\n                    label = \"âœ…\" if result['label'] else \"âŒ\"\n                    print(f\"{idx}. Jobtitle: {result['c_jobtitle']} {label}, Vá»‹ trÃ­ trong nhÃ³m dá»± Ä‘oÃ¡n: {position_in_predicted}\")\n                else:\n                    # TÃ¬m vá»‹ trÃ­ cá»§a jobtitle trong toÃ n bá»™ nhÃ³m q_id (toÃ n bá»™ danh sÃ¡ch dá»± Ä‘oÃ¡n)\n                    position_in_group = group[group['c_jobtitle'] == result['c_jobtitle']].index[0] + 1\n                    print(f\"{idx}. Jobtitle: {result['c_jobtitle']} âŒ, Vá»‹ trÃ­ trong toÃ n bá»™ nhÃ³m: {position_in_group}\")\n            \n            print(\"=\"*50)\n\n    def __call__(self, lang):\n        # Gá»i hÃ m create_merged_dataframe Ä‘á»ƒ táº¡o DataFrame\n        merged_df = self.create_merged_dataframe(lang)\n        \n        # Gá»i hÃ m print_job_info Ä‘á»ƒ in káº¿t quáº£\n        self.print_job_info(merged_df)\n        return merged_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:24:25.159293Z","iopub.execute_input":"2025-04-19T16:24:25.159529Z","iopub.status.idle":"2025-04-19T16:24:25.171956Z","shell.execute_reply.started":"2025-04-19T16:24:25.159513Z","shell.execute_reply":"2025-04-19T16:24:25.171229Z"}},"outputs":[],"execution_count":121},{"cell_type":"markdown","source":"# HÃ m thá»±c thi","metadata":{}},{"cell_type":"markdown","source":"## 1. Clone data","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhuggingface_api = user_secrets.get_secret(\"huggingface\")\n\n!huggingface-cli login --token {huggingface_api}\n!git clone https://huggingface.co/hoivinh20789/talent_clef /kaggle/working/models\nload_git_workspace_wandb()\n\n!git clone https://github.com/TalentCLEF/talentclef25_evaluation_script.git\n!pip install -r \"/kaggle/working/talentclef25_evaluation_script/requirements.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:47:50.691656Z","iopub.execute_input":"2025-04-19T14:47:50.692274Z","iopub.status.idle":"2025-04-19T14:48:47.284279Z","shell.execute_reply.started":"2025-04-19T14:47:50.692252Z","shell.execute_reply":"2025-04-19T14:48:47.283464Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nThe token `kaggle` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `kaggle`\nCloning into '/kaggle/working/models'...\nremote: Enumerating objects: 30, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 30 (delta 3), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\nUnpacking objects: 100% (30/30), 164.57 KiB | 5.49 MiB/s, done.\nFiltering content: 100% (6/6), 958.41 MiB | 159.11 MiB/s, done.\nClone thÃ nh cÃ´ng!\nStdout: \nStderr: Cloning into 'talent_clef'...\nUpdating files:  53% (75/140)\nUpdating files:  54% (76/140)\nUpdating files:  55% (77/140)\nUpdating files:  56% (79/140)\nUpdating files:  57% (80/140)\nUpdating files:  58% (82/140)\nUpdating files:  59% (83/140)\nUpdating files:  60% (84/140)\nUpdating files:  60% (85/140)\nUpdating files:  61% (86/140)\nUpdating files:  62% (87/140)\nUpdating files:  63% (89/140)\nUpdating files:  64% (90/140)\nUpdating files:  65% (91/140)\nUpdating files:  66% (93/140)\nUpdating files:  67% (94/140)\nUpdating files:  68% (96/140)\nUpdating files:  69% (97/140)\nUpdating files:  70% (98/140)\nUpdating files:  71% (100/140)\nUpdating files:  72% (101/140)\nUpdating files:  73% (103/140)\nUpdating files:  74% (104/140)\nUpdating files:  75% (105/140)\nUpdating files:  76% (107/140)\nUpdating files:  77% (108/140)\nUpdating files:  78% (110/140)\nUpdating files:  79% (111/140)\nUpdating files:  80% (112/140)\nUpdating files:  81% (114/140)\nUpdating files:  82% (115/140)\nUpdating files:  83% (117/140)\nUpdating files:  84% (118/140)\nUpdating files:  85% (119/140)\nUpdating files:  86% (121/140)\nUpdating files:  87% (122/140)\nUpdating files:  88% (124/140)\nUpdating files:  89% (125/140)\nUpdating files:  90% (126/140)\nUpdating files:  91% (128/140)\nUpdating files:  92% (129/140)\nUpdating files:  93% (131/140)\nUpdating files:  94% (132/140)\nUpdating files:  95% (133/140)\nUpdating files:  96% (135/140)\nUpdating files:  97% (136/140)\nUpdating files:  98% (138/140)\nUpdating files:  99% (139/140)\nUpdating files: 100% (140/140)\nUpdating files: 100% (140/140), done.\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoivinh20789\u001b[0m (\u001b[33mhoivinh20789-uit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"name":"stdout","text":"Cloning into 'talentclef25_evaluation_script'...\nremote: Enumerating objects: 27, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 27 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (27/27), 10.10 KiB | 10.10 MiB/s, done.\nResolving deltas: 100% (10/10), done.\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.2.3)\nCollecting ranx (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.11/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.60.0)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.67.1)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.15.2)\nCollecting ir-datasets (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (14.0.0)\nRequirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10.15)\nCollecting lz4 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting cbor2 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.2)\nCollecting fastparquet (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54.1->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.17.0)\nRequirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.9.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.3.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (24.2)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.13.3)\nCollecting inscriptis>=2.2.0 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (5.3.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (6.0.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.32.3)\nCollecting trec-car-tools>=2.5.4 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\nCollecting warc3-wet>=0.2.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\nCollecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting zlib-state>=0.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting ijson>=3.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting unlzw3>=0.2.1 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.11/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (19.0.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.19.1)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.7.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.13.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.1.31)\nCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor-1.0.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nDownloading ranx-0.3.20-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\nDownloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\nDownloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\nDownloading zlib_state-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nBuilding wheels for collected packages: warc3-wet-clueweb09, cbor\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=151f3e6511392b55184c4fba1101690b98bd1d2066cb30d55ddaab59431e4cde\n  Stored in directory: /root/.cache/pip/wheels/63/f9/dc/2dd16d3330e327236e4d407941975c42d5159d200cdb7922d8\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53930 sha256=2349f7458a94aa42e2e695d6061aa2fb010bd3bdd3ba27313e084c7cdd8c7d54\n  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\nSuccessfully built warc3-wet-clueweb09 cbor\nInstalling collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, cbor2, inscriptis, trec-car-tools, ir-datasets, fastparquet, ranx\nSuccessfully installed cbor-1.0.0 cbor2-5.6.5 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## RetrievalApp","metadata":{}},{"cell_type":"code","source":"data = {\n    \"corpus\": {\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements\"\n    },\n    \n    \"queries\":{\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/queries\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/queries\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/queries\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/queries\"\n    },\n    \n    \"qrels\": {\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\"\n    }\n}\n\nmodel_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\nmodel_path = \"/kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6\"\napp = RetrievalApp(model_name, model_path)\nratings, prediction_files = app(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:49:04.818303Z","iopub.execute_input":"2025-04-19T14:49:04.819080Z","iopub.status.idle":"2025-04-19T14:51:45.377002Z","shell.execute_reply.started":"2025-04-19T14:49:04.819052Z","shell.execute_reply":"2025-04-19T14:51:45.376270Z"}},"outputs":[{"name":"stdout","text":"Device sá»­ dá»¥ng: cuda\nTáº£i mÃ´ hÃ¬nh tá»« Ä‘Æ°á»ng dáº«n cá»¥c bá»™: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6\nMÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\nLoad mÃ´ hÃ¬nh.....\nChuáº©n bá»‹ data: ......\nChuáº©n bá»‹ data en-en:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements thÃ nh cÃ´ng\n   c_id                          jobtitle\n0     1                recording engineer\n1     2              director of taxation\n2     3  technical support representative\n3     4                        hr manager\n4     5           computer graphic artist\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/english/queries thÃ nh cÃ´ng\n   q_id             jobtitle\n0     1                nanny\n1     2    food technologist\n2     3   broadcast engineer\n3     4  automation engineer\n4     5         veterinarian\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_en-en.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_en-en.csv\nChuáº©n bá»‹ data de-de:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements thÃ nh cÃ´ng\n   c_id                   jobtitle\n0     1               pr-managerin\n1     2       talkshow-moderatorin\n2     3             sporttrainerin\n3     4         preiskoordinatorin\n4     5  persoÌˆnlicher bankberater\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/german/queries thÃ nh cÃ´ng\n   q_id                        jobtitle\n0     1           technischer recruiter\n1     2                    brieftraÌˆger\n2     3              grundschullehrerin\n3     4                     3d-animator\n4     5  unternehmensstrategieberaterin\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_de-de.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_de-de.csv\nChuáº©n bá»‹ data es-es:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements thÃ nh cÃ´ng\n   c_id                         jobtitle\n0     1               desarrollador java\n1     2         diseÃ±adora de accesorios\n2     3  agente inmobiliario residencial\n3     4           planificador de ventas\n4     5          ayudante de conferencia\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/spanish/queries thÃ nh cÃ´ng\n   q_id                        jobtitle\n0     1     ingeniera de automatizaciÃ³n\n1     2  tÃ©cnica de soporte informÃ¡tico\n2     3                 piloto de aviÃ³n\n3     4   ingeniera de diseÃ±o analÃ³gico\n4     5      analista de capital riesgo\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_es-es.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_es-es.csv\nChuáº©n bá»‹ data zh-zh:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements thÃ nh cÃ´ng\n   c_id jobtitle\n0     1   è‡ªåŠ¨åŒ–æŠ€æœ¯å‘˜\n1     2    é€‰è§’åˆ¶ä½œäºº\n2     3     ä½“è‚²ç»ç†\n3     4     ä¸´æ—¶åŠ©ç†\n4     5  ç”¨æˆ·æ”¯æŒæŠ€æœ¯å‘˜\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/chinese/queries thÃ nh cÃ´ng\n   q_id jobtitle\n0     1     è´·æ¬¾å¹²äº‹\n1     2     ç¨ŽåŠ¡ä¼šè®¡\n2     3    çŠ¬ç±»ç¾Žå®¹å¸ˆ\n3     4      æ”¶é“¶å‘˜\n4     5      ç­¹æ¬¾äºº\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_zh-zh.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_zh-zh.csv\nBáº¯t Ä‘áº§u inference.....\nLoad data en-en:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_en-en.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_en-en.csv thÃ nh cÃ´ng\nLoad data de-de:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_de-de.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_de-de.csv thÃ nh cÃ´ng\nLoad data es-es:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_es-es.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_es-es.csv thÃ nh cÃ´ng\nLoad data zh-zh:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_zh-zh.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_zh-zh.csv thÃ nh cÃ´ng\nInference en-en:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/82 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"748315fa736a4fe58c0e53e7c214ea47"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"796c6bfebea649ac805fbbdc36b46524"}},"metadata":{}},{"name":"stdout","text":"Inference de-de:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/148 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58617f76447a471184de74af21f0d613"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14166f706b4d401db2c3bbbe23d05ba2"}},"metadata":{}},{"name":"stdout","text":"Inference es-es:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/146 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7275ebac861459d837237ded1f0e269"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0e59dbf29f443382927650fcf31308"}},"metadata":{}},{"name":"stdout","text":"Inference zh-zh:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4a420465134e3babc32ef96fb38792"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d031fdfb33ee45c3bacfd7911f84e5ed"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n:.....\nDá»± Ä‘oÃ¡n en-en:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:07<00:00, 14.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dá»± Ä‘oÃ¡n de-de:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:24<00:00,  8.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dá»± Ä‘oÃ¡n es-es:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [00:22<00:00,  8.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dá»± Ä‘oÃ¡n zh-zh:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:06<00:00, 15.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Báº¯t Ä‘áº§u xuáº¥t file:....\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_en-en.trec\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_de-de.trec\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_es-es.trec\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_zh-zh.trec\nÄang nÃ©n thÆ° má»¥c /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13 thÃ nh /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13.zip...\nFile zip Ä‘Ã£ Ä‘Æ°á»£c táº¡o: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13.zip\nBáº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡:.....\nÄÃ¡nh giÃ¡ en-en:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_en-en.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.5452\nmrr: 0.8829\nndcg: 0.8068\nprecision@5: 0.7162\nprecision@10: 0.6181\nprecision@100: 0.1768\n\nÄÃ¡nh giÃ¡ de-de:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_de-de.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.3113\nmrr: 0.5638\nndcg: 0.6531\nprecision@5: 0.5281\nprecision@10: 0.4842\nprecision@100: 0.1916\n\nÄÃ¡nh giÃ¡ es-es:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_es-es.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.4501\nmrr: 0.8116\nndcg: 0.7615\nprecision@5: 0.6876\nprecision@10: 0.6178\nprecision@100: 0.2288\n\nÄÃ¡nh giÃ¡ zh-zh:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_zh-zh.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.4724\nmrr: 0.8449\nndcg: 0.7575\nprecision@5: 0.6408\nprecision@10: 0.5447\nprecision@100: 0.1537\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"prediction_files","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:52:25.424445Z","iopub.execute_input":"2025-04-19T14:52:25.424834Z","iopub.status.idle":"2025-04-19T14:52:25.433075Z","shell.execute_reply.started":"2025-04-19T14:52:25.424805Z","shell.execute_reply":"2025-04-19T14:52:25.431717Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'en-en': '/kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_en-en.trec',\n 'de-de': '/kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_de-de.trec',\n 'es-es': '/kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_es-es.trec',\n 'zh-zh': '/kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_21-50-13/run_zh-zh.trec'}"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"ratings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:35:01.593699Z","iopub.execute_input":"2025-04-18T07:35:01.594312Z","iopub.status.idle":"2025-04-18T07:35:01.599918Z","shell.execute_reply.started":"2025-04-18T07:35:01.594285Z","shell.execute_reply":"2025-04-18T07:35:01.599174Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'en-en': {'map': 0.5452,\n  'mrr': 0.8829,\n  'ndcg': 0.8068,\n  'precision@5': 0.7162,\n  'precision@10': 0.6181,\n  'precision@100': 0.1768},\n 'de-de': {'map': 0.3113,\n  'mrr': 0.5638,\n  'ndcg': 0.6531,\n  'precision@5': 0.5281,\n  'precision@10': 0.4842,\n  'precision@100': 0.1916},\n 'es-es': {'map': 0.4501,\n  'mrr': 0.8116,\n  'ndcg': 0.7615,\n  'precision@5': 0.6876,\n  'precision@10': 0.6178,\n  'precision@100': 0.2288},\n 'zh-zh': {'map': 0.4724,\n  'mrr': 0.8449,\n  'ndcg': 0.7575,\n  'precision@5': 0.6408,\n  'precision@10': 0.5447,\n  'precision@100': 0.1537}}"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## 3. Training","metadata":{}},{"cell_type":"code","source":"# train_data_org_file = \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"\n# preparer = DataPreparer()\n# train_data, train_file = preparer.prepare_train_data(train_data_org_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T18:00:10.156236Z","iopub.execute_input":"2025-04-16T18:00:10.156528Z","iopub.status.idle":"2025-04-16T18:00:19.762955Z","shell.execute_reply.started":"2025-04-16T18:00:10.156508Z","shell.execute_reply":"2025-04-16T18:00:19.762026Z"}},"outputs":[{"name":"stdout","text":"Äá»c dá»¯ liá»‡u train_org:\n                       jobtitle  \\\n0    director of technical arts   \n0          technical supervisor   \n0             technical manager   \n0  head of technical department   \n0            technical director   \n\n                                               skill  label  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \nCá»™t dá»¯ liá»‡u: Index(['jobtitle', 'skill', 'label'], dtype='object')\nXuáº¥t dá»¯ liá»‡u train sau khi chuáº©n bá»‹:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/train.csv\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# train_data = Dataset.load_train_data(train_file)\n# dataset = Dataset(train_data)\n\n# model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n# loss = losses.MultipleNegativesRankingLoss\n\n# params = {\n#     \"num_epochs\": 2,\n#     \"output_path\": f\"/kaggle/working/talent_clef/model/{model_name}/epoch2\",\n#     \"warmup_steps\": 100,\n# }\n\n# trainer = Trainer(model_name)\n# model = trainer.train(dataset.data, loss, params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T18:03:57.739587Z","iopub.execute_input":"2025-04-16T18:03:57.739904Z"}},"outputs":[{"name":"stdout","text":"Äá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/train.csv thÃ nh cÃ´ng\nDevice sá»­ dá»¥ng: cuda\nTáº£i mÃ´ hÃ¬nh tá»« Hugging Face vá»›i tÃªn: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153bc3b0cdc049cda5a42cbde2b9d15b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06982a3ec0f048ec92bdfefd61a409d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b77bc74fd3949549c22899e27f30943"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945e0da701774e9b98f67bf2ff4c4082"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c732fd1a618b4d23b08171a6c1bd84f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6d8ab31d5ea496d8a8ac5f83ea9ae01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daf04bd85d9947b8bd904c62c0a6ef32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6064adda0e9c41019ae84e197bb2d645"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d86c651139e7488f82d0eddbef6e0396"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02f0f218c6e04a8695fdc059633a46b8"}},"metadata":{}},{"name":"stdout","text":"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\nKhá»Ÿi táº¡o dataset:\nBáº¯t Ä‘áº§u train: \n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_180418-0f3b4yz7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers' target=\"_blank\">https://wandb.ai/hoivinh20789-uit/sentence-transformers</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7' target=\"_blank\">https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2387' max='3376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2387/3376 07:34 < 03:08, 5.25 it/s, Epoch 1.41/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.420400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.275600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.232200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.158100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## 5. Log Model","metadata":{}},{"cell_type":"code","source":"logger = ModelLogger(\n    model_name=model_name,\n    loss_function=None,\n    num_epochs=None,\n    metrics=ratings,\n    notes=\"epoch 6 bá» trÃ¹ng láº·p query corpus\"\n)\n\nlogger.save()\nlogger.show_log()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:35:23.084612Z","iopub.execute_input":"2025-04-18T07:35:23.084885Z","iopub.status.idle":"2025-04-18T07:35:23.098527Z","shell.execute_reply.started":"2025-04-18T07:35:23.084865Z","shell.execute_reply":"2025-04-18T07:35:23.097816Z"}},"outputs":[{"name":"stdout","text":"âœ… ÄÃ£ táº¡o file má»›i: /kaggle/working/talent_clef/results/model_info.csv\n\nðŸ“„ Ná»™i dung file log:\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/results/model_info.csv thÃ nh cÃ´ng\n                                          model_name  Avg result  \\\n0  sentence-transformers/paraphrase-multilingual-...     0.44475   \n\n                                        en-en result  \\\n0  {'map': 0.5452, 'mrr': 0.8829, 'ndcg': 0.8068,...   \n\n                                        es-es result  \\\n0  {'map': 0.4501, 'mrr': 0.8116, 'ndcg': 0.7615,...   \n\n                                        de-de result  \\\n0  {'map': 0.3113, 'mrr': 0.5638, 'ndcg': 0.6531,...   \n\n                                        zh-zh result  en-es result  \\\n0  {'map': 0.4724, 'mrr': 0.8449, 'ndcg': 0.7575,...           NaN   \n\n   en-de result  en-zh result  loss  epochs  training_time (s)  \\\n0           NaN           NaN   NaN     NaN                NaN   \n\n             date                              notes  \n0  04-18_14-35-23  epoch 6 bá» trÃ¹ng láº·p query corpus  \n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# Git Push","metadata":{}},{"cell_type":"code","source":"cd talent_clef","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:35:29.259839Z","iopub.execute_input":"2025-04-18T07:35:29.260415Z","iopub.status.idle":"2025-04-18T07:35:29.265704Z","shell.execute_reply.started":"2025-04-18T07:35:29.260391Z","shell.execute_reply":"2025-04-18T07:35:29.264951Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/talent_clef\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"brand_name = model_name + \"/\" +Timer.get()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:35:31.306612Z","iopub.execute_input":"2025-04-18T07:35:31.307223Z","iopub.status.idle":"2025-04-18T07:35:31.311037Z","shell.execute_reply.started":"2025-04-18T07:35:31.307202Z","shell.execute_reply":"2025-04-18T07:35:31.310309Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"brand_name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:35:34.260901Z","iopub.execute_input":"2025-04-18T07:35:34.261389Z","iopub.status.idle":"2025-04-18T07:35:34.265884Z","shell.execute_reply.started":"2025-04-18T07:35:34.261365Z","shell.execute_reply":"2025-04-18T07:35:34.265168Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31'"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"!git config --global user.email \"hoivd79@gmail.com\"\n!git config --global user.name \"Dang Vinh Hoi\"\n!git checkout -b {brand_name}      # Táº¡o vÃ  chuyá»ƒn sang nhÃ¡nh dev\n!git status\n!git add .\n!git commit -m \"updated\"\n!git push -u origin {brand_name}    # Push láº§n Ä‘áº§u, thiáº¿t láº­p tracking","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:35:38.770148Z","iopub.execute_input":"2025-04-18T07:35:38.770854Z","iopub.status.idle":"2025-04-18T07:36:35.437525Z","shell.execute_reply.started":"2025-04-18T07:35:38.770829Z","shell.execute_reply":"2025-04-18T07:36:35.436755Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Switched to a new branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31'\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"On branch sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\t\u001b[31mpredict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/\u001b[m\n\t\u001b[31mresults/\u001b[m\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"[sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31 6541fb7] updated\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" 16 files changed, 7068320 insertions(+)\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-27-51.zip\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-27-51/run_de-de.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-27-51/run_en-en.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-27-51/run_es-es.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-27-51/run_zh-zh.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-30-34.zip\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-30-34/run_de-de.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-30-34/run_en-en.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-30-34/run_es-es.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-30-34/run_zh-zh.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-34-06.zip\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-34-06/run_de-de.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-34-06/run_en-en.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-34-06/run_es-es.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-34-06/run_zh-zh.trec\n create mode 100644 results/model_info.csv\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Enumerating objects: 23, done.\nCounting objects: 100% (23/23), done.\nDelta compression using up to 4 threads\nCompressing objects: 100% (19/19), done.\nWriting objects: 100% (20/20), 129.54 MiB | 8.31 MiB/s, done.\nTotal 20 (delta 3), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (3/3), completed with 2 local objects.\u001b[K\nremote: \nremote: Create a pull request for 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31' on GitHub by visiting:\u001b[K\nremote:      https://github.com/hoivd/talent_clef/pull/new/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31\u001b[K\nremote: \nTo https://github.com/hoivd/talent_clef\n * [new branch]      sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31 -> sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31\nBranch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31' set up to track remote branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-18_14-35-31' from 'origin'.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"cd ..\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:22:00.505775Z","iopub.execute_input":"2025-04-14T07:22:00.506117Z","iopub.status.idle":"2025-04-14T07:22:00.512221Z","shell.execute_reply.started":"2025-04-14T07:22:00.506086Z","shell.execute_reply":"2025-04-14T07:22:00.511293Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/talent_clef\n","output_type":"stream"}],"execution_count":58}]}