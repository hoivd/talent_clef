{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torchmetrics.retrieval import RetrievalMAP\nimport os\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport google.generativeai as genai\nimport os\nimport wandb\nimport ast\nimport subprocess\nimport pickle\nimport shutil\nimport datetime\nimport pytz\nfrom huggingface_hub import HfApi, upload_folder\nfrom datetime import datetime\nimport pytz","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-04-19T12:47:11.641058Z","iopub.execute_input":"2025-04-19T12:47:11.641394Z","iopub.status.idle":"2025-04-19T12:47:11.647742Z","shell.execute_reply.started":"2025-04-19T12:47:11.641363Z","shell.execute_reply":"2025-04-19T12:47:11.646916Z"},"trusted":true},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"# PositiveExampleMining","metadata":{}},{"cell_type":"code","source":"class MiningPosExample:\n    def __init__(self):\n        self.data = None  # Khởi tạo thuộc tính self.data là None\n\n     # Phương thức __len__ để trả về số dòng của data\n    def __len__(self):\n        if self.data is not None:\n            return len(self.data)\n        return 0  # Nếu self.data chưa được gán (None), trả về 0\n    \n    # Phương thức __getitem__ để truy xuất một dòng trong data theo chỉ số\n    def __getitem__(self, index):\n        if self.data is not None:\n            return self.data.iloc[index]\n        raise IndexError(\"Index out of range\")  # Nếu self.data là None, raise lỗi\n        \n    def mining_pos_example(self, data_file):\n        # Đọc dữ liệu từ file (giả sử là file CSV)\n        df = pd.read_csv(data_file)\n        df['jobtitles'] = df['jobtitles'].apply(ast.literal_eval)\n        # Lấy các cột 'jobtitles' và 'skills_gen', sau đó \"phân nổ\" danh sách trong cột 'jobtitles'\n        new_df = df[['jobtitles', 'skills_gen']].explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n        \n        # Thêm cột 'label' với giá trị toàn bộ là 1\n        new_df['label'] = 1\n        \n        # Lưu kết quả vào self.data\n        self.data = new_df\n        \n        return new_df\n\n    def get_data(self):\n        return self.data","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:51.972684Z","iopub.execute_input":"2025-04-19T10:29:51.972931Z","iopub.status.idle":"2025-04-19T10:29:51.987692Z","shell.execute_reply.started":"2025-04-19T10:29:51.972909Z","shell.execute_reply":"2025-04-19T10:29:51.986903Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# NegativeExampleMining","metadata":{}},{"cell_type":"code","source":"class MiningNegExample:\n    def __init__(self):\n        self.data = None  # Khởi tạo thuộc tính self.data là None\n    \n     # Phương thức __len__ để trả về số dòng của data\n    def __len__(self):\n        if self.data is not None:\n            return len(self.data)\n        return 0  # Nếu self.data chưa được gán (None), trả về 0\n    \n    # Phương thức __getitem__ để truy xuất một dòng trong data theo chỉ số\n    def __getitem__(self, index):\n        if self.data is not None:\n            return self.data.iloc[index]\n        raise IndexError(\"Index out of range\")  # Nếu self.data là None, raise lỗi\n\n    def prepare_source_file(self, source_file):\n        source_df = pd.read_csv(source_file)\n        source_df['jobtitles'] = source_df['jobtitles'].apply(ast.literal_eval)\n        # Lấy các cột 'jobtitles' và 'skills_gen', sau đó \"phân nổ\" danh sách trong cột 'jobtitles'\n        source_df = source_df.explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill', 'tid': 'gid'})\n        source_df = source_df.reset_index(drop=True).reset_index(names='tid')\n\n        return source_df\n        \n    def mining_neg_example(self, pair_file, source_file):\n        # Đọc dữ liệu từ file (giả sử là file CSV)\n        \n        source_df = self.prepare_source_file(source_file)\n        pair_df = pd.read_csv(pair_file)\n        pair_df = pair_df.merge(source_df, left_on='q_id', right_on='tid')                \n        pair_df = pair_df.merge(source_df, left_on='c_id', right_on='tid')\n        pair_df = pair_df.rename(columns={'jobtitle_x': 'q_jobtitle', 'skill_x': 'q_skill', 'jobtitle_y': 'c_jobtitle', 'skill_y': 'c_skill'})\n        query_pair = pair_df[['q_jobtitle', 'c_skill', 'label']].rename(columns={'q_jobtitle': 'jobtitle', 'c_skill': 'skill'})\n        corpus_pair = pair_df[['c_jobtitle', 'q_skill', 'label']].rename(columns={'c_jobtitle': 'jobtitle', 'q_skill': 'skill'})\n        neg_pair = pd.concat([query_pair, corpus_pair], axis=0)\n\n        self.data = neg_pair\n        return neg_pair\n    \n    def get_data(self):\n        return self.data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T10:29:51.988700Z","iopub.execute_input":"2025-04-19T10:29:51.989015Z","iopub.status.idle":"2025-04-19T10:29:52.007333Z","shell.execute_reply.started":"2025-04-19T10:29:51.988980Z","shell.execute_reply":"2025-04-19T10:29:52.006689Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# DataPrepare","metadata":{}},{"cell_type":"code","source":"class DataPreparer:\n    def prepare_train_data(self, neg_pair_file, source_file):\n        print(\"Đọc dữ liệu train_org:\")\n        \n        pos_miner = MiningPosExample()\n        pos_df = pos_miner.mining_pos_example(source_file)\n        print(pos_df.head())\n\n        neg_miner = MiningNegExample()\n        neg_df = neg_miner.mining_neg_example(neg_pair_file, source_file)\n        print(neg_df.head())\n\n        train_df = pd.concat([pos_df, neg_df], axis=0)\n        train_df = train_df.drop_duplicates(subset=None, keep='first', inplace=False)\n\n        print(train_df.head())\n        print(f\"Cột dữ liệu: {train_df.columns}\")\n        print(\"Xuất dữ liệu train sau khi chuẩn bị:\")\n        train_file = \"/kaggle/working/train.csv\"\n        utils.write_csv(train_df, train_file)\n        return train_df, train_file\n\n    def prepare_inference_data(self, corpus_path, queries_path, lang):\n        print(\"Đọc dữ liệu inference:\")\n        corpus_df = utils.read_tsv(corpus_path)\n        queries_df = utils.read_tsv(queries_path)\n        \n        print(\"Xuất dữ liệu inference:\")\n        corpus_out_path = f\"/kaggle/working/corpus_{lang}.csv\"\n        queries_out_path = f\"/kaggle/working/queries_{lang}.csv\"\n        utils.write_csv(corpus_df, corpus_out_path)\n        utils.write_csv(queries_df, queries_out_path)\n        return corpus_out_path, queries_out_path","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:43:11.578579Z","iopub.execute_input":"2025-04-19T10:43:11.578982Z","iopub.status.idle":"2025-04-19T10:43:11.585653Z","shell.execute_reply.started":"2025-04-19T10:43:11.578945Z","shell.execute_reply":"2025-04-19T10:43:11.584902Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Dataset():\n    def __init__(self, data):\n        self.data = []\n        for jobtitle, skill, label in data:\n            self.data.append(InputExample(texts = [jobtitle, skill], label=label))\n\n    def __len__(self) -> int:\n        \"\"\"Trả về số lượng mẫu trong dataset.\"\"\"\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n    @staticmethod\n    def load_train_data(train_path, train_data = None):\n        if train_data is None:\n            train_df = utils.read_csv(train_path)\n        else: \n            train_df = train_data\n        jobtitles =  train_df['jobtitle'].tolist()\n        skills =  train_df['skill'].tolist()\n        labels = train_df['label'].tolist()\n\n        data = []\n        for idx, jobtitle in enumerate(jobtitles):\n            data.append((jobtitle, skills[idx], labels[idx]))\n        return data\n        \n    @staticmethod  \n    def load_inference_data(corpus_path, queries_path):\n        corpus_df = utils.read_csv(corpus_path)\n        queries_df = utils.read_csv(queries_path)\n        \n        cids_l = corpus_df['c_id'].tolist()\n        corpus_l = corpus_df['jobtitle'].tolist()\n        qids_l = queries_df['q_id'].tolist()\n        queries_l = queries_df['jobtitle'].tolist()\n\n        corpus = {\"cid\": cids_l,\n                \"jobtitle\": corpus_l\n                }\n\n        queries = {\"qid\": qids_l,\n                \"jobtitle\": queries_l\n                }\n        return corpus, queries","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:47:43.517349Z","iopub.execute_input":"2025-04-19T10:47:43.517696Z","iopub.status.idle":"2025-04-19T10:47:43.525621Z","shell.execute_reply.started":"2025-04-19T10:47:43.517668Z","shell.execute_reply":"2025-04-19T10:47:43.524643Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# BiEncoder","metadata":{}},{"cell_type":"code","source":"class BiEncoder:\n    def __init__(self, model_name=None, model_path=None):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(\"Device sử dụng:\", device)\n        \n        try:\n            if model_path is None:\n                print(f\"Tải mô hình từ Hugging Face với tên: {model_name}\")\n                self.model = SentenceTransformer(model_name)\n            else:\n                print(f\"Tải mô hình từ đường dẫn cục bộ: {model_path}\")\n                self.model = SentenceTransformer(model_path)\n            \n            # Đặt mô hình lên thiết bị\n            self.model = self.model.to(device)\n            print(\"Mô hình đã được khởi tạo thành công!\")\n        \n        except Exception as e:\n            print(f\"Lỗi khi khởi tạo mô hình: {e}\")\n            raise","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.161388Z","iopub.execute_input":"2025-04-19T10:29:52.161669Z","iopub.status.idle":"2025-04-19T10:29:52.179488Z","shell.execute_reply.started":"2025-04-19T10:29:52.161644Z","shell.execute_reply":"2025-04-19T10:29:52.178778Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# BiTrainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model_name, model_path=None):\n        self.bi_encoder = BiEncoder(model_name, model_path)\n\n    def train(self, dataset, loss, params):\n        print(\"Khởi tạo dataset:\")\n        train_dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n\n        print(\"Bắt đầu train: \")\n\n         # Khởi tạo hàm mất mát\n        train_loss = loss(self.bi_encoder.model)\n        \n        # Tạo thư mục nếu chưa có\n        os.makedirs(params['output_path'], exist_ok=True)\n        \n        # Huấn luyện với callback\n        self.bi_encoder.model.fit(\n            train_objectives=[(train_dataloader, train_loss)],\n            epochs=params['num_epochs'],\n            warmup_steps=params['warmup_steps'],\n            output_path=params[\"output_path\"],\n            show_progress_bar=True\n        )\n\n        return self.bi_encoder.model","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:45:01.395019Z","iopub.execute_input":"2025-04-19T12:45:01.395384Z","iopub.status.idle":"2025-04-19T12:45:01.402518Z","shell.execute_reply.started":"2025-04-19T12:45:01.395357Z","shell.execute_reply":"2025-04-19T12:45:01.401474Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"class Inference:\n    def __init__(self, model):\n        self.model = model\n\n    def embed(self, texts):\n        print(\"Bắt đầu chạy embeddings...\")\n        texts_embedding = self.model.encode(texts)\n        texts_embedding = torch.tensor(texts_embedding)\n\n        return texts_embedding\n\n    def infer(self, corpus, queries):    \n        class SimilarityModel(nn.Module):\n            def __init__(self, corpus_embeddings, corpus_cids):\n                super(SimilarityModel, self).__init__()\n                self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n                self.corpus_cids = corpus_cids              # List of CIDs\n        \n            def forward(self, question_embedding):\n                # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n                question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n                \n                # Compute cosine similarity\n                similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n                similarities[similarities == 1] = float('-inf')\n\n                # Get the top_n indices with the highest cosine similarity values\n                sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n                \n                \n                # Return top_n_ids, sorted similarities, and sorted indices\n                return sorted_similarities, sorted_indices\n                \n        # Example device setup\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n\n        # Initialize the similarity model\n        corpus_embeddings = corpus[\"embedding\"].to(device)\n        cids = corpus['cid']\n\n        query_embeddings = queries['embedding'].to(device)\n        qids = queries['qid']\n        \n        similarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\n        if torch.cuda.device_count() > 1:\n            similarity_model = nn.DataParallel(similarity_model)\n\n        self.predictions = []\n        for qid, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"Processing queries\"):\n            # Convert question_embedding to tensor and move to the device\n            query_embedding = query_embedding.to(device)\n            \n            # Get the top_n most relevant CIDs\n            sorted_similarities, sorted_indices = similarity_model(query_embedding)\n            results = []\n            for idx in range(len(sorted_similarities)):\n                doc_id = sorted_indices[idx].item()\n                score = sorted_similarities[idx].item()\n                rank = idx\n                row = (qid + 1, \"Q0\", doc_id + 1, rank + 1, score, \"4Huiter\")\n                results.append(row)\n            self.predictions.append(results)\n        return self.predictions\n","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.202667Z","iopub.execute_input":"2025-04-19T10:29:52.202914Z","iopub.status.idle":"2025-04-19T10:29:52.217901Z","shell.execute_reply.started":"2025-04-19T10:29:52.202883Z","shell.execute_reply":"2025-04-19T10:29:52.217035Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# RetrievalApp","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\nfrom datetime import datetime\n\nclass RetrievalApp:\n    def __init__(self, model_name, model_path=None):\n        self.model = BiEncoder(model_name, model_path).model\n        print(\"Load mô hình.....\")\n        self.model_name = model_name\n        self.model_path = model_path\n    \n    def prepare_data(self, data_file):\n        \"\"\"\n        Chuẩn bị dữ liệu: chuẩn bị các corpus và queries cho từng ngôn ngữ.\n        \"\"\"\n        print(\"Chuẩn bị data: ......\")\n        preparer = DataPreparer()\n        corpus_file = dict()\n        queries_file = dict()\n        langs = list(data_file['corpus'].keys())\n        \n        for lang in langs:\n            print(f\"Chuẩn bị data {lang}:.....\")\n            corpus_file_org = data_file['corpus'][lang]\n            queries_file_org = data_file['queries'][lang]\n            corpus_file[lang], queries_file[lang] = preparer.prepare_inference_data(corpus_file_org, queries_file_org, lang)\n        \n        return langs, corpus_file, queries_file\n\n    def inference(self, langs, corpus_file, queries_file):\n        \"\"\"\n        Thực hiện inference cho từng ngôn ngữ.\n        \"\"\"\n        print(\"Bắt đầu inference.....\")\n        corpus, queries = dict(), dict()\n        for lang in langs:\n            print(f\"Load data {lang}:.....\")\n            corpus_file_cur = corpus_file[lang]\n            queries_file_cur = queries_file[lang]\n            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n\n        inferencer = Inference(self.model)\n        for lang in langs:\n            print(f\"Inference {lang}:.....\")\n            corpus_cur, queries_cur = corpus[lang], queries[lang]\n            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n\n        return corpus, queries, inferencer\n\n    def predict(self, langs, corpus, queries, inferencer):\n        \"\"\"\n        Thực hiện dự đoán.\n        \"\"\"\n        print(\"Bắt đầu dự đoán:.....\")\n        predictions = dict()\n        for lang in langs:\n            print(f\"Dự đoán {lang}:.....\")\n            corpus_cur, queries_cur = corpus[lang], queries[lang] \n            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n\n        return predictions\n\n    def zip_directory(self, zip_filename, dir_name):\n        \"\"\"\n        Nén thư mục thành file zip mà không sử dụng đa luồng.\n        \"\"\"\n        print(f\"Đang nén thư mục {dir_name} thành {zip_filename}...\")\n        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            # Duyệt qua tất cả các file trong thư mục và nén chúng tuần tự\n            for root, dirs, files in os.walk(dir_name):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, dir_name)  # Lưu lại cấu trúc thư mục gốc\n                    zipf.write(file_path, arcname)\n\n        print(f\"File zip đã được tạo: {zip_filename}\")\n\n    def save_predictions(self, langs, predictions):\n        \"\"\"\n        Lưu kết quả dự đoán vào file và nén thư mục.\n        \"\"\"\n        print(\"Bắt đầu xuất file:....\")\n        predictions_file = dict()\n        folder_name = f\"/kaggle/working/talent_clef/predict/{self.model_name}/{Timer.get()}\"\n        os.makedirs(folder_name, exist_ok=True)\n        for lang in langs:\n            predictions_file[lang] = utils.write_predictions(predictions[lang], folder_name, lang)\n        \n        # Nén thư mục sau khi xuất file\n        zip_filename = folder_name + \".zip\"\n        self.zip_directory(zip_filename, folder_name)\n        \n        return predictions_file, zip_filename\n\n    def evaluate(self, langs, predictions_file, data):\n        \"\"\"\n        Đánh giá kết quả dự đoán.\n        \"\"\"\n        print(\"Bắt đầu đánh giá:.....\")\n        ratings = dict()\n        for lang in langs:\n            print(f\"Đánh giá {lang}:.....\")\n            run_file, qrels_file = predictions_file[lang], data['qrels'][lang]\n            ratings[lang] = Evaluate.evaluate(run_file, qrels_file)\n        return ratings\n\n    def __call__(self, data_file):\n        \"\"\"\n        Nối các hàm lại với nhau và chạy toàn bộ quy trình.\n        \"\"\"\n        langs, corpus_file, queries_file = self.prepare_data(data_file)\n        corpus, queries, inferencer = self.inference(langs, corpus_file, queries_file)\n        predictions = self.predict(langs, corpus, queries, inferencer)\n        predictions_file, zip_filename = self.save_predictions(langs, predictions)\n        ratings = self.evaluate(langs, predictions_file, data_file)\n        return ratings","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:27:52.950133Z","iopub.execute_input":"2025-04-19T12:27:52.950487Z","iopub.status.idle":"2025-04-19T12:27:52.965590Z","shell.execute_reply.started":"2025-04-19T12:27:52.950453Z","shell.execute_reply":"2025-04-19T12:27:52.964899Z"},"trusted":true},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"# SetupEnvironment","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\ndef load_git_workspace_wandb():\n    user_secrets = UserSecretsClient()\n    git_token = user_secrets.get_secret(\"github\")\n    wandp_api = user_secrets.get_secret(\"wandb\")\n\n    import subprocess\n\n    # Thay {git_token} bằng token thực tế của bạn\n    repo_url = f\"https://hoivd:{git_token}@github.com/hoivd/talent_clef\"\n    \n    # Lệnh git clone\n    command = [\"git\", \"clone\", repo_url]\n    \n    try:\n        # Chạy lệnh và đợi hoàn tất\n        result = subprocess.run(command, check=True, text=True, capture_output=True)\n        print(\"Clone thành công!\")\n        print(\"Stdout:\", result.stdout)  # In stdout nếu có\n        print(\"Stderr:\", result.stderr)  # In stderr để thấy tiến trình\n    except subprocess.CalledProcessError as e:\n        print(\"Lỗi khi clone repository:\")\n        print(e.stderr)  # In thông báo lỗi nếu có\n        # Đăng nhập W&B\n    \n    wandb.login(key=wandp_api)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.242026Z","iopub.execute_input":"2025-04-19T10:29:52.242213Z","iopub.status.idle":"2025-04-19T10:29:52.261893Z","shell.execute_reply.started":"2025-04-19T10:29:52.242195Z","shell.execute_reply":"2025-04-19T10:29:52.261249Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class utils:\n    @staticmethod\n    def read_csv(input_path, columns=None):\n        print(\"Đọc csv file:\")\n        # Kiểm tra input_path ngay từ đầu\n        if input_path is None:\n            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file CSV.\")\n        \n        try:  \n            if columns is None:\n                df = pd.read_csv(input_path, encoding='utf-8')\n            else:\n                df = pd.read_csv(input_path, encoding='utf-8', names=columns)\n            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n            return df\n        except Exception as e:\n            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n            raise\n\n\n    @staticmethod\n    def read_tsv(input_path, columns=None):\n        print(\"Đọc tsv file:\")\n        # Kiểm tra input_path ngay từ đầu\n        if input_path is None:\n            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file TSV.\")\n        \n        try:  \n            df = None\n            if columns is None:\n                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')  # Thêm sep='\\t' cho TSV\n            else:\n                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8', names=columns)\n            \n            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n            print(df.head())\n            return df\n        except Exception as e:\n            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n            raise\n\n    @staticmethod\n    def write_csv(df, output_path):\n        try:\n            # Xuất ra file CSV\n            df.to_csv(output_path, sep=',', encoding='utf-8', index=False)\n            print(f\"Đã xuất dữ liệu ra {output_path}\")\n        except Exception as e:\n            print(f\"Lỗi khi xuất file CSV: {e}\")\n            raise\n        return output_path\n\n    @staticmethod\n    def write_predictions(predictions, folder_name, lang):\n        \n        output_path = f\"{folder_name}/run_{lang}.trec\"\n        try:\n            with open(output_path, 'w', encoding='utf-8') as f:\n                for query_predict in predictions: \n                    for line in query_predict:  # rank bắt đầu từ 1\n                        f.write(' '.join(str(x) for x in line) + '\\n')\n            print(f\"Đã xuất file TREC ra {output_path}\")  \n            return output_path\n        \n        except Exception as e:\n            print(f\"Lỗi khi xuất file TREC: {e}\")\n            raise\n\n        return output_path","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.262623Z","iopub.execute_input":"2025-04-19T10:29:52.262848Z","iopub.status.idle":"2025-04-19T10:29:52.281339Z","shell.execute_reply.started":"2025-04-19T10:29:52.262804Z","shell.execute_reply":"2025-04-19T10:29:52.280514Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"class Evaluate:\n    @staticmethod\n    def evaluate(predictions_path, qrels_path):\n        command = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_path, \"--run\", predictions_path]\n        result = subprocess.run(command, capture_output=True, text=True)\n        print(result.stdout)\n\n        return Evaluate.extract_metrics(result)\n        \n    @staticmethod\n    def extract_metrics(result, language=\"en-en\"):\n        stdout = result.stdout\n        map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n        mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n        ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n        precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n        precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n        precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n    \n        metrics = {\n            \"map\": map_value,\n            \"mrr\": mrr,\n            \"ndcg\": ndcg,\n            \"precision@5\": precision_5,\n            \"precision@10\": precision_10,\n            \"precision@100\": precision_100\n        }\n        return metrics     ","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.282218Z","iopub.execute_input":"2025-04-19T10:29:52.282503Z","iopub.status.idle":"2025-04-19T10:29:52.301485Z","shell.execute_reply.started":"2025-04-19T10:29:52.282473Z","shell.execute_reply":"2025-04-19T10:29:52.300605Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Timer","metadata":{}},{"cell_type":"code","source":"class Timer:\n    @staticmethod\n    def get():\n        # Lấy múi giờ Việt Nam (UTC+7)\n        vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n        \n        # Lấy thời gian hiện tại ở UTC\n        utc_now = datetime.now(pytz.utc)\n        \n        # Chuyển thời gian UTC sang múi giờ Việt Nam\n        vietnam_time = utc_now.astimezone(vietnam_timezone)\n        \n        # Trả về thời gian đã định dạng theo kiểu YYYY-MM-DD HH:MM:SS\n        return vietnam_time.strftime(\"%m-%d_%H-%M-%S\")\n\n# Gọi hàm và in kết quả\nprint(Timer.get())","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.303390Z","iopub.execute_input":"2025-04-19T10:29:52.303617Z","iopub.status.idle":"2025-04-19T10:29:52.352188Z","shell.execute_reply.started":"2025-04-19T10:29:52.303597Z","shell.execute_reply":"2025-04-19T10:29:52.351353Z"},"trusted":true},"outputs":[{"name":"stdout","text":"04-19_17-29-52\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# ModelLogger","metadata":{}},{"cell_type":"code","source":"class ModelLogger:\n    def __init__(self, model_name, loss_function, num_epochs, metrics, notes=\"\", training_time=None,\n                 folder=\"/kaggle/working/talent_clef/results\", file_name=f\"{Timer.get()}.csv\"):\n        self.model_name = model_name\n        self.loss = loss_function\n        self.epochs = num_epochs\n        self.metrics = metrics\n        self.notes = notes\n        self.training_time = training_time\n        self.folder = folder\n        self.file_path = os.path.join(folder, file_name)\n    \n    def compute_average_map(self):\n        map_values = [lang['map'] for lang in self.metrics.values() if 'map' in lang]\n        return sum(map_values) / len(map_values) if map_values else None\n\n    def to_dict(self):\n        return {\n            \"model_name\": [self.model_name],\n            \"Avg result\": [self.compute_average_map()],\n            \"en-en result\": [self.metrics.get(\"en-en\", \"\")],\n            \"es-es result\": [self.metrics.get(\"es-es\", \"\")],\n            \"de-de result\": [self.metrics.get(\"de-de\", \"\")],\n            \"zh-zh result\": [self.metrics.get(\"zh-zh\", \"\")],\n            \"en-es result\": [self.metrics.get(\"en-es\", \"\")],\n            \"en-de result\": [self.metrics.get(\"en-de\", \"\")],\n            \"en-zh result\": [self.metrics.get(\"en-zh\", \"\")],\n            \"loss\": [self.loss],\n            \"epochs\": [self.epochs],\n            \"training_time (s)\": [self.training_time],\n            \"date\": [Timer.get()],\n            \"notes\": [self.notes]\n        }\n\n    def save(self):\n        # Tạo thư mục nếu chưa tồn tại\n        os.makedirs(self.folder, exist_ok=True)\n\n        # Tạo DataFrame từ dict\n        df_new = pd.DataFrame(self.to_dict())\n\n        if os.path.exists(self.file_path):\n            df_existing = pd.read_csv(self.file_path)\n            df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n            df_updated.to_csv(self.file_path, index=False)\n            print(f\"✅ Đã thêm dữ liệu vào file: {self.file_path}\")\n        else:\n            df_new.to_csv(self.file_path, index=False)\n            print(f\"✅ Đã tạo file mới: {self.file_path}\")\n\n    def show_log(self):\n        if os.path.exists(self.file_path):\n            print(f\"\\n📄 Nội dung file log:\")\n            log_df = utils.read_csv(self.file_path)\n            print(log_df)\n        else:\n            print(\"⚠️ Chưa có file log để hiển thị.\")","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.353066Z","iopub.execute_input":"2025-04-19T10:29:52.353280Z","iopub.status.idle":"2025-04-19T10:29:52.362281Z","shell.execute_reply.started":"2025-04-19T10:29:52.353259Z","shell.execute_reply":"2025-04-19T10:29:52.361339Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Hàm thực thi","metadata":{}},{"cell_type":"markdown","source":"## 1. Clone data","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhuggingface_api = user_secrets.get_secret(\"huggingface\")\n\n!huggingface-cli login --token {huggingface_api}\n!git clone https://huggingface.co/hoivinh20789/talent_clef /kaggle/working/models\nload_git_workspace_wandb()\n\n!git clone https://github.com/TalentCLEF/talentclef25_evaluation_script.git\n!pip install -r \"/kaggle/working/talentclef25_evaluation_script/requirements.txt\"","metadata":{"collapsed":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:21.116062Z","iopub.execute_input":"2025-04-19T12:26:21.116463Z","iopub.status.idle":"2025-04-19T12:26:35.957878Z","shell.execute_reply.started":"2025-04-19T12:26:21.116429Z","shell.execute_reply":"2025-04-19T12:26:35.956615Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nThe token `kaggle` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `kaggle`\nfatal: destination path '/kaggle/working/models' already exists and is not an empty directory.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Lỗi khi clone repository:\nfatal: destination path 'talent_clef' already exists and is not an empty directory.\n\nCloning into 'talentclef25_evaluation_script'...\nremote: Enumerating objects: 27, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 27 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (27/27), 10.10 KiB | 3.37 MiB/s, done.\nResolving deltas: 100% (10/10), done.\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.2.3)\nCollecting ranx (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.60.0)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.67.1)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.13.1)\nCollecting ir-datasets (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (13.9.4)\nRequirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10.12)\nCollecting lz4 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting cbor2 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.2)\nCollecting fastparquet (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54.1->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.17.0)\nCollecting cramjam>=2.3 (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2024.12.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (24.2)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.3)\nCollecting inscriptis>=2.2.0 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (5.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (6.0.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.32.3)\nCollecting trec-car-tools>=2.5.4 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\nCollecting warc3-wet>=0.2.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/warc3-wet-clueweb09/\u001b[0m\u001b[33m\n\u001b[0mCollecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting zlib-state>=0.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting ijson>=3.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting unlzw3>=0.2.1 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (19.0.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.19.1)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.2)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.7.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.6)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.1.31)\nCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor-1.0.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nDownloading ranx-0.3.20-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\nDownloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\nDownloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\nDownloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nBuilding wheels for collected packages: warc3-wet-clueweb09, cbor\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=b7fd2e0ec444ef72f60ff3e398f81fe71fc7a8b47b232811c091c7b01ea87a61\n  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53428 sha256=ffe4ddd3cef248e36f9334817a09a92c2d389b218758c90b872c56dbb23cb164\n  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\nSuccessfully built warc3-wet-clueweb09 cbor\nInstalling collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, cramjam, cbor2, inscriptis, trec-car-tools, ir-datasets, fastparquet, ranx\nSuccessfully installed cbor-1.0.0 cbor2-5.6.5 cramjam-2.10.0 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"## 3. Training","metadata":{}},{"cell_type":"code","source":"source_file = \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"\nneg_pair_file = \"/kaggle/working/talent_clef/data/hard_neg_mining/neg_example.csv\"\npreparer = DataPreparer()\ntrain_df, train_file = preparer.prepare_train_data(neg_pair_file, source_file)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:48:44.590677Z","iopub.execute_input":"2025-04-19T10:48:44.591031Z","iopub.status.idle":"2025-04-19T10:49:46.824992Z","shell.execute_reply.started":"2025-04-19T10:48:44.590998Z","shell.execute_reply":"2025-04-19T10:49:46.823903Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Đọc dữ liệu train_org:\n                       jobtitle  \\\n0    director of technical arts   \n0          technical supervisor   \n0             technical manager   \n0  head of technical department   \n0            technical director   \n\n                                               skill  label  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n                     jobtitle  \\\n0  director of technical arts   \n1  director of technical arts   \n2  director of technical arts   \n3  director of technical arts   \n4  director of technical arts   \n\n                                               skill  label  \n0  Overview: This comprehensive overview of skill...      0  \n1  Overview: The skills essential for success inc...      0  \n2  Overview: The skills essential for success inc...      0  \n3  Overview: The skills essential for success inc...      0  \n4  Overview: The performing arts encompass a wide...      0  \n                       jobtitle  \\\n0    director of technical arts   \n0          technical supervisor   \n0             technical manager   \n0  head of technical department   \n0            technical director   \n\n                                               skill  label  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \nCột dữ liệu: Index(['jobtitle', 'skill', 'label'], dtype='object')\nXuất dữ liệu train sau khi chuẩn bị:\nĐã xuất dữ liệu ra /kaggle/working/train.csv\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"train_data = Dataset.load_train_data(train_file, train_df)\ndataset = Dataset(train_data)\n\nmodel_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\nmodel_path = '/kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6'\nloss = losses.MultipleNegativesRankingLoss\ndetail = \"hard_neg_pair_epoch2\"\nparams = {\n    \"num_epochs\": 2,\n    \"output_path\": f\"/kaggle/working/models/{model_name}/{detail}\",\n    \"warmup_steps\": 100,\n}\n\ntrainer = Trainer(model_name, model_path)\nmodel, model_path = trainer.train(dataset.data, loss, params)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:53:47.321487Z","iopub.execute_input":"2025-04-19T10:53:47.321807Z","iopub.status.idle":"2025-04-19T12:02:53.601794Z","shell.execute_reply.started":"2025-04-19T10:53:47.321773Z","shell.execute_reply":"2025-04-19T12:02:53.600803Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device sử dụng: cuda\nTải mô hình từ đường dẫn cục bộ: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6\nMô hình đã được khởi tạo thành công!\nKhởi tạo dataset:\nBắt đầu train: \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='21084' max='21084' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [21084/21084 1:08:25, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.739400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.628800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.573700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.581300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.583600</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.536500</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.536500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.509400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.488700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.487100</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.480900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.479400</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.466900</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.456700</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.464100</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.437500</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.447800</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.436400</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.406200</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.403900</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.424300</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.349600</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.350000</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.333900</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.338700</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.344500</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.333800</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.348300</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.337900</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.337900</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.330300</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.308000</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.327800</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.326700</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.321300</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.310800</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.316000</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.299700</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.316600</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.296800</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>0.303300</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.305200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":50},{"cell_type":"markdown","source":"# Push Model","metadata":{}},{"cell_type":"code","source":"repo_id = \"hoivinh20789/talent_clef\"  # Đường dẫn tới repo của bạn trên Hugging Face\nfolder_path = params['output_path']  # Đường dẫn tới thư mục chứa mô hình của bạn\ntarget_folder = f\"{model_name}/{detail}\"  # Thư mục con mà bạn muốn đẩy mô hình vào trong repo\n\napi = HfApi()\n\n# Đẩy model vào thư mục 'model' trong repository\napi.upload_folder(\n    repo_id=repo_id,\n    folder_path=folder_path,  # Thư mục chứa các file model\n    path_in_repo=target_folder,  # Thư mục con 'model' trong repo\n    commit_message=\"Upload model version 1\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:40:25.361937Z","iopub.execute_input":"2025-04-19T12:40:25.362301Z","iopub.status.idle":"2025-04-19T12:40:37.460540Z","shell.execute_reply.started":"2025-04-19T12:40:25.362273Z","shell.execute_reply":"2025-04-19T12:40:37.459797Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5d41d8930924a338bc223c91abecdfd"}},"metadata":{}},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hoivinh20789/talent_clef/commit/0cdddb44f127b717f763c9a3907c9aae9750f009', commit_message='Upload model version 1', commit_description='', oid='0cdddb44f127b717f763c9a3907c9aae9750f009', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hoivinh20789/talent_clef', endpoint='https://huggingface.co', repo_type='model', repo_id='hoivinh20789/talent_clef'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":68},{"cell_type":"markdown","source":"## RetrievalApp","metadata":{}},{"cell_type":"code","source":"data = {\n    \"corpus\": {\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements\"\n    },\n    \n    \"queries\":{\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/queries\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/queries\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/queries\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/queries\"\n    },\n    \n    \"qrels\": {\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\"\n    }\n}\n\nmodel_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\napp = RetrievalApp(model_name, params['output_path'])\nratings = app(data)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:48:25.203583Z","iopub.execute_input":"2025-04-19T12:48:25.203966Z","iopub.status.idle":"2025-04-19T12:50:33.952860Z","shell.execute_reply.started":"2025-04-19T12:48:25.203930Z","shell.execute_reply":"2025-04-19T12:50:33.952049Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device sử dụng: cuda\nTải mô hình từ đường dẫn cục bộ: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/hard_neg_pair_epoch2\nMô hình đã được khởi tạo thành công!\nLoad mô hình.....\nChuẩn bị data: ......\nChuẩn bị data en-en:.....\nĐọc dữ liệu inference:\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements thành công\n   c_id                          jobtitle\n0     1                recording engineer\n1     2              director of taxation\n2     3  technical support representative\n3     4                        hr manager\n4     5           computer graphic artist\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/english/queries thành công\n   q_id             jobtitle\n0     1                nanny\n1     2    food technologist\n2     3   broadcast engineer\n3     4  automation engineer\n4     5         veterinarian\nXuất dữ liệu inference:\nĐã xuất dữ liệu ra /kaggle/working/corpus_en-en.csv\nĐã xuất dữ liệu ra /kaggle/working/queries_en-en.csv\nChuẩn bị data de-de:.....\nĐọc dữ liệu inference:\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements thành công\n   c_id                   jobtitle\n0     1               pr-managerin\n1     2       talkshow-moderatorin\n2     3             sporttrainerin\n3     4         preiskoordinatorin\n4     5  persönlicher bankberater\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/german/queries thành công\n   q_id                        jobtitle\n0     1           technischer recruiter\n1     2                    briefträger\n2     3              grundschullehrerin\n3     4                     3d-animator\n4     5  unternehmensstrategieberaterin\nXuất dữ liệu inference:\nĐã xuất dữ liệu ra /kaggle/working/corpus_de-de.csv\nĐã xuất dữ liệu ra /kaggle/working/queries_de-de.csv\nChuẩn bị data es-es:.....\nĐọc dữ liệu inference:\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements thành công\n   c_id                         jobtitle\n0     1               desarrollador java\n1     2         diseñadora de accesorios\n2     3  agente inmobiliario residencial\n3     4           planificador de ventas\n4     5          ayudante de conferencia\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/spanish/queries thành công\n   q_id                        jobtitle\n0     1     ingeniera de automatización\n1     2  técnica de soporte informático\n2     3                 piloto de avión\n3     4   ingeniera de diseño analógico\n4     5      analista de capital riesgo\nXuất dữ liệu inference:\nĐã xuất dữ liệu ra /kaggle/working/corpus_es-es.csv\nĐã xuất dữ liệu ra /kaggle/working/queries_es-es.csv\nChuẩn bị data zh-zh:.....\nĐọc dữ liệu inference:\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements thành công\n   c_id jobtitle\n0     1   自动化技术员\n1     2    选角制作人\n2     3     体育经理\n3     4     临时助理\n4     5  用户支持技术员\nĐọc tsv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/chinese/queries thành công\n   q_id jobtitle\n0     1     贷款干事\n1     2     税务会计\n2     3    犬类美容师\n3     4      收银员\n4     5      筹款人\nXuất dữ liệu inference:\nĐã xuất dữ liệu ra /kaggle/working/corpus_zh-zh.csv\nĐã xuất dữ liệu ra /kaggle/working/queries_zh-zh.csv\nBắt đầu inference.....\nLoad data en-en:.....\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/corpus_en-en.csv thành công\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/queries_en-en.csv thành công\nLoad data de-de:.....\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/corpus_de-de.csv thành công\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/queries_de-de.csv thành công\nLoad data es-es:.....\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/corpus_es-es.csv thành công\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/queries_es-es.csv thành công\nLoad data zh-zh:.....\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/corpus_zh-zh.csv thành công\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/queries_zh-zh.csv thành công\nInference en-en:.....\nBắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/82 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ce218707a6e4583b6a630275e6ea61f"}},"metadata":{}},{"name":"stdout","text":"Bắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8179ef950164f448628233e787dd45f"}},"metadata":{}},{"name":"stdout","text":"Inference de-de:.....\nBắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/148 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ed6f61b781457c9f0fe629926e1c75"}},"metadata":{}},{"name":"stdout","text":"Bắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f14dd730f3427c947a174cefdee170"}},"metadata":{}},{"name":"stdout","text":"Inference es-es:.....\nBắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/146 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fffe857c42ff4e4793d503f1a688c777"}},"metadata":{}},{"name":"stdout","text":"Bắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03dabcf3fab14e79a84adc5a3e821508"}},"metadata":{}},{"name":"stdout","text":"Inference zh-zh:.....\nBắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3935fad2f8b4128a9eb70822dee7582"}},"metadata":{}},{"name":"stdout","text":"Bắt đầu chạy embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f758c993ddc466e808a7036bc84b01d"}},"metadata":{}},{"name":"stdout","text":"Bắt đầu dự đoán:.....\nDự đoán en-en:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|██████████| 105/105 [00:07<00:00, 13.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dự đoán de-de:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|██████████| 203/203 [00:27<00:00,  7.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dự đoán es-es:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|██████████| 185/185 [00:25<00:00,  7.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dự đoán zh-zh:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|██████████| 103/103 [00:07<00:00, 13.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Bắt đầu xuất file:....\nĐã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_en-en.trec\nĐã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_de-de.trec\nĐã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_es-es.trec\nĐã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_zh-zh.trec\nĐang nén thư mục /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40 thành /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip...\nFile zip đã được tạo: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip\nBắt đầu đánh giá:.....\nĐánh giá en-en:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_en-en.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.5326\nmrr: 0.8820\nndcg: 0.7985\nprecision@5: 0.7029\nprecision@10: 0.6105\nprecision@100: 0.1740\n\nĐánh giá de-de:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_de-de.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.2950\nmrr: 0.5391\nndcg: 0.6342\nprecision@5: 0.5172\nprecision@10: 0.4808\nprecision@100: 0.1774\n\nĐánh giá es-es:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_es-es.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.4187\nmrr: 0.8443\nndcg: 0.7411\nprecision@5: 0.6757\nprecision@10: 0.5946\nprecision@100: 0.2096\n\nĐánh giá zh-zh:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_zh-zh.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.4537\nmrr: 0.8341\nndcg: 0.7434\nprecision@5: 0.6233\nprecision@10: 0.5223\nprecision@100: 0.1469\n\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"ratings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:50:33.954063Z","iopub.execute_input":"2025-04-19T12:50:33.954290Z","iopub.status.idle":"2025-04-19T12:50:33.960571Z","shell.execute_reply.started":"2025-04-19T12:50:33.954269Z","shell.execute_reply":"2025-04-19T12:50:33.959917Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"{'en-en': {'map': 0.5326,\n  'mrr': 0.882,\n  'ndcg': 0.7985,\n  'precision@5': 0.7029,\n  'precision@10': 0.6105,\n  'precision@100': 0.174},\n 'de-de': {'map': 0.295,\n  'mrr': 0.5391,\n  'ndcg': 0.6342,\n  'precision@5': 0.5172,\n  'precision@10': 0.4808,\n  'precision@100': 0.1774},\n 'es-es': {'map': 0.4187,\n  'mrr': 0.8443,\n  'ndcg': 0.7411,\n  'precision@5': 0.6757,\n  'precision@10': 0.5946,\n  'precision@100': 0.2096},\n 'zh-zh': {'map': 0.4537,\n  'mrr': 0.8341,\n  'ndcg': 0.7434,\n  'precision@5': 0.6233,\n  'precision@10': 0.5223,\n  'precision@100': 0.1469}}"},"metadata":{}}],"execution_count":82},{"cell_type":"markdown","source":"## 5. Log Model","metadata":{}},{"cell_type":"code","source":"logger = ModelLogger(\n    model_name=model_name,\n    loss_function=None,\n    num_epochs=None,\n    metrics=ratings,\n    notes=\"thêm negative pair và finetune tiếp từ epoch 5\"\n)\n\nlogger.save()\nlogger.show_log()","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:33.962081Z","iopub.execute_input":"2025-04-19T12:50:33.962291Z","iopub.status.idle":"2025-04-19T12:50:33.997547Z","shell.execute_reply.started":"2025-04-19T12:50:33.962271Z","shell.execute_reply":"2025-04-19T12:50:33.996545Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ Đã thêm dữ liệu vào file: /kaggle/working/talent_clef/results/04-19_17-29-52.csv\n\n📄 Nội dung file log:\nĐọc csv file:\nĐọc dữ liệu từ /kaggle/working/talent_clef/results/04-19_17-29-52.csv thành công\n                                          model_name  Avg result  \\\n0  sentence-transformers/paraphrase-multilingual-...       0.425   \n1  sentence-transformers/paraphrase-multilingual-...       0.425   \n2  sentence-transformers/paraphrase-multilingual-...       0.425   \n\n                                        en-en result  \\\n0  {'map': 0.5326, 'mrr': 0.882, 'ndcg': 0.7985, ...   \n1  {'map': 0.5326, 'mrr': 0.882, 'ndcg': 0.7985, ...   \n2  {'map': 0.5326, 'mrr': 0.882, 'ndcg': 0.7985, ...   \n\n                                        es-es result  \\\n0  {'map': 0.4187, 'mrr': 0.8443, 'ndcg': 0.7411,...   \n1  {'map': 0.4187, 'mrr': 0.8443, 'ndcg': 0.7411,...   \n2  {'map': 0.4187, 'mrr': 0.8443, 'ndcg': 0.7411,...   \n\n                                        de-de result  \\\n0  {'map': 0.295, 'mrr': 0.5391, 'ndcg': 0.6342, ...   \n1  {'map': 0.295, 'mrr': 0.5391, 'ndcg': 0.6342, ...   \n2  {'map': 0.295, 'mrr': 0.5391, 'ndcg': 0.6342, ...   \n\n                                        zh-zh result  en-es result  \\\n0  {'map': 0.4537, 'mrr': 0.8341, 'ndcg': 0.7434,...           NaN   \n1  {'map': 0.4537, 'mrr': 0.8341, 'ndcg': 0.7434,...           NaN   \n2  {'map': 0.4537, 'mrr': 0.8341, 'ndcg': 0.7434,...           NaN   \n\n   en-de result  en-zh result  loss  epochs  training_time (s)  \\\n0           NaN           NaN   NaN     NaN                NaN   \n1           NaN           NaN   NaN     NaN                NaN   \n2           NaN           NaN   NaN     NaN                NaN   \n\n             date                                           notes  \n0  04-19_19-33-17  thêm negative pair và finetune tiếp từ epoch 5  \n1  04-19_19-47-26  thêm negative pair và finetune tiếp từ epoch 5  \n2  04-19_19-50-33  thêm negative pair và finetune tiếp từ epoch 5  \n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"# Git Push","metadata":{}},{"cell_type":"code","source":"cd talent_clef","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:33.998940Z","iopub.execute_input":"2025-04-19T12:50:33.999222Z","iopub.status.idle":"2025-04-19T12:50:34.005023Z","shell.execute_reply.started":"2025-04-19T12:50:33.999197Z","shell.execute_reply":"2025-04-19T12:50:34.004187Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/talent_clef\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"brand_name = model_name + \"/\" +Timer.get()","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:34.005930Z","iopub.execute_input":"2025-04-19T12:50:34.006182Z","iopub.status.idle":"2025-04-19T12:50:34.018101Z","shell.execute_reply.started":"2025-04-19T12:50:34.006159Z","shell.execute_reply":"2025-04-19T12:50:34.017328Z"},"trusted":true},"outputs":[],"execution_count":85},{"cell_type":"code","source":"brand_name","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:34.018770Z","iopub.execute_input":"2025-04-19T12:50:34.019029Z","iopub.status.idle":"2025-04-19T12:50:34.033892Z","shell.execute_reply.started":"2025-04-19T12:50:34.018997Z","shell.execute_reply":"2025-04-19T12:50:34.033242Z"},"trusted":true},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34'"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"!git config --global user.email \"hoivd79@gmail.com\"\n!git config --global user.name \"Dang Vinh Hoi\"\n!git checkout -b {brand_name}      # Tạo và chuyển sang nhánh dev\n!git status\n!git add .\n!git commit -m \"updated\"\n!git push -u origin {brand_name}    # Push lần đầu, thiết lập tracking","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:34.034869Z","iopub.execute_input":"2025-04-19T12:50:34.035083Z","iopub.status.idle":"2025-04-19T12:50:41.887724Z","shell.execute_reply.started":"2025-04-19T12:50:34.035063Z","shell.execute_reply":"2025-04-19T12:50:41.886722Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Switched to a new branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34'\nOn branch sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\t\u001b[31mmodified:   results/04-19_17-29-52.csv\u001b[m\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\t\u001b[31mpredict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip\u001b[m\n\t\u001b[31mpredict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/\u001b[m\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n[sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34 25ab1e2] updated\n 6 files changed, 2356107 insertions(+)\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_de-de.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_en-en.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_es-es.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_zh-zh.trec\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 4 threads\nCompressing objects: 100% (8/8), done.\nWriting objects: 100% (8/8), 32.58 MiB | 21.03 MiB/s, done.\nTotal 8 (delta 5), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\nremote: \nremote: Create a pull request for 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34' on GitHub by visiting:\u001b[K\nremote:      https://github.com/hoivd/talent_clef/pull/new/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34\u001b[K\nremote: \nTo https://github.com/hoivd/talent_clef\n * [new branch]      sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34 -> sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34\nBranch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34' set up to track remote branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34' from 'origin'.\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"cd ..\n","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:41.889819Z","iopub.execute_input":"2025-04-19T12:50:41.890112Z","iopub.status.idle":"2025-04-19T12:50:41.897554Z","shell.execute_reply.started":"2025-04-19T12:50:41.890085Z","shell.execute_reply":"2025-04-19T12:50:41.896685Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":88}]}