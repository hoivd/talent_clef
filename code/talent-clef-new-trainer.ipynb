{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torchmetrics.retrieval import RetrievalMAP\nimport os\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport google.generativeai as genai\nimport os\nimport wandb\nimport ast\nimport subprocess\nimport pickle\nimport shutil\nimport datetime\nimport pytz\nfrom huggingface_hub import HfApi, upload_folder\nfrom datetime import datetime\nimport pytz","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-04-19T12:47:11.641058Z","iopub.execute_input":"2025-04-19T12:47:11.641394Z","iopub.status.idle":"2025-04-19T12:47:11.647742Z","shell.execute_reply.started":"2025-04-19T12:47:11.641363Z","shell.execute_reply":"2025-04-19T12:47:11.646916Z"},"trusted":true},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"# PositiveExampleMining","metadata":{}},{"cell_type":"code","source":"class MiningPosExample:\n    def __init__(self):\n        self.data = None  # Khá»Ÿi táº¡o thuá»™c tÃ­nh self.data lÃ  None\n\n     # PhÆ°Æ¡ng thá»©c __len__ Ä‘á»ƒ tráº£ vá» sá»‘ dÃ²ng cá»§a data\n    def __len__(self):\n        if self.data is not None:\n            return len(self.data)\n        return 0  # Náº¿u self.data chÆ°a Ä‘Æ°á»£c gÃ¡n (None), tráº£ vá» 0\n    \n    # PhÆ°Æ¡ng thá»©c __getitem__ Ä‘á»ƒ truy xuáº¥t má»™t dÃ²ng trong data theo chá»‰ sá»‘\n    def __getitem__(self, index):\n        if self.data is not None:\n            return self.data.iloc[index]\n        raise IndexError(\"Index out of range\")  # Náº¿u self.data lÃ  None, raise lá»—i\n        \n    def mining_pos_example(self, data_file):\n        # Äá»c dá»¯ liá»‡u tá»« file (giáº£ sá»­ lÃ  file CSV)\n        df = pd.read_csv(data_file)\n        df['jobtitles'] = df['jobtitles'].apply(ast.literal_eval)\n        # Láº¥y cÃ¡c cá»™t 'jobtitles' vÃ  'skills_gen', sau Ä‘Ã³ \"phÃ¢n ná»•\" danh sÃ¡ch trong cá»™t 'jobtitles'\n        new_df = df[['jobtitles', 'skills_gen']].explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n        \n        # ThÃªm cá»™t 'label' vá»›i giÃ¡ trá»‹ toÃ n bá»™ lÃ  1\n        new_df['label'] = 1\n        \n        # LÆ°u káº¿t quáº£ vÃ o self.data\n        self.data = new_df\n        \n        return new_df\n\n    def get_data(self):\n        return self.data","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:51.972684Z","iopub.execute_input":"2025-04-19T10:29:51.972931Z","iopub.status.idle":"2025-04-19T10:29:51.987692Z","shell.execute_reply.started":"2025-04-19T10:29:51.972909Z","shell.execute_reply":"2025-04-19T10:29:51.986903Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# NegativeExampleMining","metadata":{}},{"cell_type":"code","source":"class MiningNegExample:\n    def __init__(self):\n        self.data = None  # Khá»Ÿi táº¡o thuá»™c tÃ­nh self.data lÃ  None\n    \n     # PhÆ°Æ¡ng thá»©c __len__ Ä‘á»ƒ tráº£ vá» sá»‘ dÃ²ng cá»§a data\n    def __len__(self):\n        if self.data is not None:\n            return len(self.data)\n        return 0  # Náº¿u self.data chÆ°a Ä‘Æ°á»£c gÃ¡n (None), tráº£ vá» 0\n    \n    # PhÆ°Æ¡ng thá»©c __getitem__ Ä‘á»ƒ truy xuáº¥t má»™t dÃ²ng trong data theo chá»‰ sá»‘\n    def __getitem__(self, index):\n        if self.data is not None:\n            return self.data.iloc[index]\n        raise IndexError(\"Index out of range\")  # Náº¿u self.data lÃ  None, raise lá»—i\n\n    def prepare_source_file(self, source_file):\n        source_df = pd.read_csv(source_file)\n        source_df['jobtitles'] = source_df['jobtitles'].apply(ast.literal_eval)\n        # Láº¥y cÃ¡c cá»™t 'jobtitles' vÃ  'skills_gen', sau Ä‘Ã³ \"phÃ¢n ná»•\" danh sÃ¡ch trong cá»™t 'jobtitles'\n        source_df = source_df.explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill', 'tid': 'gid'})\n        source_df = source_df.reset_index(drop=True).reset_index(names='tid')\n\n        return source_df\n        \n    def mining_neg_example(self, pair_file, source_file):\n        # Äá»c dá»¯ liá»‡u tá»« file (giáº£ sá»­ lÃ  file CSV)\n        \n        source_df = self.prepare_source_file(source_file)\n        pair_df = pd.read_csv(pair_file)\n        pair_df = pair_df.merge(source_df, left_on='q_id', right_on='tid')                \n        pair_df = pair_df.merge(source_df, left_on='c_id', right_on='tid')\n        pair_df = pair_df.rename(columns={'jobtitle_x': 'q_jobtitle', 'skill_x': 'q_skill', 'jobtitle_y': 'c_jobtitle', 'skill_y': 'c_skill'})\n        query_pair = pair_df[['q_jobtitle', 'c_skill', 'label']].rename(columns={'q_jobtitle': 'jobtitle', 'c_skill': 'skill'})\n        corpus_pair = pair_df[['c_jobtitle', 'q_skill', 'label']].rename(columns={'c_jobtitle': 'jobtitle', 'q_skill': 'skill'})\n        neg_pair = pd.concat([query_pair, corpus_pair], axis=0)\n\n        self.data = neg_pair\n        return neg_pair\n    \n    def get_data(self):\n        return self.data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T10:29:51.988700Z","iopub.execute_input":"2025-04-19T10:29:51.989015Z","iopub.status.idle":"2025-04-19T10:29:52.007333Z","shell.execute_reply.started":"2025-04-19T10:29:51.988980Z","shell.execute_reply":"2025-04-19T10:29:52.006689Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# DataPrepare","metadata":{}},{"cell_type":"code","source":"class DataPreparer:\n    def prepare_train_data(self, neg_pair_file, source_file):\n        print(\"Äá»c dá»¯ liá»‡u train_org:\")\n        \n        pos_miner = MiningPosExample()\n        pos_df = pos_miner.mining_pos_example(source_file)\n        print(pos_df.head())\n\n        neg_miner = MiningNegExample()\n        neg_df = neg_miner.mining_neg_example(neg_pair_file, source_file)\n        print(neg_df.head())\n\n        train_df = pd.concat([pos_df, neg_df], axis=0)\n        train_df = train_df.drop_duplicates(subset=None, keep='first', inplace=False)\n\n        print(train_df.head())\n        print(f\"Cá»™t dá»¯ liá»‡u: {train_df.columns}\")\n        print(\"Xuáº¥t dá»¯ liá»‡u train sau khi chuáº©n bá»‹:\")\n        train_file = \"/kaggle/working/train.csv\"\n        utils.write_csv(train_df, train_file)\n        return train_df, train_file\n\n    def prepare_inference_data(self, corpus_path, queries_path, lang):\n        print(\"Äá»c dá»¯ liá»‡u inference:\")\n        corpus_df = utils.read_tsv(corpus_path)\n        queries_df = utils.read_tsv(queries_path)\n        \n        print(\"Xuáº¥t dá»¯ liá»‡u inference:\")\n        corpus_out_path = f\"/kaggle/working/corpus_{lang}.csv\"\n        queries_out_path = f\"/kaggle/working/queries_{lang}.csv\"\n        utils.write_csv(corpus_df, corpus_out_path)\n        utils.write_csv(queries_df, queries_out_path)\n        return corpus_out_path, queries_out_path","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:43:11.578579Z","iopub.execute_input":"2025-04-19T10:43:11.578982Z","iopub.status.idle":"2025-04-19T10:43:11.585653Z","shell.execute_reply.started":"2025-04-19T10:43:11.578945Z","shell.execute_reply":"2025-04-19T10:43:11.584902Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Dataset():\n    def __init__(self, data):\n        self.data = []\n        for jobtitle, skill, label in data:\n            self.data.append(InputExample(texts = [jobtitle, skill], label=label))\n\n    def __len__(self) -> int:\n        \"\"\"Tráº£ vá» sá»‘ lÆ°á»£ng máº«u trong dataset.\"\"\"\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n    @staticmethod\n    def load_train_data(train_path, train_data = None):\n        if train_data is None:\n            train_df = utils.read_csv(train_path)\n        else: \n            train_df = train_data\n        jobtitles =  train_df['jobtitle'].tolist()\n        skills =  train_df['skill'].tolist()\n        labels = train_df['label'].tolist()\n\n        data = []\n        for idx, jobtitle in enumerate(jobtitles):\n            data.append((jobtitle, skills[idx], labels[idx]))\n        return data\n        \n    @staticmethod  \n    def load_inference_data(corpus_path, queries_path):\n        corpus_df = utils.read_csv(corpus_path)\n        queries_df = utils.read_csv(queries_path)\n        \n        cids_l = corpus_df['c_id'].tolist()\n        corpus_l = corpus_df['jobtitle'].tolist()\n        qids_l = queries_df['q_id'].tolist()\n        queries_l = queries_df['jobtitle'].tolist()\n\n        corpus = {\"cid\": cids_l,\n                \"jobtitle\": corpus_l\n                }\n\n        queries = {\"qid\": qids_l,\n                \"jobtitle\": queries_l\n                }\n        return corpus, queries","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:47:43.517349Z","iopub.execute_input":"2025-04-19T10:47:43.517696Z","iopub.status.idle":"2025-04-19T10:47:43.525621Z","shell.execute_reply.started":"2025-04-19T10:47:43.517668Z","shell.execute_reply":"2025-04-19T10:47:43.524643Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# BiEncoder","metadata":{}},{"cell_type":"code","source":"class BiEncoder:\n    def __init__(self, model_name=None, model_path=None):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(\"Device sá»­ dá»¥ng:\", device)\n        \n        try:\n            if model_path is None:\n                print(f\"Táº£i mÃ´ hÃ¬nh tá»« Hugging Face vá»›i tÃªn: {model_name}\")\n                self.model = SentenceTransformer(model_name)\n            else:\n                print(f\"Táº£i mÃ´ hÃ¬nh tá»« Ä‘Æ°á»ng dáº«n cá»¥c bá»™: {model_path}\")\n                self.model = SentenceTransformer(model_path)\n            \n            # Äáº·t mÃ´ hÃ¬nh lÃªn thiáº¿t bá»‹\n            self.model = self.model.to(device)\n            print(\"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\")\n        \n        except Exception as e:\n            print(f\"Lá»—i khi khá»Ÿi táº¡o mÃ´ hÃ¬nh: {e}\")\n            raise","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.161388Z","iopub.execute_input":"2025-04-19T10:29:52.161669Z","iopub.status.idle":"2025-04-19T10:29:52.179488Z","shell.execute_reply.started":"2025-04-19T10:29:52.161644Z","shell.execute_reply":"2025-04-19T10:29:52.178778Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# BiTrainer","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model_name, model_path=None):\n        self.bi_encoder = BiEncoder(model_name, model_path)\n\n    def train(self, dataset, loss, params):\n        print(\"Khá»Ÿi táº¡o dataset:\")\n        train_dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n\n        print(\"Báº¯t Ä‘áº§u train: \")\n\n         # Khá»Ÿi táº¡o hÃ m máº¥t mÃ¡t\n        train_loss = loss(self.bi_encoder.model)\n        \n        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³\n        os.makedirs(params['output_path'], exist_ok=True)\n        \n        # Huáº¥n luyá»‡n vá»›i callback\n        self.bi_encoder.model.fit(\n            train_objectives=[(train_dataloader, train_loss)],\n            epochs=params['num_epochs'],\n            warmup_steps=params['warmup_steps'],\n            output_path=params[\"output_path\"],\n            show_progress_bar=True\n        )\n\n        return self.bi_encoder.model","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:45:01.395019Z","iopub.execute_input":"2025-04-19T12:45:01.395384Z","iopub.status.idle":"2025-04-19T12:45:01.402518Z","shell.execute_reply.started":"2025-04-19T12:45:01.395357Z","shell.execute_reply":"2025-04-19T12:45:01.401474Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"class Inference:\n    def __init__(self, model):\n        self.model = model\n\n    def embed(self, texts):\n        print(\"Báº¯t Ä‘áº§u cháº¡y embeddings...\")\n        texts_embedding = self.model.encode(texts)\n        texts_embedding = torch.tensor(texts_embedding)\n\n        return texts_embedding\n\n    def infer(self, corpus, queries):    \n        class SimilarityModel(nn.Module):\n            def __init__(self, corpus_embeddings, corpus_cids):\n                super(SimilarityModel, self).__init__()\n                self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n                self.corpus_cids = corpus_cids              # List of CIDs\n        \n            def forward(self, question_embedding):\n                # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n                question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n                \n                # Compute cosine similarity\n                similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n                similarities[similarities == 1] = float('-inf')\n\n                # Get the top_n indices with the highest cosine similarity values\n                sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n                \n                \n                # Return top_n_ids, sorted similarities, and sorted indices\n                return sorted_similarities, sorted_indices\n                \n        # Example device setup\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n\n        # Initialize the similarity model\n        corpus_embeddings = corpus[\"embedding\"].to(device)\n        cids = corpus['cid']\n\n        query_embeddings = queries['embedding'].to(device)\n        qids = queries['qid']\n        \n        similarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\n        if torch.cuda.device_count() > 1:\n            similarity_model = nn.DataParallel(similarity_model)\n\n        self.predictions = []\n        for qid, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"Processing queries\"):\n            # Convert question_embedding to tensor and move to the device\n            query_embedding = query_embedding.to(device)\n            \n            # Get the top_n most relevant CIDs\n            sorted_similarities, sorted_indices = similarity_model(query_embedding)\n            results = []\n            for idx in range(len(sorted_similarities)):\n                doc_id = sorted_indices[idx].item()\n                score = sorted_similarities[idx].item()\n                rank = idx\n                row = (qid + 1, \"Q0\", doc_id + 1, rank + 1, score, \"4Huiter\")\n                results.append(row)\n            self.predictions.append(results)\n        return self.predictions\n","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.202667Z","iopub.execute_input":"2025-04-19T10:29:52.202914Z","iopub.status.idle":"2025-04-19T10:29:52.217901Z","shell.execute_reply.started":"2025-04-19T10:29:52.202883Z","shell.execute_reply":"2025-04-19T10:29:52.217035Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# RetrievalApp","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\nfrom datetime import datetime\n\nclass RetrievalApp:\n    def __init__(self, model_name, model_path=None):\n        self.model = BiEncoder(model_name, model_path).model\n        print(\"Load mÃ´ hÃ¬nh.....\")\n        self.model_name = model_name\n        self.model_path = model_path\n    \n    def prepare_data(self, data_file):\n        \"\"\"\n        Chuáº©n bá»‹ dá»¯ liá»‡u: chuáº©n bá»‹ cÃ¡c corpus vÃ  queries cho tá»«ng ngÃ´n ngá»¯.\n        \"\"\"\n        print(\"Chuáº©n bá»‹ data: ......\")\n        preparer = DataPreparer()\n        corpus_file = dict()\n        queries_file = dict()\n        langs = list(data_file['corpus'].keys())\n        \n        for lang in langs:\n            print(f\"Chuáº©n bá»‹ data {lang}:.....\")\n            corpus_file_org = data_file['corpus'][lang]\n            queries_file_org = data_file['queries'][lang]\n            corpus_file[lang], queries_file[lang] = preparer.prepare_inference_data(corpus_file_org, queries_file_org, lang)\n        \n        return langs, corpus_file, queries_file\n\n    def inference(self, langs, corpus_file, queries_file):\n        \"\"\"\n        Thá»±c hiá»‡n inference cho tá»«ng ngÃ´n ngá»¯.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u inference.....\")\n        corpus, queries = dict(), dict()\n        for lang in langs:\n            print(f\"Load data {lang}:.....\")\n            corpus_file_cur = corpus_file[lang]\n            queries_file_cur = queries_file[lang]\n            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n\n        inferencer = Inference(self.model)\n        for lang in langs:\n            print(f\"Inference {lang}:.....\")\n            corpus_cur, queries_cur = corpus[lang], queries[lang]\n            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n\n        return corpus, queries, inferencer\n\n    def predict(self, langs, corpus, queries, inferencer):\n        \"\"\"\n        Thá»±c hiá»‡n dá»± Ä‘oÃ¡n.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n:.....\")\n        predictions = dict()\n        for lang in langs:\n            print(f\"Dá»± Ä‘oÃ¡n {lang}:.....\")\n            corpus_cur, queries_cur = corpus[lang], queries[lang] \n            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n\n        return predictions\n\n    def zip_directory(self, zip_filename, dir_name):\n        \"\"\"\n        NÃ©n thÆ° má»¥c thÃ nh file zip mÃ  khÃ´ng sá»­ dá»¥ng Ä‘a luá»“ng.\n        \"\"\"\n        print(f\"Äang nÃ©n thÆ° má»¥c {dir_name} thÃ nh {zip_filename}...\")\n        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            # Duyá»‡t qua táº¥t cáº£ cÃ¡c file trong thÆ° má»¥c vÃ  nÃ©n chÃºng tuáº§n tá»±\n            for root, dirs, files in os.walk(dir_name):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, dir_name)  # LÆ°u láº¡i cáº¥u trÃºc thÆ° má»¥c gá»‘c\n                    zipf.write(file_path, arcname)\n\n        print(f\"File zip Ä‘Ã£ Ä‘Æ°á»£c táº¡o: {zip_filename}\")\n\n    def save_predictions(self, langs, predictions):\n        \"\"\"\n        LÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ o file vÃ  nÃ©n thÆ° má»¥c.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u xuáº¥t file:....\")\n        predictions_file = dict()\n        folder_name = f\"/kaggle/working/talent_clef/predict/{self.model_name}/{Timer.get()}\"\n        os.makedirs(folder_name, exist_ok=True)\n        for lang in langs:\n            predictions_file[lang] = utils.write_predictions(predictions[lang], folder_name, lang)\n        \n        # NÃ©n thÆ° má»¥c sau khi xuáº¥t file\n        zip_filename = folder_name + \".zip\"\n        self.zip_directory(zip_filename, folder_name)\n        \n        return predictions_file, zip_filename\n\n    def evaluate(self, langs, predictions_file, data):\n        \"\"\"\n        ÄÃ¡nh giÃ¡ káº¿t quáº£ dá»± Ä‘oÃ¡n.\n        \"\"\"\n        print(\"Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡:.....\")\n        ratings = dict()\n        for lang in langs:\n            print(f\"ÄÃ¡nh giÃ¡ {lang}:.....\")\n            run_file, qrels_file = predictions_file[lang], data['qrels'][lang]\n            ratings[lang] = Evaluate.evaluate(run_file, qrels_file)\n        return ratings\n\n    def __call__(self, data_file):\n        \"\"\"\n        Ná»‘i cÃ¡c hÃ m láº¡i vá»›i nhau vÃ  cháº¡y toÃ n bá»™ quy trÃ¬nh.\n        \"\"\"\n        langs, corpus_file, queries_file = self.prepare_data(data_file)\n        corpus, queries, inferencer = self.inference(langs, corpus_file, queries_file)\n        predictions = self.predict(langs, corpus, queries, inferencer)\n        predictions_file, zip_filename = self.save_predictions(langs, predictions)\n        ratings = self.evaluate(langs, predictions_file, data_file)\n        return ratings","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:27:52.950133Z","iopub.execute_input":"2025-04-19T12:27:52.950487Z","iopub.status.idle":"2025-04-19T12:27:52.965590Z","shell.execute_reply.started":"2025-04-19T12:27:52.950453Z","shell.execute_reply":"2025-04-19T12:27:52.964899Z"},"trusted":true},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"# SetupEnvironment","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\ndef load_git_workspace_wandb():\n    user_secrets = UserSecretsClient()\n    git_token = user_secrets.get_secret(\"github\")\n    wandp_api = user_secrets.get_secret(\"wandb\")\n\n    import subprocess\n\n    # Thay {git_token} báº±ng token thá»±c táº¿ cá»§a báº¡n\n    repo_url = f\"https://hoivd:{git_token}@github.com/hoivd/talent_clef\"\n    \n    # Lá»‡nh git clone\n    command = [\"git\", \"clone\", repo_url]\n    \n    try:\n        # Cháº¡y lá»‡nh vÃ  Ä‘á»£i hoÃ n táº¥t\n        result = subprocess.run(command, check=True, text=True, capture_output=True)\n        print(\"Clone thÃ nh cÃ´ng!\")\n        print(\"Stdout:\", result.stdout)  # In stdout náº¿u cÃ³\n        print(\"Stderr:\", result.stderr)  # In stderr Ä‘á»ƒ tháº¥y tiáº¿n trÃ¬nh\n    except subprocess.CalledProcessError as e:\n        print(\"Lá»—i khi clone repository:\")\n        print(e.stderr)  # In thÃ´ng bÃ¡o lá»—i náº¿u cÃ³\n        # ÄÄƒng nháº­p W&B\n    \n    wandb.login(key=wandp_api)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.242026Z","iopub.execute_input":"2025-04-19T10:29:52.242213Z","iopub.status.idle":"2025-04-19T10:29:52.261893Z","shell.execute_reply.started":"2025-04-19T10:29:52.242195Z","shell.execute_reply":"2025-04-19T10:29:52.261249Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class utils:\n    @staticmethod\n    def read_csv(input_path, columns=None):\n        print(\"Äá»c csv file:\")\n        # Kiá»ƒm tra input_path ngay tá»« Ä‘áº§u\n        if input_path is None:\n            raise ValueError(\"input_path khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng (None). Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n file CSV.\")\n        \n        try:  \n            if columns is None:\n                df = pd.read_csv(input_path, encoding='utf-8')\n            else:\n                df = pd.read_csv(input_path, encoding='utf-8', names=columns)\n            print(f\"Äá»c dá»¯ liá»‡u tá»« {input_path} thÃ nh cÃ´ng\")\n            return df\n        except Exception as e:\n            print(f\"Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« {input_path}: {e}\")\n            raise\n\n\n    @staticmethod\n    def read_tsv(input_path, columns=None):\n        print(\"Äá»c tsv file:\")\n        # Kiá»ƒm tra input_path ngay tá»« Ä‘áº§u\n        if input_path is None:\n            raise ValueError(\"input_path khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng (None). Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n file TSV.\")\n        \n        try:  \n            df = None\n            if columns is None:\n                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')  # ThÃªm sep='\\t' cho TSV\n            else:\n                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8', names=columns)\n            \n            print(f\"Äá»c dá»¯ liá»‡u tá»« {input_path} thÃ nh cÃ´ng\")\n            print(df.head())\n            return df\n        except Exception as e:\n            print(f\"Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« {input_path}: {e}\")\n            raise\n\n    @staticmethod\n    def write_csv(df, output_path):\n        try:\n            # Xuáº¥t ra file CSV\n            df.to_csv(output_path, sep=',', encoding='utf-8', index=False)\n            print(f\"ÄÃ£ xuáº¥t dá»¯ liá»‡u ra {output_path}\")\n        except Exception as e:\n            print(f\"Lá»—i khi xuáº¥t file CSV: {e}\")\n            raise\n        return output_path\n\n    @staticmethod\n    def write_predictions(predictions, folder_name, lang):\n        \n        output_path = f\"{folder_name}/run_{lang}.trec\"\n        try:\n            with open(output_path, 'w', encoding='utf-8') as f:\n                for query_predict in predictions: \n                    for line in query_predict:  # rank báº¯t Ä‘áº§u tá»« 1\n                        f.write(' '.join(str(x) for x in line) + '\\n')\n            print(f\"ÄÃ£ xuáº¥t file TREC ra {output_path}\")  \n            return output_path\n        \n        except Exception as e:\n            print(f\"Lá»—i khi xuáº¥t file TREC: {e}\")\n            raise\n\n        return output_path","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.262623Z","iopub.execute_input":"2025-04-19T10:29:52.262848Z","iopub.status.idle":"2025-04-19T10:29:52.281339Z","shell.execute_reply.started":"2025-04-19T10:29:52.262804Z","shell.execute_reply":"2025-04-19T10:29:52.280514Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"class Evaluate:\n    @staticmethod\n    def evaluate(predictions_path, qrels_path):\n        command = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_path, \"--run\", predictions_path]\n        result = subprocess.run(command, capture_output=True, text=True)\n        print(result.stdout)\n\n        return Evaluate.extract_metrics(result)\n        \n    @staticmethod\n    def extract_metrics(result, language=\"en-en\"):\n        stdout = result.stdout\n        map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n        mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n        ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n        precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n        precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n        precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n    \n        metrics = {\n            \"map\": map_value,\n            \"mrr\": mrr,\n            \"ndcg\": ndcg,\n            \"precision@5\": precision_5,\n            \"precision@10\": precision_10,\n            \"precision@100\": precision_100\n        }\n        return metrics     ","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.282218Z","iopub.execute_input":"2025-04-19T10:29:52.282503Z","iopub.status.idle":"2025-04-19T10:29:52.301485Z","shell.execute_reply.started":"2025-04-19T10:29:52.282473Z","shell.execute_reply":"2025-04-19T10:29:52.300605Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Timer","metadata":{}},{"cell_type":"code","source":"class Timer:\n    @staticmethod\n    def get():\n        # Láº¥y mÃºi giá» Viá»‡t Nam (UTC+7)\n        vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n        \n        # Láº¥y thá»i gian hiá»‡n táº¡i á»Ÿ UTC\n        utc_now = datetime.now(pytz.utc)\n        \n        # Chuyá»ƒn thá»i gian UTC sang mÃºi giá» Viá»‡t Nam\n        vietnam_time = utc_now.astimezone(vietnam_timezone)\n        \n        # Tráº£ vá» thá»i gian Ä‘Ã£ Ä‘á»‹nh dáº¡ng theo kiá»ƒu YYYY-MM-DD HH:MM:SS\n        return vietnam_time.strftime(\"%m-%d_%H-%M-%S\")\n\n# Gá»i hÃ m vÃ  in káº¿t quáº£\nprint(Timer.get())","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.303390Z","iopub.execute_input":"2025-04-19T10:29:52.303617Z","iopub.status.idle":"2025-04-19T10:29:52.352188Z","shell.execute_reply.started":"2025-04-19T10:29:52.303597Z","shell.execute_reply":"2025-04-19T10:29:52.351353Z"},"trusted":true},"outputs":[{"name":"stdout","text":"04-19_17-29-52\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# ModelLogger","metadata":{}},{"cell_type":"code","source":"class ModelLogger:\n    def __init__(self, model_name, loss_function, num_epochs, metrics, notes=\"\", training_time=None,\n                 folder=\"/kaggle/working/talent_clef/results\", file_name=f\"{Timer.get()}.csv\"):\n        self.model_name = model_name\n        self.loss = loss_function\n        self.epochs = num_epochs\n        self.metrics = metrics\n        self.notes = notes\n        self.training_time = training_time\n        self.folder = folder\n        self.file_path = os.path.join(folder, file_name)\n    \n    def compute_average_map(self):\n        map_values = [lang['map'] for lang in self.metrics.values() if 'map' in lang]\n        return sum(map_values) / len(map_values) if map_values else None\n\n    def to_dict(self):\n        return {\n            \"model_name\": [self.model_name],\n            \"Avg result\": [self.compute_average_map()],\n            \"en-en result\": [self.metrics.get(\"en-en\", \"\")],\n            \"es-es result\": [self.metrics.get(\"es-es\", \"\")],\n            \"de-de result\": [self.metrics.get(\"de-de\", \"\")],\n            \"zh-zh result\": [self.metrics.get(\"zh-zh\", \"\")],\n            \"en-es result\": [self.metrics.get(\"en-es\", \"\")],\n            \"en-de result\": [self.metrics.get(\"en-de\", \"\")],\n            \"en-zh result\": [self.metrics.get(\"en-zh\", \"\")],\n            \"loss\": [self.loss],\n            \"epochs\": [self.epochs],\n            \"training_time (s)\": [self.training_time],\n            \"date\": [Timer.get()],\n            \"notes\": [self.notes]\n        }\n\n    def save(self):\n        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i\n        os.makedirs(self.folder, exist_ok=True)\n\n        # Táº¡o DataFrame tá»« dict\n        df_new = pd.DataFrame(self.to_dict())\n\n        if os.path.exists(self.file_path):\n            df_existing = pd.read_csv(self.file_path)\n            df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n            df_updated.to_csv(self.file_path, index=False)\n            print(f\"âœ… ÄÃ£ thÃªm dá»¯ liá»‡u vÃ o file: {self.file_path}\")\n        else:\n            df_new.to_csv(self.file_path, index=False)\n            print(f\"âœ… ÄÃ£ táº¡o file má»›i: {self.file_path}\")\n\n    def show_log(self):\n        if os.path.exists(self.file_path):\n            print(f\"\\nğŸ“„ Ná»™i dung file log:\")\n            log_df = utils.read_csv(self.file_path)\n            print(log_df)\n        else:\n            print(\"âš ï¸ ChÆ°a cÃ³ file log Ä‘á»ƒ hiá»ƒn thá»‹.\")","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:29:52.353066Z","iopub.execute_input":"2025-04-19T10:29:52.353280Z","iopub.status.idle":"2025-04-19T10:29:52.362281Z","shell.execute_reply.started":"2025-04-19T10:29:52.353259Z","shell.execute_reply":"2025-04-19T10:29:52.361339Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# HÃ m thá»±c thi","metadata":{}},{"cell_type":"markdown","source":"## 1. Clone data","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhuggingface_api = user_secrets.get_secret(\"huggingface\")\n\n!huggingface-cli login --token {huggingface_api}\n!git clone https://huggingface.co/hoivinh20789/talent_clef /kaggle/working/models\nload_git_workspace_wandb()\n\n!git clone https://github.com/TalentCLEF/talentclef25_evaluation_script.git\n!pip install -r \"/kaggle/working/talentclef25_evaluation_script/requirements.txt\"","metadata":{"collapsed":true,"execution":{"iopub.status.busy":"2025-04-19T12:26:21.116062Z","iopub.execute_input":"2025-04-19T12:26:21.116463Z","iopub.status.idle":"2025-04-19T12:26:35.957878Z","shell.execute_reply.started":"2025-04-19T12:26:21.116429Z","shell.execute_reply":"2025-04-19T12:26:35.956615Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nThe token `kaggle` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `kaggle`\nfatal: destination path '/kaggle/working/models' already exists and is not an empty directory.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Lá»—i khi clone repository:\nfatal: destination path 'talent_clef' already exists and is not an empty directory.\n\nCloning into 'talentclef25_evaluation_script'...\nremote: Enumerating objects: 27, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 27 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (27/27), 10.10 KiB | 3.37 MiB/s, done.\nResolving deltas: 100% (10/10), done.\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.2.3)\nCollecting ranx (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.60.0)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.9.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.67.1)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.13.1)\nCollecting ir-datasets (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (13.9.4)\nRequirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10.12)\nCollecting lz4 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting cbor2 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.2)\nCollecting fastparquet (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54.1->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.17.0)\nCollecting cramjam>=2.3 (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2024.12.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (24.2)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.3)\nCollecting inscriptis>=2.2.0 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (5.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (6.0.2)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.32.3)\nCollecting trec-car-tools>=2.5.4 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\nCollecting warc3-wet>=0.2.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/warc3-wet-clueweb09/\u001b[0m\u001b[33m\n\u001b[0mCollecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting zlib-state>=0.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\nCollecting ijson>=3.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nCollecting unlzw3>=0.2.1 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (19.0.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.19.1)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.2)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.7.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.6)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.1.31)\nCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n  Downloading cbor-1.0.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\nDownloading ranx-0.3.20-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\nDownloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\nDownloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\nDownloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nBuilding wheels for collected packages: warc3-wet-clueweb09, cbor\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=b7fd2e0ec444ef72f60ff3e398f81fe71fc7a8b47b232811c091c7b01ea87a61\n  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53428 sha256=ffe4ddd3cef248e36f9334817a09a92c2d389b218758c90b872c56dbb23cb164\n  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\nSuccessfully built warc3-wet-clueweb09 cbor\nInstalling collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, cramjam, cbor2, inscriptis, trec-car-tools, ir-datasets, fastparquet, ranx\nSuccessfully installed cbor-1.0.0 cbor2-5.6.5 cramjam-2.10.0 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"## 3. Training","metadata":{}},{"cell_type":"code","source":"source_file = \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"\nneg_pair_file = \"/kaggle/working/talent_clef/data/hard_neg_mining/neg_example.csv\"\npreparer = DataPreparer()\ntrain_df, train_file = preparer.prepare_train_data(neg_pair_file, source_file)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:48:44.590677Z","iopub.execute_input":"2025-04-19T10:48:44.591031Z","iopub.status.idle":"2025-04-19T10:49:46.824992Z","shell.execute_reply.started":"2025-04-19T10:48:44.590998Z","shell.execute_reply":"2025-04-19T10:49:46.823903Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Äá»c dá»¯ liá»‡u train_org:\n                       jobtitle  \\\n0    director of technical arts   \n0          technical supervisor   \n0             technical manager   \n0  head of technical department   \n0            technical director   \n\n                                               skill  label  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n                     jobtitle  \\\n0  director of technical arts   \n1  director of technical arts   \n2  director of technical arts   \n3  director of technical arts   \n4  director of technical arts   \n\n                                               skill  label  \n0  Overview: This comprehensive overview of skill...      0  \n1  Overview: The skills essential for success inc...      0  \n2  Overview: The skills essential for success inc...      0  \n3  Overview: The skills essential for success inc...      0  \n4  Overview: The performing arts encompass a wide...      0  \n                       jobtitle  \\\n0    director of technical arts   \n0          technical supervisor   \n0             technical manager   \n0  head of technical department   \n0            technical director   \n\n                                               skill  label  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \n0  Overview: The essential skills for performing ...      1  \nCá»™t dá»¯ liá»‡u: Index(['jobtitle', 'skill', 'label'], dtype='object')\nXuáº¥t dá»¯ liá»‡u train sau khi chuáº©n bá»‹:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/train.csv\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"train_data = Dataset.load_train_data(train_file, train_df)\ndataset = Dataset(train_data)\n\nmodel_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\nmodel_path = '/kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6'\nloss = losses.MultipleNegativesRankingLoss\ndetail = \"hard_neg_pair_epoch2\"\nparams = {\n    \"num_epochs\": 2,\n    \"output_path\": f\"/kaggle/working/models/{model_name}/{detail}\",\n    \"warmup_steps\": 100,\n}\n\ntrainer = Trainer(model_name, model_path)\nmodel, model_path = trainer.train(dataset.data, loss, params)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T10:53:47.321487Z","iopub.execute_input":"2025-04-19T10:53:47.321807Z","iopub.status.idle":"2025-04-19T12:02:53.601794Z","shell.execute_reply.started":"2025-04-19T10:53:47.321773Z","shell.execute_reply":"2025-04-19T12:02:53.600803Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device sá»­ dá»¥ng: cuda\nTáº£i mÃ´ hÃ¬nh tá»« Ä‘Æ°á»ng dáº«n cá»¥c bá»™: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6\nMÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\nKhá»Ÿi táº¡o dataset:\nBáº¯t Ä‘áº§u train: \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='21084' max='21084' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [21084/21084 1:08:25, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.739400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.628800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.573700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.581300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.583600</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.536500</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.536500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.509400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.488700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.487100</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.480900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.479400</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.466900</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.456700</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.464100</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.437500</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.447800</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.436400</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.406200</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.403900</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.424300</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.349600</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.350000</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.333900</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.338700</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.344500</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.333800</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.348300</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.337900</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.337900</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.330300</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.308000</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.327800</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.326700</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.321300</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.310800</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.316000</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.299700</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.316600</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.296800</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>0.303300</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.305200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":50},{"cell_type":"markdown","source":"# Push Model","metadata":{}},{"cell_type":"code","source":"repo_id = \"hoivinh20789/talent_clef\"  # ÄÆ°á»ng dáº«n tá»›i repo cá»§a báº¡n trÃªn Hugging Face\nfolder_path = params['output_path']  # ÄÆ°á»ng dáº«n tá»›i thÆ° má»¥c chá»©a mÃ´ hÃ¬nh cá»§a báº¡n\ntarget_folder = f\"{model_name}/{detail}\"  # ThÆ° má»¥c con mÃ  báº¡n muá»‘n Ä‘áº©y mÃ´ hÃ¬nh vÃ o trong repo\n\napi = HfApi()\n\n# Äáº©y model vÃ o thÆ° má»¥c 'model' trong repository\napi.upload_folder(\n    repo_id=repo_id,\n    folder_path=folder_path,  # ThÆ° má»¥c chá»©a cÃ¡c file model\n    path_in_repo=target_folder,  # ThÆ° má»¥c con 'model' trong repo\n    commit_message=\"Upload model version 1\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:40:25.361937Z","iopub.execute_input":"2025-04-19T12:40:25.362301Z","iopub.status.idle":"2025-04-19T12:40:37.460540Z","shell.execute_reply.started":"2025-04-19T12:40:25.362273Z","shell.execute_reply":"2025-04-19T12:40:37.459797Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5d41d8930924a338bc223c91abecdfd"}},"metadata":{}},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hoivinh20789/talent_clef/commit/0cdddb44f127b717f763c9a3907c9aae9750f009', commit_message='Upload model version 1', commit_description='', oid='0cdddb44f127b717f763c9a3907c9aae9750f009', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hoivinh20789/talent_clef', endpoint='https://huggingface.co', repo_type='model', repo_id='hoivinh20789/talent_clef'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":68},{"cell_type":"markdown","source":"## RetrievalApp","metadata":{}},{"cell_type":"code","source":"data = {\n    \"corpus\": {\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements\"\n    },\n    \n    \"queries\":{\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/queries\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/queries\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/queries\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/queries\"\n    },\n    \n    \"qrels\": {\n        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\",\n        \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\",\n        \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\",\n        \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\"\n    }\n}\n\nmodel_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\napp = RetrievalApp(model_name, params['output_path'])\nratings = app(data)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:48:25.203583Z","iopub.execute_input":"2025-04-19T12:48:25.203966Z","iopub.status.idle":"2025-04-19T12:50:33.952860Z","shell.execute_reply.started":"2025-04-19T12:48:25.203930Z","shell.execute_reply":"2025-04-19T12:50:33.952049Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device sá»­ dá»¥ng: cuda\nTáº£i mÃ´ hÃ¬nh tá»« Ä‘Æ°á»ng dáº«n cá»¥c bá»™: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/hard_neg_pair_epoch2\nMÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\nLoad mÃ´ hÃ¬nh.....\nChuáº©n bá»‹ data: ......\nChuáº©n bá»‹ data en-en:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements thÃ nh cÃ´ng\n   c_id                          jobtitle\n0     1                recording engineer\n1     2              director of taxation\n2     3  technical support representative\n3     4                        hr manager\n4     5           computer graphic artist\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/english/queries thÃ nh cÃ´ng\n   q_id             jobtitle\n0     1                nanny\n1     2    food technologist\n2     3   broadcast engineer\n3     4  automation engineer\n4     5         veterinarian\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_en-en.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_en-en.csv\nChuáº©n bá»‹ data de-de:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements thÃ nh cÃ´ng\n   c_id                   jobtitle\n0     1               pr-managerin\n1     2       talkshow-moderatorin\n2     3             sporttrainerin\n3     4         preiskoordinatorin\n4     5  persoÌˆnlicher bankberater\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/german/queries thÃ nh cÃ´ng\n   q_id                        jobtitle\n0     1           technischer recruiter\n1     2                    brieftraÌˆger\n2     3              grundschullehrerin\n3     4                     3d-animator\n4     5  unternehmensstrategieberaterin\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_de-de.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_de-de.csv\nChuáº©n bá»‹ data es-es:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements thÃ nh cÃ´ng\n   c_id                         jobtitle\n0     1               desarrollador java\n1     2         diseÃ±adora de accesorios\n2     3  agente inmobiliario residencial\n3     4           planificador de ventas\n4     5          ayudante de conferencia\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/spanish/queries thÃ nh cÃ´ng\n   q_id                        jobtitle\n0     1     ingeniera de automatizaciÃ³n\n1     2  tÃ©cnica de soporte informÃ¡tico\n2     3                 piloto de aviÃ³n\n3     4   ingeniera de diseÃ±o analÃ³gico\n4     5      analista de capital riesgo\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_es-es.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_es-es.csv\nChuáº©n bá»‹ data zh-zh:.....\nÄá»c dá»¯ liá»‡u inference:\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements thÃ nh cÃ´ng\n   c_id jobtitle\n0     1   è‡ªåŠ¨åŒ–æŠ€æœ¯å‘˜\n1     2    é€‰è§’åˆ¶ä½œäºº\n2     3     ä½“è‚²ç»ç†\n3     4     ä¸´æ—¶åŠ©ç†\n4     5  ç”¨æˆ·æ”¯æŒæŠ€æœ¯å‘˜\nÄá»c tsv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/chinese/queries thÃ nh cÃ´ng\n   q_id jobtitle\n0     1     è´·æ¬¾å¹²äº‹\n1     2     ç¨åŠ¡ä¼šè®¡\n2     3    çŠ¬ç±»ç¾å®¹å¸ˆ\n3     4      æ”¶é“¶å‘˜\n4     5      ç­¹æ¬¾äºº\nXuáº¥t dá»¯ liá»‡u inference:\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_zh-zh.csv\nÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_zh-zh.csv\nBáº¯t Ä‘áº§u inference.....\nLoad data en-en:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_en-en.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_en-en.csv thÃ nh cÃ´ng\nLoad data de-de:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_de-de.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_de-de.csv thÃ nh cÃ´ng\nLoad data es-es:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_es-es.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_es-es.csv thÃ nh cÃ´ng\nLoad data zh-zh:.....\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_zh-zh.csv thÃ nh cÃ´ng\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_zh-zh.csv thÃ nh cÃ´ng\nInference en-en:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/82 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ce218707a6e4583b6a630275e6ea61f"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8179ef950164f448628233e787dd45f"}},"metadata":{}},{"name":"stdout","text":"Inference de-de:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/148 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ed6f61b781457c9f0fe629926e1c75"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f14dd730f3427c947a174cefdee170"}},"metadata":{}},{"name":"stdout","text":"Inference es-es:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/146 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fffe857c42ff4e4793d503f1a688c777"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03dabcf3fab14e79a84adc5a3e821508"}},"metadata":{}},{"name":"stdout","text":"Inference zh-zh:.....\nBáº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3935fad2f8b4128a9eb70822dee7582"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u cháº¡y embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f758c993ddc466e808a7036bc84b01d"}},"metadata":{}},{"name":"stdout","text":"Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n:.....\nDá»± Ä‘oÃ¡n en-en:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:07<00:00, 13.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dá»± Ä‘oÃ¡n de-de:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:27<00:00,  7.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dá»± Ä‘oÃ¡n es-es:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [00:25<00:00,  7.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dá»± Ä‘oÃ¡n zh-zh:.....\n","output_type":"stream"},{"name":"stderr","text":"Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:07<00:00, 13.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Báº¯t Ä‘áº§u xuáº¥t file:....\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_en-en.trec\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_de-de.trec\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_es-es.trec\nÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_zh-zh.trec\nÄang nÃ©n thÆ° má»¥c /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40 thÃ nh /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip...\nFile zip Ä‘Ã£ Ä‘Æ°á»£c táº¡o: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip\nBáº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡:.....\nÄÃ¡nh giÃ¡ en-en:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_en-en.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.5326\nmrr: 0.8820\nndcg: 0.7985\nprecision@5: 0.7029\nprecision@10: 0.6105\nprecision@100: 0.1740\n\nÄÃ¡nh giÃ¡ de-de:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_de-de.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.2950\nmrr: 0.5391\nndcg: 0.6342\nprecision@5: 0.5172\nprecision@10: 0.4808\nprecision@100: 0.1774\n\nÄÃ¡nh giÃ¡ es-es:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_es-es.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.4187\nmrr: 0.8443\nndcg: 0.7411\nprecision@5: 0.6757\nprecision@10: 0.5946\nprecision@100: 0.2096\n\nÄÃ¡nh giÃ¡ zh-zh:.....\nReceived parameters:\n  qrels: /kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\n  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_zh-zh.trec\nLoading qrels...\nLoading run...\nRunning evaluation...\n\n=== Evaluation Results ===\nmap: 0.4537\nmrr: 0.8341\nndcg: 0.7434\nprecision@5: 0.6233\nprecision@10: 0.5223\nprecision@100: 0.1469\n\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"ratings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:50:33.954063Z","iopub.execute_input":"2025-04-19T12:50:33.954290Z","iopub.status.idle":"2025-04-19T12:50:33.960571Z","shell.execute_reply.started":"2025-04-19T12:50:33.954269Z","shell.execute_reply":"2025-04-19T12:50:33.959917Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"{'en-en': {'map': 0.5326,\n  'mrr': 0.882,\n  'ndcg': 0.7985,\n  'precision@5': 0.7029,\n  'precision@10': 0.6105,\n  'precision@100': 0.174},\n 'de-de': {'map': 0.295,\n  'mrr': 0.5391,\n  'ndcg': 0.6342,\n  'precision@5': 0.5172,\n  'precision@10': 0.4808,\n  'precision@100': 0.1774},\n 'es-es': {'map': 0.4187,\n  'mrr': 0.8443,\n  'ndcg': 0.7411,\n  'precision@5': 0.6757,\n  'precision@10': 0.5946,\n  'precision@100': 0.2096},\n 'zh-zh': {'map': 0.4537,\n  'mrr': 0.8341,\n  'ndcg': 0.7434,\n  'precision@5': 0.6233,\n  'precision@10': 0.5223,\n  'precision@100': 0.1469}}"},"metadata":{}}],"execution_count":82},{"cell_type":"markdown","source":"## 5. Log Model","metadata":{}},{"cell_type":"code","source":"logger = ModelLogger(\n    model_name=model_name,\n    loss_function=None,\n    num_epochs=None,\n    metrics=ratings,\n    notes=\"thÃªm negative pair vÃ  finetune tiáº¿p tá»« epoch 5\"\n)\n\nlogger.save()\nlogger.show_log()","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:33.962081Z","iopub.execute_input":"2025-04-19T12:50:33.962291Z","iopub.status.idle":"2025-04-19T12:50:33.997547Z","shell.execute_reply.started":"2025-04-19T12:50:33.962271Z","shell.execute_reply":"2025-04-19T12:50:33.996545Z"},"trusted":true},"outputs":[{"name":"stdout","text":"âœ… ÄÃ£ thÃªm dá»¯ liá»‡u vÃ o file: /kaggle/working/talent_clef/results/04-19_17-29-52.csv\n\nğŸ“„ Ná»™i dung file log:\nÄá»c csv file:\nÄá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/results/04-19_17-29-52.csv thÃ nh cÃ´ng\n                                          model_name  Avg result  \\\n0  sentence-transformers/paraphrase-multilingual-...       0.425   \n1  sentence-transformers/paraphrase-multilingual-...       0.425   \n2  sentence-transformers/paraphrase-multilingual-...       0.425   \n\n                                        en-en result  \\\n0  {'map': 0.5326, 'mrr': 0.882, 'ndcg': 0.7985, ...   \n1  {'map': 0.5326, 'mrr': 0.882, 'ndcg': 0.7985, ...   \n2  {'map': 0.5326, 'mrr': 0.882, 'ndcg': 0.7985, ...   \n\n                                        es-es result  \\\n0  {'map': 0.4187, 'mrr': 0.8443, 'ndcg': 0.7411,...   \n1  {'map': 0.4187, 'mrr': 0.8443, 'ndcg': 0.7411,...   \n2  {'map': 0.4187, 'mrr': 0.8443, 'ndcg': 0.7411,...   \n\n                                        de-de result  \\\n0  {'map': 0.295, 'mrr': 0.5391, 'ndcg': 0.6342, ...   \n1  {'map': 0.295, 'mrr': 0.5391, 'ndcg': 0.6342, ...   \n2  {'map': 0.295, 'mrr': 0.5391, 'ndcg': 0.6342, ...   \n\n                                        zh-zh result  en-es result  \\\n0  {'map': 0.4537, 'mrr': 0.8341, 'ndcg': 0.7434,...           NaN   \n1  {'map': 0.4537, 'mrr': 0.8341, 'ndcg': 0.7434,...           NaN   \n2  {'map': 0.4537, 'mrr': 0.8341, 'ndcg': 0.7434,...           NaN   \n\n   en-de result  en-zh result  loss  epochs  training_time (s)  \\\n0           NaN           NaN   NaN     NaN                NaN   \n1           NaN           NaN   NaN     NaN                NaN   \n2           NaN           NaN   NaN     NaN                NaN   \n\n             date                                           notes  \n0  04-19_19-33-17  thÃªm negative pair vÃ  finetune tiáº¿p tá»« epoch 5  \n1  04-19_19-47-26  thÃªm negative pair vÃ  finetune tiáº¿p tá»« epoch 5  \n2  04-19_19-50-33  thÃªm negative pair vÃ  finetune tiáº¿p tá»« epoch 5  \n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"# Git Push","metadata":{}},{"cell_type":"code","source":"cd talent_clef","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:33.998940Z","iopub.execute_input":"2025-04-19T12:50:33.999222Z","iopub.status.idle":"2025-04-19T12:50:34.005023Z","shell.execute_reply.started":"2025-04-19T12:50:33.999197Z","shell.execute_reply":"2025-04-19T12:50:34.004187Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/talent_clef\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"brand_name = model_name + \"/\" +Timer.get()","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:34.005930Z","iopub.execute_input":"2025-04-19T12:50:34.006182Z","iopub.status.idle":"2025-04-19T12:50:34.018101Z","shell.execute_reply.started":"2025-04-19T12:50:34.006159Z","shell.execute_reply":"2025-04-19T12:50:34.017328Z"},"trusted":true},"outputs":[],"execution_count":85},{"cell_type":"code","source":"brand_name","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:34.018770Z","iopub.execute_input":"2025-04-19T12:50:34.019029Z","iopub.status.idle":"2025-04-19T12:50:34.033892Z","shell.execute_reply.started":"2025-04-19T12:50:34.018997Z","shell.execute_reply":"2025-04-19T12:50:34.033242Z"},"trusted":true},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34'"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"!git config --global user.email \"hoivd79@gmail.com\"\n!git config --global user.name \"Dang Vinh Hoi\"\n!git checkout -b {brand_name}      # Táº¡o vÃ  chuyá»ƒn sang nhÃ¡nh dev\n!git status\n!git add .\n!git commit -m \"updated\"\n!git push -u origin {brand_name}    # Push láº§n Ä‘áº§u, thiáº¿t láº­p tracking","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:34.034869Z","iopub.execute_input":"2025-04-19T12:50:34.035083Z","iopub.status.idle":"2025-04-19T12:50:41.887724Z","shell.execute_reply.started":"2025-04-19T12:50:34.035063Z","shell.execute_reply":"2025-04-19T12:50:41.886722Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Switched to a new branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34'\nOn branch sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\t\u001b[31mmodified:   results/04-19_17-29-52.csv\u001b[m\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\t\u001b[31mpredict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip\u001b[m\n\t\u001b[31mpredict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/\u001b[m\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n[sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34 25ab1e2] updated\n 6 files changed, 2356107 insertions(+)\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40.zip\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_de-de.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_en-en.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_es-es.trec\n create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-49-40/run_zh-zh.trec\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 4 threads\nCompressing objects: 100% (8/8), done.\nWriting objects: 100% (8/8), 32.58 MiB | 21.03 MiB/s, done.\nTotal 8 (delta 5), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\nremote: \nremote: Create a pull request for 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34' on GitHub by visiting:\u001b[K\nremote:      https://github.com/hoivd/talent_clef/pull/new/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34\u001b[K\nremote: \nTo https://github.com/hoivd/talent_clef\n * [new branch]      sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34 -> sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34\nBranch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34' set up to track remote branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-19_19-50-34' from 'origin'.\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"cd ..\n","metadata":{"execution":{"iopub.status.busy":"2025-04-19T12:50:41.889819Z","iopub.execute_input":"2025-04-19T12:50:41.890112Z","iopub.status.idle":"2025-04-19T12:50:41.897554Z","shell.execute_reply.started":"2025-04-19T12:50:41.890085Z","shell.execute_reply":"2025-04-19T12:50:41.896685Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":88}]}