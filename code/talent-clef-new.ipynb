{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.806493Z",
     "iopub.status.busy": "2025-04-16T17:48:04.806201Z",
     "iopub.status.idle": "2025-04-16T17:48:04.811309Z",
     "shell.execute_reply": "2025-04-16T17:48:04.810444Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.806472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchmetrics.retrieval import RetrievalMAP\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import wandb\n",
    "import ast\n",
    "import subprocess\n",
    "import pickle\n",
    "import shutil\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PositiveExampleMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.812509Z",
     "iopub.status.busy": "2025-04-16T17:48:04.812223Z",
     "iopub.status.idle": "2025-04-16T17:48:04.833696Z",
     "shell.execute_reply": "2025-04-16T17:48:04.832894Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.812487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MiningPosExample:\n",
    "    def __init__(self):\n",
    "        self.data = None  # Khá»Ÿi táº¡o thuá»™c tÃ­nh self.data lÃ  None\n",
    "\n",
    "     # PhÆ°Æ¡ng thá»©c __len__ Ä‘á»ƒ tráº£ vá» sá»‘ dÃ²ng cá»§a data\n",
    "    def __len__(self):\n",
    "        if self.data is not None:\n",
    "            return len(self.data)\n",
    "        return 0  # Náº¿u self.data chÆ°a Ä‘Æ°á»£c gÃ¡n (None), tráº£ vá» 0\n",
    "    \n",
    "    # PhÆ°Æ¡ng thá»©c __getitem__ Ä‘á»ƒ truy xuáº¥t má»™t dÃ²ng trong data theo chá»‰ sá»‘\n",
    "    def __getitem__(self, index):\n",
    "        if self.data is not None:\n",
    "            return self.data.iloc[index]\n",
    "        raise IndexError(\"Index out of range\")  # Náº¿u self.data lÃ  None, raise lá»—i\n",
    "        \n",
    "    def mining_pos_example(self, data_file):\n",
    "        # Äá»c dá»¯ liá»‡u tá»« file (giáº£ sá»­ lÃ  file CSV)\n",
    "        df = pd.read_csv(data_file)\n",
    "        df['jobtitles'] = df['jobtitles'].apply(ast.literal_eval)\n",
    "        # Láº¥y cÃ¡c cá»™t 'jobtitles' vÃ  'skills_gen', sau Ä‘Ã³ \"phÃ¢n ná»•\" danh sÃ¡ch trong cá»™t 'jobtitles'\n",
    "        new_df = df[['jobtitles', 'skills_gen']].explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n",
    "        \n",
    "        # ThÃªm cá»™t 'label' vá»›i giÃ¡ trá»‹ toÃ n bá»™ lÃ  1\n",
    "        new_df['label'] = 1\n",
    "        \n",
    "        # LÆ°u káº¿t quáº£ vÃ o self.data\n",
    "        self.data = new_df\n",
    "        \n",
    "        return new_df\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPrepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:59:44.847386Z",
     "iopub.status.busy": "2025-04-16T17:59:44.847026Z",
     "iopub.status.idle": "2025-04-16T17:59:44.852758Z",
     "shell.execute_reply": "2025-04-16T17:59:44.851982Z",
     "shell.execute_reply.started": "2025-04-16T17:59:44.847362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DataPreparer:\n",
    "    def prepare_train_data(self, train_data_org_file):\n",
    "        print(\"Äá»c dá»¯ liá»‡u train_org:\")\n",
    "        \n",
    "        pos_miner = MiningPosExample()\n",
    "        pos_example_df = pos_miner.mining_pos_example(train_data_org_file)\n",
    "        print(pos_example_df.head())\n",
    "\n",
    "        train_df = pos_example_df\n",
    "        print(f\"Cá»™t dá»¯ liá»‡u: {train_df.columns}\")\n",
    "        print(\"Xuáº¥t dá»¯ liá»‡u train sau khi chuáº©n bá»‹:\")\n",
    "        train_file = \"/kaggle/working/train.csv\"\n",
    "        utils.write_csv(train_df, train_file)\n",
    "        return train_df, train_file\n",
    "\n",
    "    def prepare_inference_data(self, corpus_path, queries_path, lang):\n",
    "        print(\"Äá»c dá»¯ liá»‡u inference:\")\n",
    "        corpus_df = utils.read_tsv(corpus_path)\n",
    "        queries_df = utils.read_tsv(queries_path)\n",
    "        \n",
    "        print(\"Xuáº¥t dá»¯ liá»‡u inference:\")\n",
    "        corpus_out_path = f\"/kaggle/working/corpus_{lang}.csv\"\n",
    "        queries_out_path = f\"/kaggle/working/queries_{lang}.csv\"\n",
    "        utils.write_csv(corpus_df, corpus_out_path)\n",
    "        utils.write_csv(queries_df, queries_out_path)\n",
    "        return corpus_out_path, queries_out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T18:01:57.061531Z",
     "iopub.status.busy": "2025-04-16T18:01:57.061178Z",
     "iopub.status.idle": "2025-04-16T18:01:57.068841Z",
     "shell.execute_reply": "2025-04-16T18:01:57.067845Z",
     "shell.execute_reply.started": "2025-04-16T18:01:57.061504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = []\n",
    "        for jobtitle, skill, label in data:\n",
    "            self.data.append(InputExample(texts = [jobtitle, skill], label=label))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Tráº£ vá» sá»‘ lÆ°á»£ng máº«u trong dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def load_train_data(train_path):\n",
    "        train_df = utils.read_csv(train_path)\n",
    "        jobtitles =  train_df['jobtitle'].tolist()\n",
    "        skills =  train_df['skill'].tolist()\n",
    "        labels = train_df['label'].tolist()\n",
    "\n",
    "        data = []\n",
    "        for idx, jobtitle in enumerate(jobtitles):\n",
    "            data.append((jobtitle, skills[idx], labels[idx]))\n",
    "        return data\n",
    "        \n",
    "    @staticmethod  \n",
    "    def load_inference_data(corpus_path, queries_path):\n",
    "        corpus_df = utils.read_csv(corpus_path)\n",
    "        queries_df = utils.read_csv(queries_path)\n",
    "        \n",
    "        cids_l = corpus_df['c_id'].tolist()\n",
    "        corpus_l = corpus_df['jobtitle'].tolist()\n",
    "        qids_l = queries_df['q_id'].tolist()\n",
    "        queries_l = queries_df['jobtitle'].tolist()\n",
    "\n",
    "        corpus = {\"cid\": cids_l,\n",
    "                \"jobtitle\": corpus_l\n",
    "                }\n",
    "\n",
    "        queries = {\"qid\": qids_l,\n",
    "                \"jobtitle\": queries_l\n",
    "                }\n",
    "        return corpus, queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.867422Z",
     "iopub.status.busy": "2025-04-16T17:48:04.867155Z",
     "iopub.status.idle": "2025-04-16T17:48:04.883747Z",
     "shell.execute_reply": "2025-04-16T17:48:04.882978Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.867391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BiEncoder:\n",
    "    def __init__(self, model_name=None, model_path=None):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Device sá»­ dá»¥ng:\", device)\n",
    "        \n",
    "        try:\n",
    "            if model_path is None:\n",
    "                print(f\"Táº£i mÃ´ hÃ¬nh tá»« Hugging Face vá»›i tÃªn: {model_name}\")\n",
    "                self.model = SentenceTransformer(model_name)\n",
    "            else:\n",
    "                print(f\"Táº£i mÃ´ hÃ¬nh tá»« Ä‘Æ°á»ng dáº«n cá»¥c bá»™: {model_path}\")\n",
    "                self.model = SentenceTransformer(model_path)\n",
    "            \n",
    "            # Äáº·t mÃ´ hÃ¬nh lÃªn thiáº¿t bá»‹\n",
    "            self.model = self.model.to(device)\n",
    "            print(\"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lá»—i khi khá»Ÿi táº¡o mÃ´ hÃ¬nh: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.927617Z",
     "iopub.status.busy": "2025-04-16T17:48:04.927431Z",
     "iopub.status.idle": "2025-04-16T17:48:04.932346Z",
     "shell.execute_reply": "2025-04-16T17:48:04.931532Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.927601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.bi_encoder = BiEncoder(model_name, model_path)\n",
    "\n",
    "    def train(self, dataset, loss, params):\n",
    "        print(\"Khá»Ÿi táº¡o dataset:\")\n",
    "        train_dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n",
    "\n",
    "        print(\"Báº¯t Ä‘áº§u train: \")\n",
    "\n",
    "         # Khá»Ÿi táº¡o hÃ m máº¥t mÃ¡t\n",
    "        train_loss = loss(self.bi_encoder.model)\n",
    "        \n",
    "        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³\n",
    "        os.makedirs(params['output_path'], exist_ok=True)\n",
    "        \n",
    "        # Huáº¥n luyá»‡n vá»›i callback\n",
    "        self.bi_encoder.model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=params['num_epochs'],\n",
    "            warmup_steps=params['warmup_steps'],\n",
    "            output_path=params[\"output_path\"],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        return self.bi_encoder.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.933704Z",
     "iopub.status.busy": "2025-04-16T17:48:04.933421Z",
     "iopub.status.idle": "2025-04-16T17:48:04.948258Z",
     "shell.execute_reply": "2025-04-16T17:48:04.947562Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.933669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed(self, texts):\n",
    "        print(\"Báº¯t Ä‘áº§u cháº¡y embeddings...\")\n",
    "        texts_embedding = self.model.encode(texts)\n",
    "        texts_embedding = torch.tensor(texts_embedding)\n",
    "\n",
    "        return texts_embedding\n",
    "\n",
    "    def infer(self, corpus, queries):    \n",
    "        class SimilarityModel(nn.Module):\n",
    "            def __init__(self, corpus_embeddings, corpus_cids):\n",
    "                super(SimilarityModel, self).__init__()\n",
    "                self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n",
    "                self.corpus_cids = corpus_cids              # List of CIDs\n",
    "        \n",
    "            def forward(self, question_embedding):\n",
    "                # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n",
    "                question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n",
    "                \n",
    "                # Get the top_n indices with the highest cosine similarity values\n",
    "                sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n",
    "                \n",
    "                \n",
    "                # Return top_n_ids, sorted similarities, and sorted indices\n",
    "                return sorted_similarities, sorted_indices\n",
    "                \n",
    "        # Example device setup\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        # Initialize the similarity model\n",
    "        corpus_embeddings = corpus[\"embedding\"].to(device)\n",
    "        cids = corpus['cid']\n",
    "\n",
    "        query_embeddings = queries['embedding'].to(device)\n",
    "        qids = queries['qid']\n",
    "        \n",
    "        similarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            similarity_model = nn.DataParallel(similarity_model)\n",
    "\n",
    "        self.predictions = []\n",
    "        for qid, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"Processing queries\"):\n",
    "            # Convert question_embedding to tensor and move to the device\n",
    "            query_embedding = query_embedding.to(device)\n",
    "            \n",
    "            # Get the top_n most relevant CIDs\n",
    "            sorted_similarities, sorted_indices = similarity_model(query_embedding)\n",
    "            results = []\n",
    "            for idx in range(len(sorted_similarities)):\n",
    "                doc_id = sorted_indices[idx].item()\n",
    "                score = sorted_similarities[idx].item()\n",
    "                rank = idx\n",
    "                row = (qid + 1, \"Q0\", doc_id + 1, rank + 1, score, \"4Huiter\")\n",
    "                results.append(row)\n",
    "            self.predictions.append(results)\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetrievalApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.949768Z",
     "iopub.status.busy": "2025-04-16T17:48:04.949578Z",
     "iopub.status.idle": "2025-04-16T17:48:04.966386Z",
     "shell.execute_reply": "2025-04-16T17:48:04.965685Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.949752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "class RetrievalApp:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.model = BiEncoder(model_name).model\n",
    "        print(\"Load mÃ´ hÃ¬nh.....\")\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "    \n",
    "    def prepare_data(self, data_file):\n",
    "        \"\"\"\n",
    "        Chuáº©n bá»‹ dá»¯ liá»‡u: chuáº©n bá»‹ cÃ¡c corpus vÃ  queries cho tá»«ng ngÃ´n ngá»¯.\n",
    "        \"\"\"\n",
    "        print(\"Chuáº©n bá»‹ data: ......\")\n",
    "        preparer = DataPreparer()\n",
    "        corpus_file = dict()\n",
    "        queries_file = dict()\n",
    "        langs = list(data_file['corpus'].keys())\n",
    "        \n",
    "        for lang in langs:\n",
    "            print(f\"Chuáº©n bá»‹ data {lang}:.....\")\n",
    "            corpus_file_org = data_file['corpus'][lang]\n",
    "            queries_file_org = data_file['queries'][lang]\n",
    "            corpus_file[lang], queries_file[lang] = preparer.prepare_inference_data(corpus_file_org, queries_file_org, lang)\n",
    "        \n",
    "        return langs, corpus_file, queries_file\n",
    "\n",
    "    def inference(self, langs, corpus_file, queries_file):\n",
    "        \"\"\"\n",
    "        Thá»±c hiá»‡n inference cho tá»«ng ngÃ´n ngá»¯.\n",
    "        \"\"\"\n",
    "        print(\"Báº¯t Ä‘áº§u inference.....\")\n",
    "        corpus, queries = dict(), dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Load data {lang}:.....\")\n",
    "            corpus_file_cur = corpus_file[lang]\n",
    "            queries_file_cur = queries_file[lang]\n",
    "            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n",
    "\n",
    "        inferencer = Inference(self.model)\n",
    "        for lang in langs:\n",
    "            print(f\"Inference {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang]\n",
    "            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n",
    "\n",
    "        return corpus, queries, inferencer\n",
    "\n",
    "    def predict(self, langs, corpus, queries, inferencer):\n",
    "        \"\"\"\n",
    "        Thá»±c hiá»‡n dá»± Ä‘oÃ¡n.\n",
    "        \"\"\"\n",
    "        print(\"Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n:.....\")\n",
    "        predictions = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Dá»± Ä‘oÃ¡n {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang] \n",
    "            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def zip_directory(self, zip_filename, dir_name):\n",
    "        \"\"\"\n",
    "        NÃ©n thÆ° má»¥c thÃ nh file zip mÃ  khÃ´ng sá»­ dá»¥ng Ä‘a luá»“ng.\n",
    "        \"\"\"\n",
    "        print(f\"Äang nÃ©n thÆ° má»¥c {dir_name} thÃ nh {zip_filename}...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Duyá»‡t qua táº¥t cáº£ cÃ¡c file trong thÆ° má»¥c vÃ  nÃ©n chÃºng tuáº§n tá»±\n",
    "            for root, dirs, files in os.walk(dir_name):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, dir_name)  # LÆ°u láº¡i cáº¥u trÃºc thÆ° má»¥c gá»‘c\n",
    "                    zipf.write(file_path, arcname)\n",
    "\n",
    "        print(f\"File zip Ä‘Ã£ Ä‘Æ°á»£c táº¡o: {zip_filename}\")\n",
    "\n",
    "    def save_predictions(self, langs, predictions):\n",
    "        \"\"\"\n",
    "        LÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ o file vÃ  nÃ©n thÆ° má»¥c.\n",
    "        \"\"\"\n",
    "        print(\"Báº¯t Ä‘áº§u xuáº¥t file:....\")\n",
    "        predictions_file = dict()\n",
    "        folder_name = f\"/kaggle/working/talent_clef/predict/{self.model_name}/{Timer.get()}\"\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        for lang in langs:\n",
    "            predictions_file[lang] = utils.write_predictions(predictions[lang], folder_name, lang)\n",
    "        \n",
    "        # NÃ©n thÆ° má»¥c sau khi xuáº¥t file\n",
    "        zip_filename = folder_name + \".zip\"\n",
    "        self.zip_directory(zip_filename, folder_name)\n",
    "        \n",
    "        return predictions_file, zip_filename\n",
    "\n",
    "    def evaluate(self, langs, predictions_file, data):\n",
    "        \"\"\"\n",
    "        ÄÃ¡nh giÃ¡ káº¿t quáº£ dá»± Ä‘oÃ¡n.\n",
    "        \"\"\"\n",
    "        print(\"Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡:.....\")\n",
    "        ratings = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"ÄÃ¡nh giÃ¡ {lang}:.....\")\n",
    "            run_file, qrels_file = predictions_file[lang], data['qrels'][lang]\n",
    "            ratings[lang] = Evaluate.evaluate(run_file, qrels_file)\n",
    "        return ratings\n",
    "\n",
    "    def __call__(self, data_file):\n",
    "        \"\"\"\n",
    "        Ná»‘i cÃ¡c hÃ m láº¡i vá»›i nhau vÃ  cháº¡y toÃ n bá»™ quy trÃ¬nh.\n",
    "        \"\"\"\n",
    "        langs, corpus_file, queries_file = self.prepare_data(data_file)\n",
    "        corpus, queries, inferencer = self.inference(langs, corpus_file, queries_file)\n",
    "        predictions = self.predict(langs, corpus, queries, inferencer)\n",
    "        predictions_file, zip_filename = self.save_predictions(langs, predictions)\n",
    "        ratings = self.evaluate(langs, predictions_file, data_file)\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.967563Z",
     "iopub.status.busy": "2025-04-16T17:48:04.967382Z",
     "iopub.status.idle": "2025-04-16T17:48:04.984269Z",
     "shell.execute_reply": "2025-04-16T17:48:04.983500Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.967548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "def load_git_workspace_wandb():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    git_token = user_secrets.get_secret(\"token_git\")\n",
    "    wandp_api = user_secrets.get_secret(\"wandb_api_key\")\n",
    "\n",
    "    import subprocess\n",
    "\n",
    "    # Thay {git_token} báº±ng token thá»±c táº¿ cá»§a báº¡n\n",
    "    repo_url = f\"https://hoivd:{git_token}@github.com/hoivd/talent_clef\"\n",
    "    \n",
    "    # Lá»‡nh git clone\n",
    "    command = [\"git\", \"clone\", repo_url]\n",
    "    \n",
    "    try:\n",
    "        # Cháº¡y lá»‡nh vÃ  Ä‘á»£i hoÃ n táº¥t\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        print(\"Clone thÃ nh cÃ´ng!\")\n",
    "        print(\"Stdout:\", result.stdout)  # In stdout náº¿u cÃ³\n",
    "        print(\"Stderr:\", result.stderr)  # In stderr Ä‘á»ƒ tháº¥y tiáº¿n trÃ¬nh\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Lá»—i khi clone repository:\")\n",
    "        print(e.stderr)  # In thÃ´ng bÃ¡o lá»—i náº¿u cÃ³\n",
    "        # ÄÄƒng nháº­p W&B\n",
    "    \n",
    "    wandb.login(key=wandp_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.985129Z",
     "iopub.status.busy": "2025-04-16T17:48:04.984922Z",
     "iopub.status.idle": "2025-04-16T17:48:05.001440Z",
     "shell.execute_reply": "2025-04-16T17:48:05.000809Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.985109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class utils:\n",
    "    @staticmethod\n",
    "    def read_csv(input_path, columns=None):\n",
    "        print(\"Äá»c csv file:\")\n",
    "        # Kiá»ƒm tra input_path ngay tá»« Ä‘áº§u\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng (None). Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n file CSV.\")\n",
    "        \n",
    "        try:  \n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8')\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8', names=columns)\n",
    "            print(f\"Äá»c dá»¯ liá»‡u tá»« {input_path} thÃ nh cÃ´ng\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_tsv(input_path, columns=None):\n",
    "        print(\"Äá»c tsv file:\")\n",
    "        # Kiá»ƒm tra input_path ngay tá»« Ä‘áº§u\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng (None). Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n file TSV.\")\n",
    "        \n",
    "        try:  \n",
    "            df = None\n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')  # ThÃªm sep='\\t' cho TSV\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8', names=columns)\n",
    "            \n",
    "            print(f\"Äá»c dá»¯ liá»‡u tá»« {input_path} thÃ nh cÃ´ng\")\n",
    "            print(df.head())\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def write_csv(df, output_path):\n",
    "        try:\n",
    "            # Xuáº¥t ra file CSV\n",
    "            df.to_csv(output_path, sep=',', encoding='utf-8', index=False)\n",
    "            print(f\"ÄÃ£ xuáº¥t dá»¯ liá»‡u ra {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lá»—i khi xuáº¥t file CSV: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def write_predictions(predictions, folder_name, lang):\n",
    "        \n",
    "        output_path = f\"{folder_name}/run_{lang}.trec\"\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                for query_predict in predictions: \n",
    "                    for line in query_predict:  # rank báº¯t Ä‘áº§u tá»« 1\n",
    "                        f.write(' '.join(str(x) for x in line) + '\\n')\n",
    "            print(f\"ÄÃ£ xuáº¥t file TREC ra {output_path}\")  \n",
    "            return output_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lá»—i khi xuáº¥t file TREC: {e}\")\n",
    "            raise\n",
    "\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:05.002627Z",
     "iopub.status.busy": "2025-04-16T17:48:05.002369Z",
     "iopub.status.idle": "2025-04-16T17:48:05.019158Z",
     "shell.execute_reply": "2025-04-16T17:48:05.018410Z",
     "shell.execute_reply.started": "2025-04-16T17:48:05.002599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    @staticmethod\n",
    "    def evaluate(predictions_path, qrels_path):\n",
    "        command = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_path, \"--run\", predictions_path]\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "\n",
    "        return Evaluate.extract_metrics(result)\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_metrics(result, language=\"en-en\"):\n",
    "        stdout = result.stdout\n",
    "        map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n",
    "        mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n",
    "        ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n",
    "        precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n",
    "        precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n",
    "        precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n",
    "    \n",
    "        metrics = {\n",
    "            \"map\": map_value,\n",
    "            \"mrr\": mrr,\n",
    "            \"ndcg\": ndcg,\n",
    "            \"precision@5\": precision_5,\n",
    "            \"precision@10\": precision_10,\n",
    "            \"precision@100\": precision_100\n",
    "        }\n",
    "        return metrics     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:05.020294Z",
     "iopub.status.busy": "2025-04-16T17:48:05.019964Z",
     "iopub.status.idle": "2025-04-16T17:48:05.035322Z",
     "shell.execute_reply": "2025-04-16T17:48:05.034662Z",
     "shell.execute_reply.started": "2025-04-16T17:48:05.020265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ModelLogger:\n",
    "    def __init__(self, model_name, loss_function, num_epochs, metrics, notes=\"\", training_time=None,\n",
    "                 folder=\"/kaggle/working/talent_clef/results\", file_name=\"model_info.csv\"):\n",
    "        self.model_name = model_name\n",
    "        self.loss = loss_function\n",
    "        self.epochs = num_epochs\n",
    "        self.metrics = metrics\n",
    "        self.notes = notes\n",
    "        self.training_time = training_time\n",
    "        self.folder = folder\n",
    "        self.file_path = os.path.join(folder, file_name)\n",
    "    \n",
    "    def compute_average_map(self):\n",
    "        map_values = [lang['map'] for lang in self.metrics.values() if 'map' in lang]\n",
    "        return sum(map_values) / len(map_values) if map_values else None\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"model_name\": [self.model_name],\n",
    "            \"Avg result\": [self.compute_average_map()],\n",
    "            \"en-en result\": [self.metrics.get(\"en-en\", \"\")],\n",
    "            \"es-es result\": [self.metrics.get(\"es-es\", \"\")],\n",
    "            \"de-de result\": [self.metrics.get(\"de-de\", \"\")],\n",
    "            \"zh-zh result\": [self.metrics.get(\"zh-zh\", \"\")],\n",
    "            \"en-es result\": [self.metrics.get(\"en-es\", \"\")],\n",
    "            \"en-de result\": [self.metrics.get(\"en-de\", \"\")],\n",
    "            \"en-zh result\": [self.metrics.get(\"en-zh\", \"\")],\n",
    "            \"loss\": [self.loss],\n",
    "            \"epochs\": [self.epochs],\n",
    "            \"training_time (s)\": [self.training_time],\n",
    "            \"date\": [Timer.get()],\n",
    "            \"notes\": [self.notes]\n",
    "        }\n",
    "\n",
    "    def save(self):\n",
    "        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i\n",
    "        os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "        # Táº¡o DataFrame tá»« dict\n",
    "        df_new = pd.DataFrame(self.to_dict())\n",
    "\n",
    "        if os.path.exists(self.file_path):\n",
    "            df_existing = pd.read_csv(self.file_path)\n",
    "            df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "            df_updated.to_csv(self.file_path, index=False)\n",
    "            print(f\"âœ… ÄÃ£ thÃªm dá»¯ liá»‡u vÃ o file: {self.file_path}\")\n",
    "        else:\n",
    "            df_new.to_csv(self.file_path, index=False)\n",
    "            print(f\"âœ… ÄÃ£ táº¡o file má»›i: {self.file_path}\")\n",
    "\n",
    "    def show_log(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            print(f\"\\nðŸ“„ Ná»™i dung file log:\")\n",
    "            log_df = utils.read_csv(self.file_path)\n",
    "            print(log_df)\n",
    "        else:\n",
    "            print(\"âš ï¸ ChÆ°a cÃ³ file log Ä‘á»ƒ hiá»ƒn thá»‹.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:05.037326Z",
     "iopub.status.busy": "2025-04-16T17:48:05.037097Z",
     "iopub.status.idle": "2025-04-16T17:48:05.052223Z",
     "shell.execute_reply": "2025-04-16T17:48:05.051363Z",
     "shell.execute_reply.started": "2025-04-16T17:48:05.037309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-17_17-01-44\n"
     ]
    }
   ],
   "source": [
    "class Timer:\n",
    "    @staticmethod\n",
    "    def get():\n",
    "        # Láº¥y mÃºi giá» Viá»‡t Nam (UTC+7)\n",
    "        vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n",
    "        \n",
    "        # Láº¥y thá»i gian hiá»‡n táº¡i á»Ÿ UTC\n",
    "        utc_now = datetime.now(pytz.utc)\n",
    "        \n",
    "        # Chuyá»ƒn thá»i gian UTC sang mÃºi giá» Viá»‡t Nam\n",
    "        vietnam_time = utc_now.astimezone(vietnam_timezone)\n",
    "        \n",
    "        # Tráº£ vá» thá»i gian Ä‘Ã£ Ä‘á»‹nh dáº¡ng theo kiá»ƒu YYYY-MM-DD HH:MM:SS\n",
    "        return vietnam_time.strftime(\"%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Gá»i hÃ m vÃ  in káº¿t quáº£\n",
    "print(Timer.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HÃ m thá»±c thi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:15.119452Z",
     "iopub.status.busy": "2025-04-16T17:48:15.119164Z",
     "iopub.status.idle": "2025-04-16T17:48:53.332767Z",
     "shell.execute_reply": "2025-04-16T17:48:53.331878Z",
     "shell.execute_reply.started": "2025-04-16T17:48:15.119430Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clone thÃ nh cÃ´ng!\n",
      "Stdout: \n",
      "Stderr: Cloning into 'talent_clef'...\n",
      "Updating files:  51% (45/88)\n",
      "Updating files:  52% (46/88)\n",
      "Updating files:  53% (47/88)\n",
      "Updating files:  54% (48/88)\n",
      "Updating files:  55% (49/88)\n",
      "Updating files:  56% (50/88)\n",
      "Updating files:  57% (51/88)\n",
      "Updating files:  59% (52/88)\n",
      "Updating files:  60% (53/88)\n",
      "Updating files:  61% (54/88)\n",
      "Updating files:  62% (55/88)\n",
      "Updating files:  63% (56/88)\n",
      "Updating files:  64% (57/88)\n",
      "Updating files:  65% (58/88)\n",
      "Updating files:  67% (59/88)\n",
      "Updating files:  68% (60/88)\n",
      "Updating files:  69% (61/88)\n",
      "Updating files:  70% (62/88)\n",
      "Updating files:  71% (63/88)\n",
      "Updating files:  72% (64/88)\n",
      "Updating files:  73% (65/88)\n",
      "Updating files:  75% (66/88)\n",
      "Updating files:  76% (67/88)\n",
      "Updating files:  77% (68/88)\n",
      "Updating files:  78% (69/88)\n",
      "Updating files:  79% (70/88)\n",
      "Updating files:  80% (71/88)\n",
      "Updating files:  81% (72/88)\n",
      "Updating files:  82% (73/88)\n",
      "Updating files:  84% (74/88)\n",
      "Updating files:  85% (75/88)\n",
      "Updating files:  86% (76/88)\n",
      "Updating files:  87% (77/88)\n",
      "Updating files:  88% (78/88)\n",
      "Updating files:  89% (79/88)\n",
      "Updating files:  90% (80/88)\n",
      "Updating files:  92% (81/88)\n",
      "Updating files:  93% (82/88)\n",
      "Updating files:  94% (83/88)\n",
      "Updating files:  95% (84/88)\n",
      "Updating files:  96% (85/88)\n",
      "Updating files:  97% (86/88)\n",
      "Updating files:  98% (87/88)\n",
      "Updating files: 100% (88/88)\n",
      "Updating files: 100% (88/88), done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoivinh20789\u001b[0m (\u001b[33mhoivinh20789-uit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'talentclef25_evaluation_script'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 27 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (27/27), 10.10 KiB | 5.05 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.2.3)\n",
      "Collecting ranx (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.60.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.13.1)\n",
      "Collecting ir-datasets (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10.12)\n",
      "Collecting lz4 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting cbor2 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.2)\n",
      "Collecting fastparquet (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54.1->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.17.0)\n",
      "Collecting cramjam>=2.3 (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2024.12.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.3)\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (5.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.32.3)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting ijson>=3.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (19.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.7.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.1.31)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\n",
      "Downloading ranx-0.3.20-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
      "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
      "Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Building wheels for collected packages: warc3-wet-clueweb09, cbor\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=e2e5faf45a01afec2f2e0db9c92dff81e6622fc6111e2c550ef15b5333497168\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53430 sha256=2a79b8ac4c34386606a5232d2d6bc51ec6aa4e551a3eba67b3a6974603b10ea3\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
      "Successfully built warc3-wet-clueweb09 cbor\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, cramjam, cbor2, inscriptis, trec-car-tools, ir-datasets, fastparquet, ranx\n",
      "Successfully installed cbor-1.0.0 cbor2-5.6.5 cramjam-2.10.0 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n"
     ]
    }
   ],
   "source": [
    "load_git_workspace_wandb()    \n",
    "\n",
    "!git clone https://github.com/TalentCLEF/talentclef25_evaluation_script.git\n",
    "!pip install -r \"/kaggle/working/talentclef25_evaluation_script/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetrievalApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-16T07:00:12.028109Z",
     "iopub.status.busy": "2025-04-16T07:00:12.026738Z",
     "iopub.status.idle": "2025-04-16T07:03:15.507676Z",
     "shell.execute_reply": "2025-04-16T07:03:15.506823Z",
     "shell.execute_reply.started": "2025-04-16T07:00:12.028074Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device sá»­ dá»¥ng: cuda\n",
      "Táº£i mÃ´ hÃ¬nh tá»« Hugging Face vá»›i tÃªn: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b24251053b543819ae35b2e90e37573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e6fd60ab2a488b89fe83c0d6f27f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcf2c0428d940feac7364e173e9b514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cd1d4033c146bca2a13081956c2266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cc5cddf5d8498ab2abb984a9df394c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa934b43b6654a20bcceb9c2ce9c922e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6bcfac80eb4291b7fdd62e3abc9264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fdc48b080e48a8a6135fd459b5bbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4b6695b07142e59215f79d3bdb35cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb726d9bf2a641219a9ae70e198e4b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fa13ef944e444e900af9a21d8e3437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\n",
      "Load mÃ´ hÃ¬nh.....\n",
      "Chuáº©n bá»‹ data: ......\n",
      "Chuáº©n bá»‹ data en-en:.....\n",
      "Äá»c dá»¯ liá»‡u inference:\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements thÃ nh cÃ´ng\n",
      "   c_id                          jobtitle\n",
      "0     1                recording engineer\n",
      "1     2              director of taxation\n",
      "2     3  technical support representative\n",
      "3     4                        hr manager\n",
      "4     5           computer graphic artist\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/english/queries thÃ nh cÃ´ng\n",
      "   q_id             jobtitle\n",
      "0     1                nanny\n",
      "1     2    food technologist\n",
      "2     3   broadcast engineer\n",
      "3     4  automation engineer\n",
      "4     5         veterinarian\n",
      "Xuáº¥t dá»¯ liá»‡u inference:\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_en-en.csv\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_en-en.csv\n",
      "Chuáº©n bá»‹ data de-de:.....\n",
      "Äá»c dá»¯ liá»‡u inference:\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements thÃ nh cÃ´ng\n",
      "   c_id                   jobtitle\n",
      "0     1               pr-managerin\n",
      "1     2       talkshow-moderatorin\n",
      "2     3             sporttrainerin\n",
      "3     4         preiskoordinatorin\n",
      "4     5  persoÌˆnlicher bankberater\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/german/queries thÃ nh cÃ´ng\n",
      "   q_id                        jobtitle\n",
      "0     1           technischer recruiter\n",
      "1     2                    brieftraÌˆger\n",
      "2     3              grundschullehrerin\n",
      "3     4                     3d-animator\n",
      "4     5  unternehmensstrategieberaterin\n",
      "Xuáº¥t dá»¯ liá»‡u inference:\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_de-de.csv\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_de-de.csv\n",
      "Chuáº©n bá»‹ data es-es:.....\n",
      "Äá»c dá»¯ liá»‡u inference:\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements thÃ nh cÃ´ng\n",
      "   c_id                         jobtitle\n",
      "0     1               desarrollador java\n",
      "1     2         diseÃ±adora de accesorios\n",
      "2     3  agente inmobiliario residencial\n",
      "3     4           planificador de ventas\n",
      "4     5          ayudante de conferencia\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/spanish/queries thÃ nh cÃ´ng\n",
      "   q_id                        jobtitle\n",
      "0     1     ingeniera de automatizaciÃ³n\n",
      "1     2  tÃ©cnica de soporte informÃ¡tico\n",
      "2     3                 piloto de aviÃ³n\n",
      "3     4   ingeniera de diseÃ±o analÃ³gico\n",
      "4     5      analista de capital riesgo\n",
      "Xuáº¥t dá»¯ liá»‡u inference:\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_es-es.csv\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_es-es.csv\n",
      "Chuáº©n bá»‹ data zh-zh:.....\n",
      "Äá»c dá»¯ liá»‡u inference:\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements thÃ nh cÃ´ng\n",
      "   c_id jobtitle\n",
      "0     1   è‡ªåŠ¨åŒ–æŠ€æœ¯å‘˜\n",
      "1     2    é€‰è§’åˆ¶ä½œäºº\n",
      "2     3     ä½“è‚²ç»ç†\n",
      "3     4     ä¸´æ—¶åŠ©ç†\n",
      "4     5  ç”¨æˆ·æ”¯æŒæŠ€æœ¯å‘˜\n",
      "Äá»c tsv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/data/TaskA/validation/chinese/queries thÃ nh cÃ´ng\n",
      "   q_id jobtitle\n",
      "0     1     è´·æ¬¾å¹²äº‹\n",
      "1     2     ç¨ŽåŠ¡ä¼šè®¡\n",
      "2     3    çŠ¬ç±»ç¾Žå®¹å¸ˆ\n",
      "3     4      æ”¶é“¶å‘˜\n",
      "4     5      ç­¹æ¬¾äºº\n",
      "Xuáº¥t dá»¯ liá»‡u inference:\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/corpus_zh-zh.csv\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/queries_zh-zh.csv\n",
      "Báº¯t Ä‘áº§u inference.....\n",
      "Load data en-en:.....\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_en-en.csv thÃ nh cÃ´ng\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_en-en.csv thÃ nh cÃ´ng\n",
      "Load data de-de:.....\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_de-de.csv thÃ nh cÃ´ng\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_de-de.csv thÃ nh cÃ´ng\n",
      "Load data es-es:.....\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_es-es.csv thÃ nh cÃ´ng\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_es-es.csv thÃ nh cÃ´ng\n",
      "Load data zh-zh:.....\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/corpus_zh-zh.csv thÃ nh cÃ´ng\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/queries_zh-zh.csv thÃ nh cÃ´ng\n",
      "Inference en-en:.....\n",
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944b0f274ca949f8bc6649696f38df98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675bb84777584c00b196f2b659d07660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference de-de:.....\n",
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983c6b1488904cf6be153c355d510093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5420865a79ec48bcac87650f1a0d9713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference es-es:.....\n",
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bafe21040c402391383cef3f21390b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487509a4f2bc4643b7921e1fcdbf1006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference zh-zh:.....\n",
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f827d474414559aa875ff4a127f87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báº¯t Ä‘áº§u cháº¡y embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c8a26da57491c9f918c0eab28b286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n:.....\n",
      "Dá»± Ä‘oÃ¡n en-en:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:08<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»± Ä‘oÃ¡n de-de:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203/203 [00:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»± Ä‘oÃ¡n es-es:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [00:26<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»± Ä‘oÃ¡n zh-zh:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:07<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báº¯t Ä‘áº§u xuáº¥t file:....\n",
      "ÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_en-en.trec\n",
      "ÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_de-de.trec\n",
      "ÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_es-es.trec\n",
      "ÄÃ£ xuáº¥t file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_zh-zh.trec\n",
      "Äang nÃ©n thÆ° má»¥c /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37 thÃ nh /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip...\n",
      "File zip Ä‘Ã£ Ä‘Æ°á»£c táº¡o: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip\n",
      "Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡:.....\n",
      "ÄÃ¡nh giÃ¡ en-en:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_en-en.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.4966\n",
      "mrr: 0.7638\n",
      "ndcg: 0.7669\n",
      "precision@5: 0.6762\n",
      "precision@10: 0.5914\n",
      "precision@100: 0.1617\n",
      "\n",
      "ÄÃ¡nh giÃ¡ de-de:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_de-de.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.2091\n",
      "mrr: 0.4842\n",
      "ndcg: 0.5713\n",
      "precision@5: 0.4591\n",
      "precision@10: 0.4365\n",
      "precision@100: 0.1380\n",
      "\n",
      "ÄÃ¡nh giÃ¡ es-es:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_es-es.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.2840\n",
      "mrr: 0.5421\n",
      "ndcg: 0.6307\n",
      "precision@5: 0.5741\n",
      "precision@10: 0.5259\n",
      "precision@100: 0.1583\n",
      "\n",
      "ÄÃ¡nh giÃ¡ zh-zh:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_zh-zh.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.1344\n",
      "mrr: 0.3855\n",
      "ndcg: 0.4553\n",
      "precision@5: 0.2466\n",
      "precision@10: 0.2214\n",
      "precision@100: 0.0541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data = {\n",
    "#     \"corpus\": {\n",
    "#         \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements\",\n",
    "#         \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements\",\n",
    "#         \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements\",\n",
    "#         \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements\"\n",
    "#     },\n",
    "    \n",
    "#     \"queries\":{\n",
    "#         \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/queries\",\n",
    "#         \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/queries\",\n",
    "#         \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/queries\",\n",
    "#         \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/queries\"\n",
    "#     },\n",
    "    \n",
    "#     \"qrels\": {\n",
    "#         \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\",\n",
    "#         \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\",\n",
    "#         \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\",\n",
    "#         \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# app = RetrievalApp(model_name)\n",
    "# ratings = app(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T18:00:10.156528Z",
     "iopub.status.busy": "2025-04-16T18:00:10.156236Z",
     "iopub.status.idle": "2025-04-16T18:00:19.762955Z",
     "shell.execute_reply": "2025-04-16T18:00:19.762026Z",
     "shell.execute_reply.started": "2025-04-16T18:00:10.156508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Äá»c dá»¯ liá»‡u train_org:\n",
      "                       jobtitle  \\\n",
      "0    director of technical arts   \n",
      "0          technical supervisor   \n",
      "0             technical manager   \n",
      "0  head of technical department   \n",
      "0            technical director   \n",
      "\n",
      "                                               skill  label  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "Cá»™t dá»¯ liá»‡u: Index(['jobtitle', 'skill', 'label'], dtype='object')\n",
      "Xuáº¥t dá»¯ liá»‡u train sau khi chuáº©n bá»‹:\n",
      "ÄÃ£ xuáº¥t dá»¯ liá»‡u ra /kaggle/working/train.csv\n"
     ]
    }
   ],
   "source": [
    "train_data_org_file = \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"\n",
    "preparer = DataPreparer()\n",
    "train_data, train_file = preparer.prepare_train_data(train_data_org_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T18:03:57.739904Z",
     "iopub.status.busy": "2025-04-16T18:03:57.739587Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/train.csv thÃ nh cÃ´ng\n",
      "Device sá»­ dá»¥ng: cuda\n",
      "Táº£i mÃ´ hÃ¬nh tá»« Hugging Face vá»›i tÃªn: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153bc3b0cdc049cda5a42cbde2b9d15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06982a3ec0f048ec92bdfefd61a409d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b77bc74fd3949549c22899e27f30943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945e0da701774e9b98f67bf2ff4c4082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c732fd1a618b4d23b08171a6c1bd84f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d8ab31d5ea496d8a8ac5f83ea9ae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf04bd85d9947b8bd904c62c0a6ef32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6064adda0e9c41019ae84e197bb2d645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86c651139e7488f82d0eddbef6e0396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f0f218c6e04a8695fdc059633a46b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng!\n",
      "Khá»Ÿi táº¡o dataset:\n",
      "Báº¯t Ä‘áº§u train: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_180418-0f3b4yz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers' target=\"_blank\">https://wandb.ai/hoivinh20789-uit/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7' target=\"_blank\">https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2387' max='3376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2387/3376 07:34 < 03:08, 5.25 it/s, Epoch 1.41/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.158100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = Dataset.load_train_data(train_file)\n",
    "dataset = Dataset(train_data)\n",
    "\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "loss = losses.MultipleNegativesRankingLoss\n",
    "\n",
    "params = {\n",
    "    \"num_epochs\": 2,\n",
    "    \"output_path\": f\"/kaggle/working/talent_clef/model/{model_name}/epoch2\",\n",
    "    \"warmup_steps\": 100,\n",
    "}\n",
    "\n",
    "trainer = Trainer(model_name)\n",
    "model = trainer.train(dataset.data, loss, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Log Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:04:41.791344Z",
     "iopub.status.busy": "2025-04-16T07:04:41.790975Z",
     "iopub.status.idle": "2025-04-16T07:04:41.812873Z",
     "shell.execute_reply": "2025-04-16T07:04:41.812119Z",
     "shell.execute_reply.started": "2025-04-16T07:04:41.791314Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ thÃªm dá»¯ liá»‡u vÃ o file: /kaggle/working/talent_clef/results/model_info.csv\n",
      "\n",
      "ðŸ“„ Ná»™i dung file log:\n",
      "Äá»c csv file:\n",
      "Äá»c dá»¯ liá»‡u tá»« /kaggle/working/talent_clef/results/model_info.csv thÃ nh cÃ´ng\n",
      "                               model_name  Avg result  \\\n",
      "0                jjzha/jobbert-base-cased    0.271500   \n",
      "1                           agne/jobGBERT    0.260500   \n",
      "2  sentence-transformers/all-MiniLM-L6-v2    0.496600   \n",
      "3  sentence-transformers/all-MiniLM-L6-v2    0.551900   \n",
      "4  sentence-transformers/all-MiniLM-L6-v2    0.563200   \n",
      "5  sentence-transformers/all-MiniLM-L6-v2    0.563600   \n",
      "6  sentence-transformers/all-MiniLM-L6-v2    0.281025   \n",
      "\n",
      "                                        en-en result  \\\n",
      "0  {'map': 0.2715, 'mrr': 0.6136, 'ndcg': 0.6032,...   \n",
      "1  {'map': 0.2605, 'mrr': 0.634, 'ndcg': 0.5962, ...   \n",
      "2  {'map': 0.4966, 'mrr': 0.7638, 'ndcg': 0.7669,...   \n",
      "3  {'map': 0.5519, 'mrr': 0.7946, 'ndcg': 0.8011,...   \n",
      "4  {'map': 0.5632, 'mrr': 0.8045, 'ndcg': 0.8085,...   \n",
      "5  {'map': 0.5636, 'mrr': 0.8087, 'ndcg': 0.809, ...   \n",
      "6  {'map': 0.4966, 'mrr': 0.7638, 'ndcg': 0.7669,...   \n",
      "\n",
      "                                        es-es result  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "5                                                NaN   \n",
      "6  {'map': 0.284, 'mrr': 0.5421, 'ndcg': 0.6307, ...   \n",
      "\n",
      "                                        de-de result  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "5                                                NaN   \n",
      "6  {'map': 0.2091, 'mrr': 0.4842, 'ndcg': 0.5713,...   \n",
      "\n",
      "                                        zh-zh result  en-es result  \\\n",
      "0                                                NaN           NaN   \n",
      "1                                                NaN           NaN   \n",
      "2                                                NaN           NaN   \n",
      "3                                                NaN           NaN   \n",
      "4                                                NaN           NaN   \n",
      "5                                                NaN           NaN   \n",
      "6  {'map': 0.1344, 'mrr': 0.3855, 'ndcg': 0.4553,...           NaN   \n",
      "\n",
      "   en-de result  en-zh result                          loss  epochs  \\\n",
      "0           NaN           NaN                           NaN     NaN   \n",
      "1           NaN           NaN                           NaN     NaN   \n",
      "2           NaN           NaN                           NaN     NaN   \n",
      "3           NaN           NaN  MultipleNegativesRankingLoss     1.0   \n",
      "4           NaN           NaN  MultipleNegativesRankingLoss     3.0   \n",
      "5           NaN           NaN  MultipleNegativesRankingLoss     1.0   \n",
      "6           NaN           NaN                           NaN     NaN   \n",
      "\n",
      "   training_time (s)                 date  \\\n",
      "0                NaN  22-03-2025 05:40:16   \n",
      "1                NaN  22-03-2025 05:43:05   \n",
      "2                NaN  22-03-2025 05:46:41   \n",
      "3                NaN  22-03-2025 05:55:41   \n",
      "4                NaN  22-03-2025 06:18:46   \n",
      "5                NaN  01-04-2025 14:46:32   \n",
      "6                NaN       04-16_14-04-41   \n",
      "\n",
      "                                            notes  \n",
      "0                                            Test  \n",
      "1                                            Test  \n",
      "2                                            Test  \n",
      "3                                            Test  \n",
      "4                                            Test  \n",
      "5  thÃªm negative pair vÃ  finetune tiáº¿p tá»« epoch 3  \n",
      "6  thÃªm negative pair vÃ  finetune tiáº¿p tá»« epoch 5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-08bc3e49c7e0>:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "logger = ModelLogger(\n",
    "    model_name=model_name,\n",
    "    loss_function=None,\n",
    "    num_epochs=None,\n",
    "    metrics=ratings,\n",
    "    notes=\"thÃªm negative pair vÃ  finetune tiáº¿p tá»« epoch 5\"\n",
    ")\n",
    "\n",
    "logger.save()\n",
    "logger.show_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:08:08.896966Z",
     "iopub.status.busy": "2025-04-16T07:08:08.896529Z",
     "iopub.status.idle": "2025-04-16T07:08:08.903988Z",
     "shell.execute_reply": "2025-04-16T07:08:08.903291Z",
     "shell.execute_reply.started": "2025-04-16T07:08:08.896911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/talent_clef\n"
     ]
    }
   ],
   "source": [
    "cd talent_clef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:05:26.934527Z",
     "iopub.status.busy": "2025-04-16T07:05:26.934227Z",
     "iopub.status.idle": "2025-04-16T07:05:26.938489Z",
     "shell.execute_reply": "2025-04-16T07:05:26.937550Z",
     "shell.execute_reply.started": "2025-04-16T07:05:26.934505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "brand_name = model_name + \"/\" +Timer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:05:29.045592Z",
     "iopub.status.busy": "2025-04-16T07:05:29.045282Z",
     "iopub.status.idle": "2025-04-16T07:05:29.050430Z",
     "shell.execute_reply": "2025-04-16T07:05:29.049619Z",
     "shell.execute_reply.started": "2025-04-16T07:05:29.045564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:08:12.273020Z",
     "iopub.status.busy": "2025-04-16T07:08:12.272698Z",
     "iopub.status.idle": "2025-04-16T07:08:33.682946Z",
     "shell.execute_reply": "2025-04-16T07:08:33.681928Z",
     "shell.execute_reply.started": "2025-04-16T07:08:12.272997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26'\n",
      "On branch sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   results/model_info.csv\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mpredict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip\u001b[m\n",
      "\t\u001b[31mpredict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "[sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26 b17b3c4] updated\n",
      " 6 files changed, 2356107 insertions(+)\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_de-de.trec\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_en-en.trec\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_es-es.trec\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_zh-zh.trec\n",
      "Enumerating objects: 19, done.\n",
      "Counting objects: 100% (19/19), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (11/11), done.\n",
      "Writing objects: 100% (13/13), 61.35 MiB | 6.52 MiB/s, done.\n",
      "Total 13 (delta 4), reused 1 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "remote: \n",
      "remote: Create a pull request for 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26' on GitHub by visiting:\u001b[K\n",
      "remote:      https://github.com/hoivd/talent_clef/pull/new/sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26\u001b[K\n",
      "remote: \n",
      "To https://github.com/hoivd/talent_clef\n",
      " * [new branch]      sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26 -> sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26\n",
      "Branch 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26' set up to track remote branch 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"hoivd79@gmail.com\"\n",
    "!git config --global user.name \"Dang Vinh Hoi\"\n",
    "!git checkout -b {brand_name}      # Táº¡o vÃ  chuyá»ƒn sang nhÃ¡nh dev\n",
    "!git status\n",
    "!git add .\n",
    "!git commit -m \"updated\"\n",
    "!git push -u origin {brand_name}    # Push láº§n Ä‘áº§u, thiáº¿t láº­p tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T07:22:00.506117Z",
     "iopub.status.busy": "2025-04-14T07:22:00.505775Z",
     "iopub.status.idle": "2025-04-14T07:22:00.512221Z",
     "shell.execute_reply": "2025-04-14T07:22:00.511293Z",
     "shell.execute_reply.started": "2025-04-14T07:22:00.506086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/talent_clef\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
