{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.806493Z",
     "iopub.status.busy": "2025-04-16T17:48:04.806201Z",
     "iopub.status.idle": "2025-04-16T17:48:04.811309Z",
     "shell.execute_reply": "2025-04-16T17:48:04.810444Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.806472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchmetrics.retrieval import RetrievalMAP\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import wandb\n",
    "import ast\n",
    "import subprocess\n",
    "import pickle\n",
    "import shutil\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PositiveExampleMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.812509Z",
     "iopub.status.busy": "2025-04-16T17:48:04.812223Z",
     "iopub.status.idle": "2025-04-16T17:48:04.833696Z",
     "shell.execute_reply": "2025-04-16T17:48:04.832894Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.812487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MiningPosExample:\n",
    "    def __init__(self):\n",
    "        self.data = None  # Khởi tạo thuộc tính self.data là None\n",
    "\n",
    "     # Phương thức __len__ để trả về số dòng của data\n",
    "    def __len__(self):\n",
    "        if self.data is not None:\n",
    "            return len(self.data)\n",
    "        return 0  # Nếu self.data chưa được gán (None), trả về 0\n",
    "    \n",
    "    # Phương thức __getitem__ để truy xuất một dòng trong data theo chỉ số\n",
    "    def __getitem__(self, index):\n",
    "        if self.data is not None:\n",
    "            return self.data.iloc[index]\n",
    "        raise IndexError(\"Index out of range\")  # Nếu self.data là None, raise lỗi\n",
    "        \n",
    "    def mining_pos_example(self, data_file):\n",
    "        # Đọc dữ liệu từ file (giả sử là file CSV)\n",
    "        df = pd.read_csv(data_file)\n",
    "        df['jobtitles'] = df['jobtitles'].apply(ast.literal_eval)\n",
    "        # Lấy các cột 'jobtitles' và 'skills_gen', sau đó \"phân nổ\" danh sách trong cột 'jobtitles'\n",
    "        new_df = df[['jobtitles', 'skills_gen']].explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n",
    "        \n",
    "        # Thêm cột 'label' với giá trị toàn bộ là 1\n",
    "        new_df['label'] = 1\n",
    "        \n",
    "        # Lưu kết quả vào self.data\n",
    "        self.data = new_df\n",
    "        \n",
    "        return new_df\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataPrepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:59:44.847386Z",
     "iopub.status.busy": "2025-04-16T17:59:44.847026Z",
     "iopub.status.idle": "2025-04-16T17:59:44.852758Z",
     "shell.execute_reply": "2025-04-16T17:59:44.851982Z",
     "shell.execute_reply.started": "2025-04-16T17:59:44.847362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DataPreparer:\n",
    "    def prepare_train_data(self, train_data_org_file):\n",
    "        print(\"Đọc dữ liệu train_org:\")\n",
    "        \n",
    "        pos_miner = MiningPosExample()\n",
    "        pos_example_df = pos_miner.mining_pos_example(train_data_org_file)\n",
    "        print(pos_example_df.head())\n",
    "\n",
    "        train_df = pos_example_df\n",
    "        print(f\"Cột dữ liệu: {train_df.columns}\")\n",
    "        print(\"Xuất dữ liệu train sau khi chuẩn bị:\")\n",
    "        train_file = \"/kaggle/working/train.csv\"\n",
    "        utils.write_csv(train_df, train_file)\n",
    "        return train_df, train_file\n",
    "\n",
    "    def prepare_inference_data(self, corpus_path, queries_path, lang):\n",
    "        print(\"Đọc dữ liệu inference:\")\n",
    "        corpus_df = utils.read_tsv(corpus_path)\n",
    "        queries_df = utils.read_tsv(queries_path)\n",
    "        \n",
    "        print(\"Xuất dữ liệu inference:\")\n",
    "        corpus_out_path = f\"/kaggle/working/corpus_{lang}.csv\"\n",
    "        queries_out_path = f\"/kaggle/working/queries_{lang}.csv\"\n",
    "        utils.write_csv(corpus_df, corpus_out_path)\n",
    "        utils.write_csv(queries_df, queries_out_path)\n",
    "        return corpus_out_path, queries_out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T18:01:57.061531Z",
     "iopub.status.busy": "2025-04-16T18:01:57.061178Z",
     "iopub.status.idle": "2025-04-16T18:01:57.068841Z",
     "shell.execute_reply": "2025-04-16T18:01:57.067845Z",
     "shell.execute_reply.started": "2025-04-16T18:01:57.061504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = []\n",
    "        for jobtitle, skill, label in data:\n",
    "            self.data.append(InputExample(texts = [jobtitle, skill], label=label))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Trả về số lượng mẫu trong dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def load_train_data(train_path):\n",
    "        train_df = utils.read_csv(train_path)\n",
    "        jobtitles =  train_df['jobtitle'].tolist()\n",
    "        skills =  train_df['skill'].tolist()\n",
    "        labels = train_df['label'].tolist()\n",
    "\n",
    "        data = []\n",
    "        for idx, jobtitle in enumerate(jobtitles):\n",
    "            data.append((jobtitle, skills[idx], labels[idx]))\n",
    "        return data\n",
    "        \n",
    "    @staticmethod  \n",
    "    def load_inference_data(corpus_path, queries_path):\n",
    "        corpus_df = utils.read_csv(corpus_path)\n",
    "        queries_df = utils.read_csv(queries_path)\n",
    "        \n",
    "        cids_l = corpus_df['c_id'].tolist()\n",
    "        corpus_l = corpus_df['jobtitle'].tolist()\n",
    "        qids_l = queries_df['q_id'].tolist()\n",
    "        queries_l = queries_df['jobtitle'].tolist()\n",
    "\n",
    "        corpus = {\"cid\": cids_l,\n",
    "                \"jobtitle\": corpus_l\n",
    "                }\n",
    "\n",
    "        queries = {\"qid\": qids_l,\n",
    "                \"jobtitle\": queries_l\n",
    "                }\n",
    "        return corpus, queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.867422Z",
     "iopub.status.busy": "2025-04-16T17:48:04.867155Z",
     "iopub.status.idle": "2025-04-16T17:48:04.883747Z",
     "shell.execute_reply": "2025-04-16T17:48:04.882978Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.867391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BiEncoder:\n",
    "    def __init__(self, model_name=None, model_path=None):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Device sử dụng:\", device)\n",
    "        \n",
    "        try:\n",
    "            if model_path is None:\n",
    "                print(f\"Tải mô hình từ Hugging Face với tên: {model_name}\")\n",
    "                self.model = SentenceTransformer(model_name)\n",
    "            else:\n",
    "                print(f\"Tải mô hình từ đường dẫn cục bộ: {model_path}\")\n",
    "                self.model = SentenceTransformer(model_path)\n",
    "            \n",
    "            # Đặt mô hình lên thiết bị\n",
    "            self.model = self.model.to(device)\n",
    "            print(\"Mô hình đã được khởi tạo thành công!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi khởi tạo mô hình: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.927617Z",
     "iopub.status.busy": "2025-04-16T17:48:04.927431Z",
     "iopub.status.idle": "2025-04-16T17:48:04.932346Z",
     "shell.execute_reply": "2025-04-16T17:48:04.931532Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.927601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.bi_encoder = BiEncoder(model_name, model_path)\n",
    "\n",
    "    def train(self, dataset, loss, params):\n",
    "        print(\"Khởi tạo dataset:\")\n",
    "        train_dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n",
    "\n",
    "        print(\"Bắt đầu train: \")\n",
    "\n",
    "         # Khởi tạo hàm mất mát\n",
    "        train_loss = loss(self.bi_encoder.model)\n",
    "        \n",
    "        # Tạo thư mục nếu chưa có\n",
    "        os.makedirs(params['output_path'], exist_ok=True)\n",
    "        \n",
    "        # Huấn luyện với callback\n",
    "        self.bi_encoder.model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=params['num_epochs'],\n",
    "            warmup_steps=params['warmup_steps'],\n",
    "            output_path=params[\"output_path\"],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        return self.bi_encoder.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.933704Z",
     "iopub.status.busy": "2025-04-16T17:48:04.933421Z",
     "iopub.status.idle": "2025-04-16T17:48:04.948258Z",
     "shell.execute_reply": "2025-04-16T17:48:04.947562Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.933669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed(self, texts):\n",
    "        print(\"Bắt đầu chạy embeddings...\")\n",
    "        texts_embedding = self.model.encode(texts)\n",
    "        texts_embedding = torch.tensor(texts_embedding)\n",
    "\n",
    "        return texts_embedding\n",
    "\n",
    "    def infer(self, corpus, queries):    \n",
    "        class SimilarityModel(nn.Module):\n",
    "            def __init__(self, corpus_embeddings, corpus_cids):\n",
    "                super(SimilarityModel, self).__init__()\n",
    "                self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n",
    "                self.corpus_cids = corpus_cids              # List of CIDs\n",
    "        \n",
    "            def forward(self, question_embedding):\n",
    "                # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n",
    "                question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n",
    "                \n",
    "                # Get the top_n indices with the highest cosine similarity values\n",
    "                sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n",
    "                \n",
    "                \n",
    "                # Return top_n_ids, sorted similarities, and sorted indices\n",
    "                return sorted_similarities, sorted_indices\n",
    "                \n",
    "        # Example device setup\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        # Initialize the similarity model\n",
    "        corpus_embeddings = corpus[\"embedding\"].to(device)\n",
    "        cids = corpus['cid']\n",
    "\n",
    "        query_embeddings = queries['embedding'].to(device)\n",
    "        qids = queries['qid']\n",
    "        \n",
    "        similarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            similarity_model = nn.DataParallel(similarity_model)\n",
    "\n",
    "        self.predictions = []\n",
    "        for qid, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"Processing queries\"):\n",
    "            # Convert question_embedding to tensor and move to the device\n",
    "            query_embedding = query_embedding.to(device)\n",
    "            \n",
    "            # Get the top_n most relevant CIDs\n",
    "            sorted_similarities, sorted_indices = similarity_model(query_embedding)\n",
    "            results = []\n",
    "            for idx in range(len(sorted_similarities)):\n",
    "                doc_id = sorted_indices[idx].item()\n",
    "                score = sorted_similarities[idx].item()\n",
    "                rank = idx\n",
    "                row = (qid + 1, \"Q0\", doc_id + 1, rank + 1, score, \"4Huiter\")\n",
    "                results.append(row)\n",
    "            self.predictions.append(results)\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetrievalApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.949768Z",
     "iopub.status.busy": "2025-04-16T17:48:04.949578Z",
     "iopub.status.idle": "2025-04-16T17:48:04.966386Z",
     "shell.execute_reply": "2025-04-16T17:48:04.965685Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.949752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "class RetrievalApp:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.model = BiEncoder(model_name).model\n",
    "        print(\"Load mô hình.....\")\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "    \n",
    "    def prepare_data(self, data_file):\n",
    "        \"\"\"\n",
    "        Chuẩn bị dữ liệu: chuẩn bị các corpus và queries cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Chuẩn bị data: ......\")\n",
    "        preparer = DataPreparer()\n",
    "        corpus_file = dict()\n",
    "        queries_file = dict()\n",
    "        langs = list(data_file['corpus'].keys())\n",
    "        \n",
    "        for lang in langs:\n",
    "            print(f\"Chuẩn bị data {lang}:.....\")\n",
    "            corpus_file_org = data_file['corpus'][lang]\n",
    "            queries_file_org = data_file['queries'][lang]\n",
    "            corpus_file[lang], queries_file[lang] = preparer.prepare_inference_data(corpus_file_org, queries_file_org, lang)\n",
    "        \n",
    "        return langs, corpus_file, queries_file\n",
    "\n",
    "    def inference(self, langs, corpus_file, queries_file):\n",
    "        \"\"\"\n",
    "        Thực hiện inference cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu inference.....\")\n",
    "        corpus, queries = dict(), dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Load data {lang}:.....\")\n",
    "            corpus_file_cur = corpus_file[lang]\n",
    "            queries_file_cur = queries_file[lang]\n",
    "            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n",
    "\n",
    "        inferencer = Inference(self.model)\n",
    "        for lang in langs:\n",
    "            print(f\"Inference {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang]\n",
    "            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n",
    "\n",
    "        return corpus, queries, inferencer\n",
    "\n",
    "    def predict(self, langs, corpus, queries, inferencer):\n",
    "        \"\"\"\n",
    "        Thực hiện dự đoán.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu dự đoán:.....\")\n",
    "        predictions = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Dự đoán {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang] \n",
    "            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def zip_directory(self, zip_filename, dir_name):\n",
    "        \"\"\"\n",
    "        Nén thư mục thành file zip mà không sử dụng đa luồng.\n",
    "        \"\"\"\n",
    "        print(f\"Đang nén thư mục {dir_name} thành {zip_filename}...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Duyệt qua tất cả các file trong thư mục và nén chúng tuần tự\n",
    "            for root, dirs, files in os.walk(dir_name):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, dir_name)  # Lưu lại cấu trúc thư mục gốc\n",
    "                    zipf.write(file_path, arcname)\n",
    "\n",
    "        print(f\"File zip đã được tạo: {zip_filename}\")\n",
    "\n",
    "    def save_predictions(self, langs, predictions):\n",
    "        \"\"\"\n",
    "        Lưu kết quả dự đoán vào file và nén thư mục.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu xuất file:....\")\n",
    "        predictions_file = dict()\n",
    "        folder_name = f\"/kaggle/working/talent_clef/predict/{self.model_name}/{Timer.get()}\"\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        for lang in langs:\n",
    "            predictions_file[lang] = utils.write_predictions(predictions[lang], folder_name, lang)\n",
    "        \n",
    "        # Nén thư mục sau khi xuất file\n",
    "        zip_filename = folder_name + \".zip\"\n",
    "        self.zip_directory(zip_filename, folder_name)\n",
    "        \n",
    "        return predictions_file, zip_filename\n",
    "\n",
    "    def evaluate(self, langs, predictions_file, data):\n",
    "        \"\"\"\n",
    "        Đánh giá kết quả dự đoán.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu đánh giá:.....\")\n",
    "        ratings = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Đánh giá {lang}:.....\")\n",
    "            run_file, qrels_file = predictions_file[lang], data['qrels'][lang]\n",
    "            ratings[lang] = Evaluate.evaluate(run_file, qrels_file)\n",
    "        return ratings\n",
    "\n",
    "    def __call__(self, data_file):\n",
    "        \"\"\"\n",
    "        Nối các hàm lại với nhau và chạy toàn bộ quy trình.\n",
    "        \"\"\"\n",
    "        langs, corpus_file, queries_file = self.prepare_data(data_file)\n",
    "        corpus, queries, inferencer = self.inference(langs, corpus_file, queries_file)\n",
    "        predictions = self.predict(langs, corpus, queries, inferencer)\n",
    "        predictions_file, zip_filename = self.save_predictions(langs, predictions)\n",
    "        ratings = self.evaluate(langs, predictions_file, data_file)\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.967563Z",
     "iopub.status.busy": "2025-04-16T17:48:04.967382Z",
     "iopub.status.idle": "2025-04-16T17:48:04.984269Z",
     "shell.execute_reply": "2025-04-16T17:48:04.983500Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.967548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "def load_git_workspace_wandb():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    git_token = user_secrets.get_secret(\"token_git\")\n",
    "    wandp_api = user_secrets.get_secret(\"wandb_api_key\")\n",
    "\n",
    "    import subprocess\n",
    "\n",
    "    # Thay {git_token} bằng token thực tế của bạn\n",
    "    repo_url = f\"https://hoivd:{git_token}@github.com/hoivd/talent_clef\"\n",
    "    \n",
    "    # Lệnh git clone\n",
    "    command = [\"git\", \"clone\", repo_url]\n",
    "    \n",
    "    try:\n",
    "        # Chạy lệnh và đợi hoàn tất\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        print(\"Clone thành công!\")\n",
    "        print(\"Stdout:\", result.stdout)  # In stdout nếu có\n",
    "        print(\"Stderr:\", result.stderr)  # In stderr để thấy tiến trình\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Lỗi khi clone repository:\")\n",
    "        print(e.stderr)  # In thông báo lỗi nếu có\n",
    "        # Đăng nhập W&B\n",
    "    \n",
    "    wandb.login(key=wandp_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:04.985129Z",
     "iopub.status.busy": "2025-04-16T17:48:04.984922Z",
     "iopub.status.idle": "2025-04-16T17:48:05.001440Z",
     "shell.execute_reply": "2025-04-16T17:48:05.000809Z",
     "shell.execute_reply.started": "2025-04-16T17:48:04.985109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class utils:\n",
    "    @staticmethod\n",
    "    def read_csv(input_path, columns=None):\n",
    "        print(\"Đọc csv file:\")\n",
    "        # Kiểm tra input_path ngay từ đầu\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file CSV.\")\n",
    "        \n",
    "        try:  \n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8')\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8', names=columns)\n",
    "            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_tsv(input_path, columns=None):\n",
    "        print(\"Đọc tsv file:\")\n",
    "        # Kiểm tra input_path ngay từ đầu\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file TSV.\")\n",
    "        \n",
    "        try:  \n",
    "            df = None\n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')  # Thêm sep='\\t' cho TSV\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8', names=columns)\n",
    "            \n",
    "            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n",
    "            print(df.head())\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def write_csv(df, output_path):\n",
    "        try:\n",
    "            # Xuất ra file CSV\n",
    "            df.to_csv(output_path, sep=',', encoding='utf-8', index=False)\n",
    "            print(f\"Đã xuất dữ liệu ra {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xuất file CSV: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def write_predictions(predictions, folder_name, lang):\n",
    "        \n",
    "        output_path = f\"{folder_name}/run_{lang}.trec\"\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                for query_predict in predictions: \n",
    "                    for line in query_predict:  # rank bắt đầu từ 1\n",
    "                        f.write(' '.join(str(x) for x in line) + '\\n')\n",
    "            print(f\"Đã xuất file TREC ra {output_path}\")  \n",
    "            return output_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xuất file TREC: {e}\")\n",
    "            raise\n",
    "\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:05.002627Z",
     "iopub.status.busy": "2025-04-16T17:48:05.002369Z",
     "iopub.status.idle": "2025-04-16T17:48:05.019158Z",
     "shell.execute_reply": "2025-04-16T17:48:05.018410Z",
     "shell.execute_reply.started": "2025-04-16T17:48:05.002599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    @staticmethod\n",
    "    def evaluate(predictions_path, qrels_path):\n",
    "        command = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_path, \"--run\", predictions_path]\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "\n",
    "        return Evaluate.extract_metrics(result)\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_metrics(result, language=\"en-en\"):\n",
    "        stdout = result.stdout\n",
    "        map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n",
    "        mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n",
    "        ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n",
    "        precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n",
    "        precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n",
    "        precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n",
    "    \n",
    "        metrics = {\n",
    "            \"map\": map_value,\n",
    "            \"mrr\": mrr,\n",
    "            \"ndcg\": ndcg,\n",
    "            \"precision@5\": precision_5,\n",
    "            \"precision@10\": precision_10,\n",
    "            \"precision@100\": precision_100\n",
    "        }\n",
    "        return metrics     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:05.020294Z",
     "iopub.status.busy": "2025-04-16T17:48:05.019964Z",
     "iopub.status.idle": "2025-04-16T17:48:05.035322Z",
     "shell.execute_reply": "2025-04-16T17:48:05.034662Z",
     "shell.execute_reply.started": "2025-04-16T17:48:05.020265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ModelLogger:\n",
    "    def __init__(self, model_name, loss_function, num_epochs, metrics, notes=\"\", training_time=None,\n",
    "                 folder=\"/kaggle/working/talent_clef/results\", file_name=\"model_info.csv\"):\n",
    "        self.model_name = model_name\n",
    "        self.loss = loss_function\n",
    "        self.epochs = num_epochs\n",
    "        self.metrics = metrics\n",
    "        self.notes = notes\n",
    "        self.training_time = training_time\n",
    "        self.folder = folder\n",
    "        self.file_path = os.path.join(folder, file_name)\n",
    "    \n",
    "    def compute_average_map(self):\n",
    "        map_values = [lang['map'] for lang in self.metrics.values() if 'map' in lang]\n",
    "        return sum(map_values) / len(map_values) if map_values else None\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"model_name\": [self.model_name],\n",
    "            \"Avg result\": [self.compute_average_map()],\n",
    "            \"en-en result\": [self.metrics.get(\"en-en\", \"\")],\n",
    "            \"es-es result\": [self.metrics.get(\"es-es\", \"\")],\n",
    "            \"de-de result\": [self.metrics.get(\"de-de\", \"\")],\n",
    "            \"zh-zh result\": [self.metrics.get(\"zh-zh\", \"\")],\n",
    "            \"en-es result\": [self.metrics.get(\"en-es\", \"\")],\n",
    "            \"en-de result\": [self.metrics.get(\"en-de\", \"\")],\n",
    "            \"en-zh result\": [self.metrics.get(\"en-zh\", \"\")],\n",
    "            \"loss\": [self.loss],\n",
    "            \"epochs\": [self.epochs],\n",
    "            \"training_time (s)\": [self.training_time],\n",
    "            \"date\": [Timer.get()],\n",
    "            \"notes\": [self.notes]\n",
    "        }\n",
    "\n",
    "    def save(self):\n",
    "        # Tạo thư mục nếu chưa tồn tại\n",
    "        os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "        # Tạo DataFrame từ dict\n",
    "        df_new = pd.DataFrame(self.to_dict())\n",
    "\n",
    "        if os.path.exists(self.file_path):\n",
    "            df_existing = pd.read_csv(self.file_path)\n",
    "            df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "            df_updated.to_csv(self.file_path, index=False)\n",
    "            print(f\"✅ Đã thêm dữ liệu vào file: {self.file_path}\")\n",
    "        else:\n",
    "            df_new.to_csv(self.file_path, index=False)\n",
    "            print(f\"✅ Đã tạo file mới: {self.file_path}\")\n",
    "\n",
    "    def show_log(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            print(f\"\\n📄 Nội dung file log:\")\n",
    "            log_df = utils.read_csv(self.file_path)\n",
    "            print(log_df)\n",
    "        else:\n",
    "            print(\"⚠️ Chưa có file log để hiển thị.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:05.037326Z",
     "iopub.status.busy": "2025-04-16T17:48:05.037097Z",
     "iopub.status.idle": "2025-04-16T17:48:05.052223Z",
     "shell.execute_reply": "2025-04-16T17:48:05.051363Z",
     "shell.execute_reply.started": "2025-04-16T17:48:05.037309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-17_17-01-44\n"
     ]
    }
   ],
   "source": [
    "class Timer:\n",
    "    @staticmethod\n",
    "    def get():\n",
    "        # Lấy múi giờ Việt Nam (UTC+7)\n",
    "        vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n",
    "        \n",
    "        # Lấy thời gian hiện tại ở UTC\n",
    "        utc_now = datetime.now(pytz.utc)\n",
    "        \n",
    "        # Chuyển thời gian UTC sang múi giờ Việt Nam\n",
    "        vietnam_time = utc_now.astimezone(vietnam_timezone)\n",
    "        \n",
    "        # Trả về thời gian đã định dạng theo kiểu YYYY-MM-DD HH:MM:SS\n",
    "        return vietnam_time.strftime(\"%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Gọi hàm và in kết quả\n",
    "print(Timer.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm thực thi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-16T17:48:15.119452Z",
     "iopub.status.busy": "2025-04-16T17:48:15.119164Z",
     "iopub.status.idle": "2025-04-16T17:48:53.332767Z",
     "shell.execute_reply": "2025-04-16T17:48:53.331878Z",
     "shell.execute_reply.started": "2025-04-16T17:48:15.119430Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clone thành công!\n",
      "Stdout: \n",
      "Stderr: Cloning into 'talent_clef'...\n",
      "Updating files:  51% (45/88)\n",
      "Updating files:  52% (46/88)\n",
      "Updating files:  53% (47/88)\n",
      "Updating files:  54% (48/88)\n",
      "Updating files:  55% (49/88)\n",
      "Updating files:  56% (50/88)\n",
      "Updating files:  57% (51/88)\n",
      "Updating files:  59% (52/88)\n",
      "Updating files:  60% (53/88)\n",
      "Updating files:  61% (54/88)\n",
      "Updating files:  62% (55/88)\n",
      "Updating files:  63% (56/88)\n",
      "Updating files:  64% (57/88)\n",
      "Updating files:  65% (58/88)\n",
      "Updating files:  67% (59/88)\n",
      "Updating files:  68% (60/88)\n",
      "Updating files:  69% (61/88)\n",
      "Updating files:  70% (62/88)\n",
      "Updating files:  71% (63/88)\n",
      "Updating files:  72% (64/88)\n",
      "Updating files:  73% (65/88)\n",
      "Updating files:  75% (66/88)\n",
      "Updating files:  76% (67/88)\n",
      "Updating files:  77% (68/88)\n",
      "Updating files:  78% (69/88)\n",
      "Updating files:  79% (70/88)\n",
      "Updating files:  80% (71/88)\n",
      "Updating files:  81% (72/88)\n",
      "Updating files:  82% (73/88)\n",
      "Updating files:  84% (74/88)\n",
      "Updating files:  85% (75/88)\n",
      "Updating files:  86% (76/88)\n",
      "Updating files:  87% (77/88)\n",
      "Updating files:  88% (78/88)\n",
      "Updating files:  89% (79/88)\n",
      "Updating files:  90% (80/88)\n",
      "Updating files:  92% (81/88)\n",
      "Updating files:  93% (82/88)\n",
      "Updating files:  94% (83/88)\n",
      "Updating files:  95% (84/88)\n",
      "Updating files:  96% (85/88)\n",
      "Updating files:  97% (86/88)\n",
      "Updating files:  98% (87/88)\n",
      "Updating files: 100% (88/88)\n",
      "Updating files: 100% (88/88), done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoivinh20789\u001b[0m (\u001b[33mhoivinh20789-uit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'talentclef25_evaluation_script'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 27 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (27/27), 10.10 KiB | 5.05 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.2.3)\n",
      "Collecting ranx (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.60.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.13.1)\n",
      "Collecting ir-datasets (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10.12)\n",
      "Collecting lz4 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting cbor2 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.2)\n",
      "Collecting fastparquet (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54.1->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.17.0)\n",
      "Collecting cramjam>=2.3 (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2024.12.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.3)\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (5.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.32.3)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting ijson>=3.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (19.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.7.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.1.31)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\n",
      "Downloading ranx-0.3.20-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
      "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
      "Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Building wheels for collected packages: warc3-wet-clueweb09, cbor\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=e2e5faf45a01afec2f2e0db9c92dff81e6622fc6111e2c550ef15b5333497168\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53430 sha256=2a79b8ac4c34386606a5232d2d6bc51ec6aa4e551a3eba67b3a6974603b10ea3\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
      "Successfully built warc3-wet-clueweb09 cbor\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, cramjam, cbor2, inscriptis, trec-car-tools, ir-datasets, fastparquet, ranx\n",
      "Successfully installed cbor-1.0.0 cbor2-5.6.5 cramjam-2.10.0 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\n"
     ]
    }
   ],
   "source": [
    "load_git_workspace_wandb()    \n",
    "\n",
    "!git clone https://github.com/TalentCLEF/talentclef25_evaluation_script.git\n",
    "!pip install -r \"/kaggle/working/talentclef25_evaluation_script/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetrievalApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-16T07:00:12.028109Z",
     "iopub.status.busy": "2025-04-16T07:00:12.026738Z",
     "iopub.status.idle": "2025-04-16T07:03:15.507676Z",
     "shell.execute_reply": "2025-04-16T07:03:15.506823Z",
     "shell.execute_reply.started": "2025-04-16T07:00:12.028074Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device sử dụng: cuda\n",
      "Tải mô hình từ Hugging Face với tên: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b24251053b543819ae35b2e90e37573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e6fd60ab2a488b89fe83c0d6f27f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcf2c0428d940feac7364e173e9b514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cd1d4033c146bca2a13081956c2266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cc5cddf5d8498ab2abb984a9df394c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa934b43b6654a20bcceb9c2ce9c922e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6bcfac80eb4291b7fdd62e3abc9264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fdc48b080e48a8a6135fd459b5bbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4b6695b07142e59215f79d3bdb35cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb726d9bf2a641219a9ae70e198e4b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fa13ef944e444e900af9a21d8e3437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được khởi tạo thành công!\n",
      "Load mô hình.....\n",
      "Chuẩn bị data: ......\n",
      "Chuẩn bị data en-en:.....\n",
      "Đọc dữ liệu inference:\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements thành công\n",
      "   c_id                          jobtitle\n",
      "0     1                recording engineer\n",
      "1     2              director of taxation\n",
      "2     3  technical support representative\n",
      "3     4                        hr manager\n",
      "4     5           computer graphic artist\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/english/queries thành công\n",
      "   q_id             jobtitle\n",
      "0     1                nanny\n",
      "1     2    food technologist\n",
      "2     3   broadcast engineer\n",
      "3     4  automation engineer\n",
      "4     5         veterinarian\n",
      "Xuất dữ liệu inference:\n",
      "Đã xuất dữ liệu ra /kaggle/working/corpus_en-en.csv\n",
      "Đã xuất dữ liệu ra /kaggle/working/queries_en-en.csv\n",
      "Chuẩn bị data de-de:.....\n",
      "Đọc dữ liệu inference:\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements thành công\n",
      "   c_id                   jobtitle\n",
      "0     1               pr-managerin\n",
      "1     2       talkshow-moderatorin\n",
      "2     3             sporttrainerin\n",
      "3     4         preiskoordinatorin\n",
      "4     5  persönlicher bankberater\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/german/queries thành công\n",
      "   q_id                        jobtitle\n",
      "0     1           technischer recruiter\n",
      "1     2                    briefträger\n",
      "2     3              grundschullehrerin\n",
      "3     4                     3d-animator\n",
      "4     5  unternehmensstrategieberaterin\n",
      "Xuất dữ liệu inference:\n",
      "Đã xuất dữ liệu ra /kaggle/working/corpus_de-de.csv\n",
      "Đã xuất dữ liệu ra /kaggle/working/queries_de-de.csv\n",
      "Chuẩn bị data es-es:.....\n",
      "Đọc dữ liệu inference:\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements thành công\n",
      "   c_id                         jobtitle\n",
      "0     1               desarrollador java\n",
      "1     2         diseñadora de accesorios\n",
      "2     3  agente inmobiliario residencial\n",
      "3     4           planificador de ventas\n",
      "4     5          ayudante de conferencia\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/spanish/queries thành công\n",
      "   q_id                        jobtitle\n",
      "0     1     ingeniera de automatización\n",
      "1     2  técnica de soporte informático\n",
      "2     3                 piloto de avión\n",
      "3     4   ingeniera de diseño analógico\n",
      "4     5      analista de capital riesgo\n",
      "Xuất dữ liệu inference:\n",
      "Đã xuất dữ liệu ra /kaggle/working/corpus_es-es.csv\n",
      "Đã xuất dữ liệu ra /kaggle/working/queries_es-es.csv\n",
      "Chuẩn bị data zh-zh:.....\n",
      "Đọc dữ liệu inference:\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements thành công\n",
      "   c_id jobtitle\n",
      "0     1   自动化技术员\n",
      "1     2    选角制作人\n",
      "2     3     体育经理\n",
      "3     4     临时助理\n",
      "4     5  用户支持技术员\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/chinese/queries thành công\n",
      "   q_id jobtitle\n",
      "0     1     贷款干事\n",
      "1     2     税务会计\n",
      "2     3    犬类美容师\n",
      "3     4      收银员\n",
      "4     5      筹款人\n",
      "Xuất dữ liệu inference:\n",
      "Đã xuất dữ liệu ra /kaggle/working/corpus_zh-zh.csv\n",
      "Đã xuất dữ liệu ra /kaggle/working/queries_zh-zh.csv\n",
      "Bắt đầu inference.....\n",
      "Load data en-en:.....\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/corpus_en-en.csv thành công\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/queries_en-en.csv thành công\n",
      "Load data de-de:.....\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/corpus_de-de.csv thành công\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/queries_de-de.csv thành công\n",
      "Load data es-es:.....\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/corpus_es-es.csv thành công\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/queries_es-es.csv thành công\n",
      "Load data zh-zh:.....\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/corpus_zh-zh.csv thành công\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/queries_zh-zh.csv thành công\n",
      "Inference en-en:.....\n",
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944b0f274ca949f8bc6649696f38df98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675bb84777584c00b196f2b659d07660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference de-de:.....\n",
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983c6b1488904cf6be153c355d510093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5420865a79ec48bcac87650f1a0d9713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference es-es:.....\n",
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bafe21040c402391383cef3f21390b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/146 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487509a4f2bc4643b7921e1fcdbf1006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference zh-zh:.....\n",
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f827d474414559aa875ff4a127f87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c8a26da57491c9f918c0eab28b286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu dự đoán:.....\n",
      "Dự đoán en-en:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 105/105 [00:08<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán de-de:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 203/203 [00:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán es-es:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 185/185 [00:26<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán zh-zh:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 103/103 [00:07<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu xuất file:....\n",
      "Đã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_en-en.trec\n",
      "Đã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_de-de.trec\n",
      "Đã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_es-es.trec\n",
      "Đã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_zh-zh.trec\n",
      "Đang nén thư mục /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37 thành /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip...\n",
      "File zip đã được tạo: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip\n",
      "Bắt đầu đánh giá:.....\n",
      "Đánh giá en-en:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_en-en.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.4966\n",
      "mrr: 0.7638\n",
      "ndcg: 0.7669\n",
      "precision@5: 0.6762\n",
      "precision@10: 0.5914\n",
      "precision@100: 0.1617\n",
      "\n",
      "Đánh giá de-de:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_de-de.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.2091\n",
      "mrr: 0.4842\n",
      "ndcg: 0.5713\n",
      "precision@5: 0.4591\n",
      "precision@10: 0.4365\n",
      "precision@100: 0.1380\n",
      "\n",
      "Đánh giá es-es:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_es-es.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.2840\n",
      "mrr: 0.5421\n",
      "ndcg: 0.6307\n",
      "precision@5: 0.5741\n",
      "precision@10: 0.5259\n",
      "precision@100: 0.1583\n",
      "\n",
      "Đánh giá zh-zh:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_zh-zh.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.1344\n",
      "mrr: 0.3855\n",
      "ndcg: 0.4553\n",
      "precision@5: 0.2466\n",
      "precision@10: 0.2214\n",
      "precision@100: 0.0541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data = {\n",
    "#     \"corpus\": {\n",
    "#         \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements\",\n",
    "#         \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements\",\n",
    "#         \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements\",\n",
    "#         \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements\"\n",
    "#     },\n",
    "    \n",
    "#     \"queries\":{\n",
    "#         \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/queries\",\n",
    "#         \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/queries\",\n",
    "#         \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/queries\",\n",
    "#         \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/queries\"\n",
    "#     },\n",
    "    \n",
    "#     \"qrels\": {\n",
    "#         \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\",\n",
    "#         \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\",\n",
    "#         \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\",\n",
    "#         \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# app = RetrievalApp(model_name)\n",
    "# ratings = app(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T18:00:10.156528Z",
     "iopub.status.busy": "2025-04-16T18:00:10.156236Z",
     "iopub.status.idle": "2025-04-16T18:00:19.762955Z",
     "shell.execute_reply": "2025-04-16T18:00:19.762026Z",
     "shell.execute_reply.started": "2025-04-16T18:00:10.156508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đọc dữ liệu train_org:\n",
      "                       jobtitle  \\\n",
      "0    director of technical arts   \n",
      "0          technical supervisor   \n",
      "0             technical manager   \n",
      "0  head of technical department   \n",
      "0            technical director   \n",
      "\n",
      "                                               skill  label  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "Cột dữ liệu: Index(['jobtitle', 'skill', 'label'], dtype='object')\n",
      "Xuất dữ liệu train sau khi chuẩn bị:\n",
      "Đã xuất dữ liệu ra /kaggle/working/train.csv\n"
     ]
    }
   ],
   "source": [
    "train_data_org_file = \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"\n",
    "preparer = DataPreparer()\n",
    "train_data, train_file = preparer.prepare_train_data(train_data_org_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T18:03:57.739904Z",
     "iopub.status.busy": "2025-04-16T18:03:57.739587Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/train.csv thành công\n",
      "Device sử dụng: cuda\n",
      "Tải mô hình từ Hugging Face với tên: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153bc3b0cdc049cda5a42cbde2b9d15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06982a3ec0f048ec92bdfefd61a409d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b77bc74fd3949549c22899e27f30943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945e0da701774e9b98f67bf2ff4c4082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c732fd1a618b4d23b08171a6c1bd84f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d8ab31d5ea496d8a8ac5f83ea9ae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf04bd85d9947b8bd904c62c0a6ef32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6064adda0e9c41019ae84e197bb2d645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86c651139e7488f82d0eddbef6e0396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f0f218c6e04a8695fdc059633a46b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được khởi tạo thành công!\n",
      "Khởi tạo dataset:\n",
      "Bắt đầu train: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_180418-0f3b4yz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers' target=\"_blank\">https://wandb.ai/hoivinh20789-uit/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7' target=\"_blank\">https://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/0f3b4yz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2387' max='3376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2387/3376 07:34 < 03:08, 5.25 it/s, Epoch 1.41/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.158100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = Dataset.load_train_data(train_file)\n",
    "dataset = Dataset(train_data)\n",
    "\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "loss = losses.MultipleNegativesRankingLoss\n",
    "\n",
    "params = {\n",
    "    \"num_epochs\": 2,\n",
    "    \"output_path\": f\"/kaggle/working/talent_clef/model/{model_name}/epoch2\",\n",
    "    \"warmup_steps\": 100,\n",
    "}\n",
    "\n",
    "trainer = Trainer(model_name)\n",
    "model = trainer.train(dataset.data, loss, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Log Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:04:41.791344Z",
     "iopub.status.busy": "2025-04-16T07:04:41.790975Z",
     "iopub.status.idle": "2025-04-16T07:04:41.812873Z",
     "shell.execute_reply": "2025-04-16T07:04:41.812119Z",
     "shell.execute_reply.started": "2025-04-16T07:04:41.791314Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã thêm dữ liệu vào file: /kaggle/working/talent_clef/results/model_info.csv\n",
      "\n",
      "📄 Nội dung file log:\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/results/model_info.csv thành công\n",
      "                               model_name  Avg result  \\\n",
      "0                jjzha/jobbert-base-cased    0.271500   \n",
      "1                           agne/jobGBERT    0.260500   \n",
      "2  sentence-transformers/all-MiniLM-L6-v2    0.496600   \n",
      "3  sentence-transformers/all-MiniLM-L6-v2    0.551900   \n",
      "4  sentence-transformers/all-MiniLM-L6-v2    0.563200   \n",
      "5  sentence-transformers/all-MiniLM-L6-v2    0.563600   \n",
      "6  sentence-transformers/all-MiniLM-L6-v2    0.281025   \n",
      "\n",
      "                                        en-en result  \\\n",
      "0  {'map': 0.2715, 'mrr': 0.6136, 'ndcg': 0.6032,...   \n",
      "1  {'map': 0.2605, 'mrr': 0.634, 'ndcg': 0.5962, ...   \n",
      "2  {'map': 0.4966, 'mrr': 0.7638, 'ndcg': 0.7669,...   \n",
      "3  {'map': 0.5519, 'mrr': 0.7946, 'ndcg': 0.8011,...   \n",
      "4  {'map': 0.5632, 'mrr': 0.8045, 'ndcg': 0.8085,...   \n",
      "5  {'map': 0.5636, 'mrr': 0.8087, 'ndcg': 0.809, ...   \n",
      "6  {'map': 0.4966, 'mrr': 0.7638, 'ndcg': 0.7669,...   \n",
      "\n",
      "                                        es-es result  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "5                                                NaN   \n",
      "6  {'map': 0.284, 'mrr': 0.5421, 'ndcg': 0.6307, ...   \n",
      "\n",
      "                                        de-de result  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "5                                                NaN   \n",
      "6  {'map': 0.2091, 'mrr': 0.4842, 'ndcg': 0.5713,...   \n",
      "\n",
      "                                        zh-zh result  en-es result  \\\n",
      "0                                                NaN           NaN   \n",
      "1                                                NaN           NaN   \n",
      "2                                                NaN           NaN   \n",
      "3                                                NaN           NaN   \n",
      "4                                                NaN           NaN   \n",
      "5                                                NaN           NaN   \n",
      "6  {'map': 0.1344, 'mrr': 0.3855, 'ndcg': 0.4553,...           NaN   \n",
      "\n",
      "   en-de result  en-zh result                          loss  epochs  \\\n",
      "0           NaN           NaN                           NaN     NaN   \n",
      "1           NaN           NaN                           NaN     NaN   \n",
      "2           NaN           NaN                           NaN     NaN   \n",
      "3           NaN           NaN  MultipleNegativesRankingLoss     1.0   \n",
      "4           NaN           NaN  MultipleNegativesRankingLoss     3.0   \n",
      "5           NaN           NaN  MultipleNegativesRankingLoss     1.0   \n",
      "6           NaN           NaN                           NaN     NaN   \n",
      "\n",
      "   training_time (s)                 date  \\\n",
      "0                NaN  22-03-2025 05:40:16   \n",
      "1                NaN  22-03-2025 05:43:05   \n",
      "2                NaN  22-03-2025 05:46:41   \n",
      "3                NaN  22-03-2025 05:55:41   \n",
      "4                NaN  22-03-2025 06:18:46   \n",
      "5                NaN  01-04-2025 14:46:32   \n",
      "6                NaN       04-16_14-04-41   \n",
      "\n",
      "                                            notes  \n",
      "0                                            Test  \n",
      "1                                            Test  \n",
      "2                                            Test  \n",
      "3                                            Test  \n",
      "4                                            Test  \n",
      "5  thêm negative pair và finetune tiếp từ epoch 3  \n",
      "6  thêm negative pair và finetune tiếp từ epoch 5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-08bc3e49c7e0>:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "logger = ModelLogger(\n",
    "    model_name=model_name,\n",
    "    loss_function=None,\n",
    "    num_epochs=None,\n",
    "    metrics=ratings,\n",
    "    notes=\"thêm negative pair và finetune tiếp từ epoch 5\"\n",
    ")\n",
    "\n",
    "logger.save()\n",
    "logger.show_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Git Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:08:08.896966Z",
     "iopub.status.busy": "2025-04-16T07:08:08.896529Z",
     "iopub.status.idle": "2025-04-16T07:08:08.903988Z",
     "shell.execute_reply": "2025-04-16T07:08:08.903291Z",
     "shell.execute_reply.started": "2025-04-16T07:08:08.896911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/talent_clef\n"
     ]
    }
   ],
   "source": [
    "cd talent_clef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:05:26.934527Z",
     "iopub.status.busy": "2025-04-16T07:05:26.934227Z",
     "iopub.status.idle": "2025-04-16T07:05:26.938489Z",
     "shell.execute_reply": "2025-04-16T07:05:26.937550Z",
     "shell.execute_reply.started": "2025-04-16T07:05:26.934505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "brand_name = model_name + \"/\" +Timer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:05:29.045592Z",
     "iopub.status.busy": "2025-04-16T07:05:29.045282Z",
     "iopub.status.idle": "2025-04-16T07:05:29.050430Z",
     "shell.execute_reply": "2025-04-16T07:05:29.049619Z",
     "shell.execute_reply.started": "2025-04-16T07:05:29.045564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:08:12.273020Z",
     "iopub.status.busy": "2025-04-16T07:08:12.272698Z",
     "iopub.status.idle": "2025-04-16T07:08:33.682946Z",
     "shell.execute_reply": "2025-04-16T07:08:33.681928Z",
     "shell.execute_reply.started": "2025-04-16T07:08:12.272997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26'\n",
      "On branch sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   results/model_info.csv\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mpredict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip\u001b[m\n",
      "\t\u001b[31mpredict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "[sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26 b17b3c4] updated\n",
      " 6 files changed, 2356107 insertions(+)\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37.zip\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_de-de.trec\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_en-en.trec\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_es-es.trec\n",
      " create mode 100644 predict/sentence-transformers/all-MiniLM-L6-v2/04-16_14-01-37/run_zh-zh.trec\n",
      "Enumerating objects: 19, done.\n",
      "Counting objects: 100% (19/19), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (11/11), done.\n",
      "Writing objects: 100% (13/13), 61.35 MiB | 6.52 MiB/s, done.\n",
      "Total 13 (delta 4), reused 1 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "remote: \n",
      "remote: Create a pull request for 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26' on GitHub by visiting:\u001b[K\n",
      "remote:      https://github.com/hoivd/talent_clef/pull/new/sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26\u001b[K\n",
      "remote: \n",
      "To https://github.com/hoivd/talent_clef\n",
      " * [new branch]      sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26 -> sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26\n",
      "Branch 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26' set up to track remote branch 'sentence-transformers/all-MiniLM-L6-v2/04-16_14-05-26' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"hoivd79@gmail.com\"\n",
    "!git config --global user.name \"Dang Vinh Hoi\"\n",
    "!git checkout -b {brand_name}      # Tạo và chuyển sang nhánh dev\n",
    "!git status\n",
    "!git add .\n",
    "!git commit -m \"updated\"\n",
    "!git push -u origin {brand_name}    # Push lần đầu, thiết lập tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T07:22:00.506117Z",
     "iopub.status.busy": "2025-04-14T07:22:00.505775Z",
     "iopub.status.idle": "2025-04-14T07:22:00.512221Z",
     "shell.execute_reply": "2025-04-14T07:22:00.511293Z",
     "shell.execute_reply.started": "2025-04-14T07:22:00.506086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/talent_clef\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
