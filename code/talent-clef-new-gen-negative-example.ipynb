{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba3266b",
   "metadata": {
    "papermill": {
     "duration": 0.008786,
     "end_time": "2025-04-19T13:04:03.415385",
     "exception": false,
     "start_time": "2025-04-19T13:04:03.406599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca6a54e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:03.431066Z",
     "iopub.status.busy": "2025-04-19T13:04:03.430804Z",
     "iopub.status.idle": "2025-04-19T13:04:37.221184Z",
     "shell.execute_reply": "2025-04-19T13:04:37.220269Z"
    },
    "papermill": {
     "duration": 33.799928,
     "end_time": "2025-04-19T13:04:37.222753",
     "exception": false,
     "start_time": "2025-04-19T13:04:03.422825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 13:04:20.251677: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745067860.445811      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745067860.500669      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchmetrics.retrieval import RetrievalMAP\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import wandb\n",
    "import ast\n",
    "import subprocess\n",
    "import pickle\n",
    "import shutil\n",
    "import datetime\n",
    "import pytz\n",
    "from kaggle_secrets import UserSecretsClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30c054",
   "metadata": {
    "papermill": {
     "duration": 0.00866,
     "end_time": "2025-04-19T13:04:37.240120",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.231460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PositiveExampleMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9732f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.258484Z",
     "iopub.status.busy": "2025-04-19T13:04:37.258184Z",
     "iopub.status.idle": "2025-04-19T13:04:37.264124Z",
     "shell.execute_reply": "2025-04-19T13:04:37.263572Z"
    },
    "papermill": {
     "duration": 0.016596,
     "end_time": "2025-04-19T13:04:37.265120",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.248524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MiningPosExample:\n",
    "    def __init__(self):\n",
    "        self.data = None  # Khởi tạo thuộc tính self.data là None\n",
    "\n",
    "     # Phương thức __len__ để trả về số dòng của data\n",
    "    def __len__(self):\n",
    "        if self.data is not None:\n",
    "            return len(self.data)\n",
    "        return 0  # Nếu self.data chưa được gán (None), trả về 0\n",
    "    \n",
    "    # Phương thức __getitem__ để truy xuất một dòng trong data theo chỉ số\n",
    "    def __getitem__(self, index):\n",
    "        if self.data is not None:\n",
    "            return self.data.iloc[index]\n",
    "        raise IndexError(\"Index out of range\")  # Nếu self.data là None, raise lỗi\n",
    "        \n",
    "    def mining_pos_example(self, data_file):\n",
    "        # Đọc dữ liệu từ file (giả sử là file CSV)\n",
    "        df = pd.read_csv(data_file)\n",
    "        df['jobtitles'] = df['jobtitles'].apply(ast.literal_eval)\n",
    "        # Lấy các cột 'jobtitles' và 'skills_gen', sau đó \"phân nổ\" danh sách trong cột 'jobtitles'\n",
    "        new_df = df[['jobtitles', 'skills_gen']].explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n",
    "        \n",
    "        # Thêm cột 'label' với giá trị toàn bộ là 1\n",
    "        new_df['label'] = 1\n",
    "        \n",
    "        # Lưu kết quả vào self.data\n",
    "        self.data = new_df\n",
    "        \n",
    "        return new_df\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023e0b5",
   "metadata": {
    "papermill": {
     "duration": 0.007619,
     "end_time": "2025-04-19T13:04:37.280235",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.272616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HardNegativeExampleMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcb1fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.295958Z",
     "iopub.status.busy": "2025-04-19T13:04:37.295731Z",
     "iopub.status.idle": "2025-04-19T13:04:37.303703Z",
     "shell.execute_reply": "2025-04-19T13:04:37.303155Z"
    },
    "papermill": {
     "duration": 0.017129,
     "end_time": "2025-04-19T13:04:37.304730",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.287601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "class RetrievalTrainData:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.model = BiEncoder(model_name, model_path).model\n",
    "        print(\"Load mô hình.....\")\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path        \n",
    "    \n",
    "    def prepare_query_corpus(self, data_file):\n",
    "        \"\"\"\n",
    "        Chuẩn bị dữ liệu: chuẩn bị các corpus và queries cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Chuẩn bị data: ......\")\n",
    "        preparer = DataPreparer()\n",
    "        corpus_file = dict()\n",
    "        queries_file = dict()\n",
    "        langs = list(data_file['source_file'].keys())\n",
    "        print(langs)\n",
    "        for lang in langs:\n",
    "            print(f\"Chuẩn bị data {lang}:.....\")\n",
    "            source_file = data_file['source_file'][lang]\n",
    "            corpus_file[lang], queries_file[lang] = preparer.prepare_query_corpus(source_file)\n",
    "        \n",
    "        return langs, corpus_file, queries_file\n",
    "\n",
    "    def inference(self, langs, corpus_file, queries_file):\n",
    "        \"\"\"\n",
    "        Thực hiện inference cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu inference.....\")\n",
    "        corpus, queries = dict(), dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Load data {lang}:.....\")\n",
    "            corpus_file_cur = corpus_file[lang]\n",
    "            queries_file_cur = queries_file[lang]\n",
    "            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n",
    "\n",
    "        inferencer = Inference(self.model)\n",
    "        for lang in langs:\n",
    "            print(f\"Inference {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang]\n",
    "            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n",
    "\n",
    "        return corpus, queries, inferencer\n",
    "\n",
    "    def predict(self, langs, corpus, queries, inferencer):\n",
    "        \"\"\"\n",
    "        Thực hiện dự đoán.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu dự đoán:.....\")\n",
    "        predictions = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Dự đoán {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang] \n",
    "            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c4974aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.320192Z",
     "iopub.status.busy": "2025-04-19T13:04:37.319935Z",
     "iopub.status.idle": "2025-04-19T13:04:37.323283Z",
     "shell.execute_reply": "2025-04-19T13:04:37.322585Z"
    },
    "papermill": {
     "duration": 0.012405,
     "end_time": "2025-04-19T13:04:37.324409",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.312004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prediction_p1 = utils.read_pkl(\"/kaggle/working/talent_clef/data/negative_pair_new/prediction_p1.pkl\")\n",
    "# prediction_p2 = utils.read_pkl(\"/kaggle/working/talent_clef/data/negative_pair_new/prediction_p2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2e2ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.340119Z",
     "iopub.status.busy": "2025-04-19T13:04:37.339541Z",
     "iopub.status.idle": "2025-04-19T13:04:37.342619Z",
     "shell.execute_reply": "2025-04-19T13:04:37.341938Z"
    },
    "papermill": {
     "duration": 0.011826,
     "end_time": "2025-04-19T13:04:37.343697",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.331871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_p1 = prediction_p1['en-en'] \n",
    "# similarities_p2 = prediction_p2['en-en'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a471088e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.358811Z",
     "iopub.status.busy": "2025-04-19T13:04:37.358605Z",
     "iopub.status.idle": "2025-04-19T13:04:37.361462Z",
     "shell.execute_reply": "2025-04-19T13:04:37.360780Z"
    },
    "papermill": {
     "duration": 0.01167,
     "end_time": "2025-04-19T13:04:37.362615",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.350945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(similarities_p1)\n",
    "# len(similarities_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19afa78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.377701Z",
     "iopub.status.busy": "2025-04-19T13:04:37.377528Z",
     "iopub.status.idle": "2025-04-19T13:04:37.380338Z",
     "shell.execute_reply": "2025-04-19T13:04:37.379839Z"
    },
    "papermill": {
     "duration": 0.011454,
     "end_time": "2025-04-19T13:04:37.381309",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.369855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities = similarities_p1 + similarities_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "364c760c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.396442Z",
     "iopub.status.busy": "2025-04-19T13:04:37.396213Z",
     "iopub.status.idle": "2025-04-19T13:04:37.399106Z",
     "shell.execute_reply": "2025-04-19T13:04:37.398560Z"
    },
    "papermill": {
     "duration": 0.011827,
     "end_time": "2025-04-19T13:04:37.400297",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.388470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'A': similarities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2803ba3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.415581Z",
     "iopub.status.busy": "2025-04-19T13:04:37.415396Z",
     "iopub.status.idle": "2025-04-19T13:04:37.418092Z",
     "shell.execute_reply": "2025-04-19T13:04:37.417611Z"
    },
    "papermill": {
     "duration": 0.011446,
     "end_time": "2025-04-19T13:04:37.419079",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.407633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df = df.explode('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50bc270b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.434457Z",
     "iopub.status.busy": "2025-04-19T13:04:37.434197Z",
     "iopub.status.idle": "2025-04-19T13:04:37.437211Z",
     "shell.execute_reply": "2025-04-19T13:04:37.436665Z"
    },
    "papermill": {
     "duration": 0.01171,
     "end_time": "2025-04-19T13:04:37.438196",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.426486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df['c_id'] = similarities_df['A'].apply(lambda row: row[0])\n",
    "# similarities_df['score'] = similarities_df['A'].apply(lambda row: row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b63d629e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.454321Z",
     "iopub.status.busy": "2025-04-19T13:04:37.454100Z",
     "iopub.status.idle": "2025-04-19T13:04:37.456745Z",
     "shell.execute_reply": "2025-04-19T13:04:37.456264Z"
    },
    "papermill": {
     "duration": 0.011778,
     "end_time": "2025-04-19T13:04:37.457735",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.445957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df = similarities_df.reset_index(names='q_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86d2d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.472818Z",
     "iopub.status.busy": "2025-04-19T13:04:37.472640Z",
     "iopub.status.idle": "2025-04-19T13:04:37.475479Z",
     "shell.execute_reply": "2025-04-19T13:04:37.474962Z"
    },
    "papermill": {
     "duration": 0.011444,
     "end_time": "2025-04-19T13:04:37.476452",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.465008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37cb430d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.491698Z",
     "iopub.status.busy": "2025-04-19T13:04:37.491503Z",
     "iopub.status.idle": "2025-04-19T13:04:37.494319Z",
     "shell.execute_reply": "2025-04-19T13:04:37.493787Z"
    },
    "papermill": {
     "duration": 0.011673,
     "end_time": "2025-04-19T13:04:37.495377",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.483704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df = similarities_df.drop(['A'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d45de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.510805Z",
     "iopub.status.busy": "2025-04-19T13:04:37.510608Z",
     "iopub.status.idle": "2025-04-19T13:04:37.513358Z",
     "shell.execute_reply": "2025-04-19T13:04:37.512810Z"
    },
    "papermill": {
     "duration": 0.011743,
     "end_time": "2025-04-19T13:04:37.514481",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.502738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df['rank'] = similarities_df.groupby('q_id').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f12f46ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.571845Z",
     "iopub.status.busy": "2025-04-19T13:04:37.571618Z",
     "iopub.status.idle": "2025-04-19T13:04:37.574895Z",
     "shell.execute_reply": "2025-04-19T13:04:37.574163Z"
    },
    "papermill": {
     "duration": 0.012304,
     "end_time": "2025-04-19T13:04:37.575914",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.563610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "066e0a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.591326Z",
     "iopub.status.busy": "2025-04-19T13:04:37.591109Z",
     "iopub.status.idle": "2025-04-19T13:04:37.593742Z",
     "shell.execute_reply": "2025-04-19T13:04:37.593278Z"
    },
    "papermill": {
     "duration": 0.011444,
     "end_time": "2025-04-19T13:04:37.594763",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.583319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source_file = DataPreparer.prepare_source_data('/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945eafb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.610553Z",
     "iopub.status.busy": "2025-04-19T13:04:37.610340Z",
     "iopub.status.idle": "2025-04-19T13:04:37.613262Z",
     "shell.execute_reply": "2025-04-19T13:04:37.612612Z"
    },
    "papermill": {
     "duration": 0.012281,
     "end_time": "2025-04-19T13:04:37.614374",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.602093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source_df = utils.read_csv(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9117572b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.631130Z",
     "iopub.status.busy": "2025-04-19T13:04:37.630747Z",
     "iopub.status.idle": "2025-04-19T13:04:37.633654Z",
     "shell.execute_reply": "2025-04-19T13:04:37.633010Z"
    },
    "papermill": {
     "duration": 0.011763,
     "end_time": "2025-04-19T13:04:37.634628",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.622865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1052475c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.649898Z",
     "iopub.status.busy": "2025-04-19T13:04:37.649693Z",
     "iopub.status.idle": "2025-04-19T13:04:37.652537Z",
     "shell.execute_reply": "2025-04-19T13:04:37.651988Z"
    },
    "papermill": {
     "duration": 0.011577,
     "end_time": "2025-04-19T13:04:37.653519",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.641942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# similarities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "063a98ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.668738Z",
     "iopub.status.busy": "2025-04-19T13:04:37.668546Z",
     "iopub.status.idle": "2025-04-19T13:04:37.671115Z",
     "shell.execute_reply": "2025-04-19T13:04:37.670643Z"
    },
    "papermill": {
     "duration": 0.011335,
     "end_time": "2025-04-19T13:04:37.672045",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.660710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge = similarities_df.merge(source_df, left_on='q_id', right_on='t_id')\n",
    "# merge = merge.merge(source_df, left_on='c_id', right_on='t_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47eca5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.687165Z",
     "iopub.status.busy": "2025-04-19T13:04:37.686996Z",
     "iopub.status.idle": "2025-04-19T13:04:37.689903Z",
     "shell.execute_reply": "2025-04-19T13:04:37.689261Z"
    },
    "papermill": {
     "duration": 0.011709,
     "end_time": "2025-04-19T13:04:37.690909",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.679200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge_df = merge.rename(columns={'g_id_x': 'q_gid', 'g_id_y': 'c_gid'}).drop(['jobtitle_x', 'skill_x','t_id_x', 't_id_y', 'jobtitle_y', 'skill_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d646d839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.706512Z",
     "iopub.status.busy": "2025-04-19T13:04:37.705893Z",
     "iopub.status.idle": "2025-04-19T13:04:37.708748Z",
     "shell.execute_reply": "2025-04-19T13:04:37.708274Z"
    },
    "papermill": {
     "duration": 0.011569,
     "end_time": "2025-04-19T13:04:37.709776",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.698207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge_df['label'] = merge_df.apply(lambda row: 1 if row['q_gid'] == row['c_gid'] else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "598f5140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.725048Z",
     "iopub.status.busy": "2025-04-19T13:04:37.724852Z",
     "iopub.status.idle": "2025-04-19T13:04:37.727739Z",
     "shell.execute_reply": "2025-04-19T13:04:37.727060Z"
    },
    "papermill": {
     "duration": 0.011657,
     "end_time": "2025-04-19T13:04:37.728765",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.717108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a24ede81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.744273Z",
     "iopub.status.busy": "2025-04-19T13:04:37.743706Z",
     "iopub.status.idle": "2025-04-19T13:04:37.746700Z",
     "shell.execute_reply": "2025-04-19T13:04:37.746151Z"
    },
    "papermill": {
     "duration": 0.011774,
     "end_time": "2025-04-19T13:04:37.747860",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.736086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# condition = (merge_df['label'] == 0) & (merge_df['rank'] <= 10)\n",
    "# hard_negative_df = merge_df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d110b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.763786Z",
     "iopub.status.busy": "2025-04-19T13:04:37.763587Z",
     "iopub.status.idle": "2025-04-19T13:04:37.766442Z",
     "shell.execute_reply": "2025-04-19T13:04:37.765769Z"
    },
    "papermill": {
     "duration": 0.011916,
     "end_time": "2025-04-19T13:04:37.767515",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.755599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hard_negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "826ef228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.782829Z",
     "iopub.status.busy": "2025-04-19T13:04:37.782654Z",
     "iopub.status.idle": "2025-04-19T13:04:37.785631Z",
     "shell.execute_reply": "2025-04-19T13:04:37.784974Z"
    },
    "papermill": {
     "duration": 0.011774,
     "end_time": "2025-04-19T13:04:37.786705",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.774931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path = '/kaggle/working/talent_clef/data/hard_neg_mining'\n",
    "# os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# neg_example_file = path + '/' + 'neg_example.csv'\n",
    "# hard_neg_file = utils.write_csv(hard_negative_df, neg_example_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ef645",
   "metadata": {
    "papermill": {
     "duration": 0.007082,
     "end_time": "2025-04-19T13:04:37.801131",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.794049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataPrepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c5e530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.816707Z",
     "iopub.status.busy": "2025-04-19T13:04:37.816489Z",
     "iopub.status.idle": "2025-04-19T13:04:37.824285Z",
     "shell.execute_reply": "2025-04-19T13:04:37.823692Z"
    },
    "papermill": {
     "duration": 0.017047,
     "end_time": "2025-04-19T13:04:37.825340",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.808293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreparer:\n",
    "    def prepare_train_data(self, train_data_org_file):\n",
    "        print(\"Đọc dữ liệu train_org:\")\n",
    "        \n",
    "        pos_miner = MiningPosExample()\n",
    "        pos_example_df = pos_miner.mining_pos_example(train_data_org_file)\n",
    "        print(pos_example_df.head())\n",
    "\n",
    "        train_df = pos_example_df\n",
    "        print(f\"Cột dữ liệu: {train_df.columns}\")\n",
    "        print(\"Xuất dữ liệu train sau khi chuẩn bị:\")\n",
    "        train_file = \"/kaggle/working/train.csv\"\n",
    "        utils.write_csv(train_df, train_file)\n",
    "        return train_df, train_file\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_query_corpus(train_file):\n",
    "        train_data = pd.read_csv(train_file)\n",
    "        data = train_data[['tid', 'jobtitles']].rename(columns={'tid': 'g_id', 'jobtitles': 'jobtitle'})\n",
    "        data['jobtitle'] = data['jobtitle'].apply(ast.literal_eval)\n",
    "        data = data.explode('jobtitle').reset_index(drop=True)\n",
    "\n",
    "        query_df = data.reset_index(names='q_id')\n",
    "        corpus_df = data.reset_index(names='c_id')\n",
    "\n",
    "        print(\"Xuất query và corpus từ train:........\")\n",
    "        query_file = utils.write_csv(query_df, 'queries_train.csv')\n",
    "        corpus_file = utils.write_csv(corpus_df, 'corpus_train.csv')\n",
    "        return corpus_file, query_file \n",
    "\n",
    "    def prepare_inference_data(self, corpus_path, queries_path, lang):\n",
    "        print(\"Đọc dữ liệu inference:\")\n",
    "        corpus_df = utils.read_tsv(corpus_path)\n",
    "        queries_df = utils.read_tsv(queries_path)\n",
    "        \n",
    "        print(\"Xuất dữ liệu inference:\")\n",
    "        corpus_out_path = f\"/kaggle/working/corpus_{lang}.csv\"\n",
    "        queries_out_path = f\"/kaggle/working/queries_{lang}.csv\"\n",
    "        utils.write_csv(corpus_df, corpus_out_path)\n",
    "        utils.write_csv(queries_df, queries_out_path)\n",
    "        return corpus_out_path, queries_out_path\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_source_data(train_file):\n",
    "        train_data = pd.read_csv(train_file)\n",
    "        data = train_data[['tid', 'jobtitles', 'skills_gen']].rename(columns={'tid': 'g_id', 'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n",
    "        data['jobtitle'] = data['jobtitle'].apply(ast.literal_eval)\n",
    "        data = data.explode('jobtitle').reset_index(drop=True)\n",
    "\n",
    "        source_df = data.reset_index(names='t_id')\n",
    "\n",
    "        print(\"Xuất source file từ train:........\")\n",
    "        source_file = utils.write_csv(source_df, 'source_file.csv')\n",
    "        return source_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26acbefb",
   "metadata": {
    "papermill": {
     "duration": 0.007026,
     "end_time": "2025-04-19T13:04:37.839567",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.832541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9d1fbb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.855017Z",
     "iopub.status.busy": "2025-04-19T13:04:37.854557Z",
     "iopub.status.idle": "2025-04-19T13:04:37.860903Z",
     "shell.execute_reply": "2025-04-19T13:04:37.860437Z"
    },
    "papermill": {
     "duration": 0.015185,
     "end_time": "2025-04-19T13:04:37.861955",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.846770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = []\n",
    "        for jobtitle, skill, label in data:\n",
    "            self.data.append(InputExample(texts = [jobtitle, skill], label=label))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Trả về số lượng mẫu trong dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def load_train_data(train_path, train_data=None):\n",
    "        if train_data == None:\n",
    "            train_df = utils.read_csv(train_path)\n",
    "        else: \n",
    "            train_df = train_data\n",
    "        jobtitles =  train_df['jobtitle'].tolist()\n",
    "        skills =  train_df['skill'].tolist()\n",
    "        labels = train_df['label'].tolist()\n",
    "\n",
    "        data = []\n",
    "        for idx, jobtitle in enumerate(jobtitles):\n",
    "            data.append((jobtitle, skills[idx], labels[idx]))\n",
    "        return data\n",
    "        \n",
    "    @staticmethod  \n",
    "    def load_inference_data(corpus_path, queries_path):\n",
    "        corpus_df = utils.read_csv(corpus_path)\n",
    "        queries_df = utils.read_csv(queries_path)\n",
    "        \n",
    "        cids_l = corpus_df['c_id'].tolist()\n",
    "        corpus_l = corpus_df['jobtitle'].tolist()\n",
    "        qids_l = queries_df['q_id'].tolist()\n",
    "        queries_l = queries_df['jobtitle'].tolist()\n",
    "\n",
    "        corpus = {\"c_id\": cids_l,\n",
    "                \"jobtitle\": corpus_l\n",
    "                }\n",
    "\n",
    "        queries = {\"q_id\": qids_l,\n",
    "                \"jobtitle\": queries_l\n",
    "                }\n",
    "        return corpus, queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14103c",
   "metadata": {
    "papermill": {
     "duration": 0.00712,
     "end_time": "2025-04-19T13:04:37.876410",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.869290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BiEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b07c9ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.892042Z",
     "iopub.status.busy": "2025-04-19T13:04:37.891536Z",
     "iopub.status.idle": "2025-04-19T13:04:37.896147Z",
     "shell.execute_reply": "2025-04-19T13:04:37.895666Z"
    },
    "papermill": {
     "duration": 0.013483,
     "end_time": "2025-04-19T13:04:37.897145",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.883662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiEncoder:\n",
    "    def __init__(self, model_name=None, model_path=None):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Device sử dụng:\", device)\n",
    "        \n",
    "        try:\n",
    "            if model_path is None:\n",
    "                print(f\"Tải mô hình từ Hugging Face với tên: {model_name}\")\n",
    "                self.model = SentenceTransformer(model_name)\n",
    "            else:\n",
    "                print(f\"Tải mô hình từ đường dẫn cục bộ: {model_path}\")\n",
    "                self.model = SentenceTransformer(model_path)\n",
    "            \n",
    "            # Đặt mô hình lên thiết bị\n",
    "            self.model = self.model.to(device)\n",
    "            print(\"Mô hình đã được khởi tạo thành công!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi khởi tạo mô hình: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098c2be",
   "metadata": {
    "papermill": {
     "duration": 0.007008,
     "end_time": "2025-04-19T13:04:37.911372",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.904364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BiTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4104e300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.926931Z",
     "iopub.status.busy": "2025-04-19T13:04:37.926294Z",
     "iopub.status.idle": "2025-04-19T13:04:37.931441Z",
     "shell.execute_reply": "2025-04-19T13:04:37.930756Z"
    },
    "papermill": {
     "duration": 0.014131,
     "end_time": "2025-04-19T13:04:37.932600",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.918469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.bi_encoder = BiEncoder(model_name, model_path)\n",
    "\n",
    "    def train(self, dataset, loss, params):\n",
    "        print(\"Khởi tạo dataset:\")\n",
    "        train_dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n",
    "\n",
    "        print(\"Bắt đầu train: \")\n",
    "\n",
    "         # Khởi tạo hàm mất mát\n",
    "        train_loss = loss(self.bi_encoder.model)\n",
    "        \n",
    "        # Tạo thư mục nếu chưa có\n",
    "        os.makedirs(params['output_path'], exist_ok=True)\n",
    "        \n",
    "        # Huấn luyện với callback\n",
    "        self.bi_encoder.model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=params['num_epochs'],\n",
    "            warmup_steps=params['warmup_steps'],\n",
    "            output_path=params[\"output_path\"],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        return self.bi_encoder.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefcce9",
   "metadata": {
    "papermill": {
     "duration": 0.007049,
     "end_time": "2025-04-19T13:04:37.946983",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.939934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c88762c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:37.962536Z",
     "iopub.status.busy": "2025-04-19T13:04:37.962002Z",
     "iopub.status.idle": "2025-04-19T13:04:37.969988Z",
     "shell.execute_reply": "2025-04-19T13:04:37.969507Z"
    },
    "papermill": {
     "duration": 0.016821,
     "end_time": "2025-04-19T13:04:37.970965",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.954144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed(self, texts):\n",
    "        print(\"Bắt đầu chạy embeddings...\")\n",
    "        texts_embedding = self.model.encode(texts)\n",
    "        texts_embedding = torch.tensor(texts_embedding)\n",
    "\n",
    "        return texts_embedding\n",
    "\n",
    "    def infer(self, corpus, queries):    \n",
    "        class SimilarityModel(nn.Module):\n",
    "            def __init__(self, corpus_embeddings, corpus_cids):\n",
    "                super(SimilarityModel, self).__init__()\n",
    "                self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n",
    "                self.corpus_cids = corpus_cids              # List of CIDs\n",
    "        \n",
    "            def forward(self, question_embedding):\n",
    "                # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n",
    "                question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n",
    "                similarities[similarities == 1] = float('-inf')\n",
    "\n",
    "                # Get the top_n indices with the highest cosine similarity values\n",
    "                sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n",
    "                \n",
    "                \n",
    "                # Return top_n_ids, sorted similarities, and sorted indices\n",
    "                return sorted_similarities, sorted_indices\n",
    "                \n",
    "        # Example device setup\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        # Initialize the similarity model\n",
    "        corpus_embeddings = corpus[\"embedding\"].to(device)\n",
    "        cids = corpus['c_id']\n",
    "\n",
    "        query_embeddings = queries['embedding'].to(device)\n",
    "        qids = queries['q_id']\n",
    "        \n",
    "        similarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            similarity_model = nn.DataParallel(similarity_model)\n",
    "\n",
    "        self.predictions = []\n",
    "        for qid, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"Processing queries\"):\n",
    "            # Convert question_embedding to tensor and move to the device\n",
    "            query_embedding = query_embedding.to(device)\n",
    "            \n",
    "            # Get the top_n most relevant CIDs\n",
    "            sorted_similarities, sorted_indices = similarity_model(query_embedding)\n",
    "            results = []\n",
    "            for idx in range(len(sorted_similarities)):\n",
    "                doc_id = sorted_indices[idx].item()\n",
    "                score = sorted_similarities[idx].item()\n",
    "                rank = idx\n",
    "                row = (doc_id, score)\n",
    "                results.append(row)\n",
    "            self.predictions.append(results[:100])\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b5d16",
   "metadata": {
    "papermill": {
     "duration": 0.007256,
     "end_time": "2025-04-19T13:04:37.985533",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.978277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RetrievalApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ca990fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:38.000928Z",
     "iopub.status.busy": "2025-04-19T13:04:38.000727Z",
     "iopub.status.idle": "2025-04-19T13:04:38.013129Z",
     "shell.execute_reply": "2025-04-19T13:04:38.012608Z"
    },
    "papermill": {
     "duration": 0.021371,
     "end_time": "2025-04-19T13:04:38.014084",
     "exception": false,
     "start_time": "2025-04-19T13:04:37.992713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "class RetrievalApp:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.model = BiEncoder(model_name).model\n",
    "        print(\"Load mô hình.....\")\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "    \n",
    "    def prepare_data(self, data_file):\n",
    "        \"\"\"\n",
    "        Chuẩn bị dữ liệu: chuẩn bị các corpus và queries cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Chuẩn bị data: ......\")\n",
    "        preparer = DataPreparer()\n",
    "        corpus_file = dict()\n",
    "        queries_file = dict()\n",
    "        langs = list(data_file['corpus'].keys())\n",
    "        \n",
    "        for lang in langs:\n",
    "            print(f\"Chuẩn bị data {lang}:.....\")\n",
    "            corpus_file_org = data_file['corpus'][lang]\n",
    "            queries_file_org = data_file['queries'][lang]\n",
    "            corpus_file[lang], queries_file[lang] = preparer.prepare_inference_data(corpus_file_org, queries_file_org, lang)\n",
    "        \n",
    "        return langs, corpus_file, queries_file\n",
    "\n",
    "    def inference(self, langs, corpus_file, queries_file):\n",
    "        \"\"\"\n",
    "        Thực hiện inference cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu inference.....\")\n",
    "        corpus, queries = dict(), dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Load data {lang}:.....\")\n",
    "            corpus_file_cur = corpus_file[lang]\n",
    "            queries_file_cur = queries_file[lang]\n",
    "            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n",
    "\n",
    "        inferencer = Inference(self.model)\n",
    "        for lang in langs:\n",
    "            print(f\"Inference {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang]\n",
    "            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n",
    "\n",
    "        return corpus, queries, inferencer\n",
    "\n",
    "    def predict(self, langs, corpus, queries, inferencer):\n",
    "        \"\"\"\n",
    "        Thực hiện dự đoán.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu dự đoán:.....\")\n",
    "        predictions = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Dự đoán {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang] \n",
    "            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def zip_directory(self, zip_filename, dir_name):\n",
    "        \"\"\"\n",
    "        Nén thư mục thành file zip mà không sử dụng đa luồng.\n",
    "        \"\"\"\n",
    "        print(f\"Đang nén thư mục {dir_name} thành {zip_filename}...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Duyệt qua tất cả các file trong thư mục và nén chúng tuần tự\n",
    "            for root, dirs, files in os.walk(dir_name):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, dir_name)  # Lưu lại cấu trúc thư mục gốc\n",
    "                    zipf.write(file_path, arcname)\n",
    "\n",
    "        print(f\"File zip đã được tạo: {zip_filename}\")\n",
    "\n",
    "    def save_predictions(self, langs, predictions):\n",
    "        \"\"\"\n",
    "        Lưu kết quả dự đoán vào file và nén thư mục.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu xuất file:....\")\n",
    "        predictions_file = dict()\n",
    "        folder_name = f\"/kaggle/working/talent_clef/predict/{self.model_name}/{Timer.get()}\"\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        for lang in langs:\n",
    "            predictions_file[lang] = utils.write_predictions(predictions[lang], folder_name, lang)\n",
    "        \n",
    "        # Nén thư mục sau khi xuất file\n",
    "        zip_filename = folder_name + \".zip\"\n",
    "        self.zip_directory(zip_filename, folder_name)\n",
    "        \n",
    "        return predictions_file, zip_filename\n",
    "\n",
    "    def evaluate(self, langs, predictions_file, data):\n",
    "        \"\"\"\n",
    "        Đánh giá kết quả dự đoán.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu đánh giá:.....\")\n",
    "        ratings = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Đánh giá {lang}:.....\")\n",
    "            run_file, qrels_file = predictions_file[lang], data['qrels'][lang]\n",
    "            ratings[lang] = Evaluate.evaluate(run_file, qrels_file)\n",
    "        return ratings\n",
    "\n",
    "    def __call__(self, data_file):\n",
    "        \"\"\"\n",
    "        Nối các hàm lại với nhau và chạy toàn bộ quy trình.\n",
    "        \"\"\"\n",
    "        langs, corpus_file, queries_file = self.prepare_data(data_file)\n",
    "        corpus, queries, inferencer = self.inference(langs, corpus_file, queries_file)\n",
    "        predictions = self.predict(langs, corpus, queries, inferencer)\n",
    "        predictions_file, zip_filename = self.save_predictions(langs, predictions)\n",
    "        ratings = self.evaluate(langs, predictions_file, data_file)\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733279ab",
   "metadata": {
    "papermill": {
     "duration": 0.006974,
     "end_time": "2025-04-19T13:04:38.028390",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.021416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SetupEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae3cabf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:38.043329Z",
     "iopub.status.busy": "2025-04-19T13:04:38.043125Z",
     "iopub.status.idle": "2025-04-19T13:04:38.047575Z",
     "shell.execute_reply": "2025-04-19T13:04:38.047068Z"
    },
    "papermill": {
     "duration": 0.013124,
     "end_time": "2025-04-19T13:04:38.048599",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.035475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_git_workspace_wandb():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    git_token = user_secrets.get_secret(\"github\")\n",
    "    wandp_api = user_secrets.get_secret(\"wandb\")\n",
    "\n",
    "    import subprocess\n",
    "\n",
    "    # Thay {git_token} bằng token thực tế của bạn\n",
    "    repo_url = f\"https://hoivd:{git_token}@github.com/hoivd/talent_clef\"\n",
    "    \n",
    "    # Lệnh git clone\n",
    "    command = [\"git\", \"clone\", repo_url]\n",
    "    \n",
    "    try:\n",
    "        # Chạy lệnh và đợi hoàn tất\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        print(\"Clone thành công!\")\n",
    "        print(\"Stdout:\", result.stdout)  # In stdout nếu có\n",
    "        print(\"Stderr:\", result.stderr)  # In stderr để thấy tiến trình\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Lỗi khi clone repository:\")\n",
    "        print(e.stderr)  # In thông báo lỗi nếu có\n",
    "        # Đăng nhập W&B\n",
    "    \n",
    "    wandb.login(key=wandp_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056d7c8",
   "metadata": {
    "papermill": {
     "duration": 0.007022,
     "end_time": "2025-04-19T13:04:38.062809",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.055787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6c2f868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:38.078041Z",
     "iopub.status.busy": "2025-04-19T13:04:38.077871Z",
     "iopub.status.idle": "2025-04-19T13:04:38.089844Z",
     "shell.execute_reply": "2025-04-19T13:04:38.089385Z"
    },
    "papermill": {
     "duration": 0.020934,
     "end_time": "2025-04-19T13:04:38.090835",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.069901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class utils:\n",
    "    @staticmethod\n",
    "    def read_csv(input_path, columns=None):\n",
    "        print(\"Đọc csv file:\")\n",
    "        # Kiểm tra input_path ngay từ đầu\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file CSV.\")\n",
    "        \n",
    "        try:  \n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8')\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8', names=columns)\n",
    "            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_tsv(input_path, columns=None):\n",
    "        print(\"Đọc tsv file:\")\n",
    "        # Kiểm tra input_path ngay từ đầu\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file TSV.\")\n",
    "        \n",
    "        try:  \n",
    "            df = None\n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')  # Thêm sep='\\t' cho TSV\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8', names=columns)\n",
    "            \n",
    "            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n",
    "            print(df.head())\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def write_csv(df, output_path):\n",
    "        try:\n",
    "            # Xuất ra file CSV\n",
    "            df.to_csv(output_path, sep=',', encoding='utf-8', index=False)\n",
    "            print(f\"Đã xuất dữ liệu ra {output_path}\")\n",
    "            return output_path\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xuất file CSV: {e}\")\n",
    "            raise\n",
    "        \n",
    "    @staticmethod\n",
    "    def write_predictions(predictions, folder_name, lang):\n",
    "        \n",
    "        output_path = f\"{folder_name}/run_{lang}.trec\"\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                for query_predict in predictions: \n",
    "                    for line in query_predict:  # rank bắt đầu từ 1\n",
    "                        f.write(' '.join(str(x) for x in line) + '\\n')\n",
    "            print(f\"Đã xuất file TREC ra {output_path}\")  \n",
    "            return output_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xuất file TREC: {e}\")\n",
    "            raise\n",
    "\n",
    "        return output_path\n",
    "\n",
    "    @staticmethod\n",
    "    def write_pkl(data, output_path):\n",
    "        print(\"Ghi file pkl:........\")\n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(\"Ghi file thành công\")\n",
    "        return output_path\n",
    "\n",
    "    @staticmethod\n",
    "    def read_pkl(output_path):\n",
    "        print(\"Đọc file pkl:........\")\n",
    "        with open(output_path, 'rb') as f:\n",
    "            loaded_data = pickle.load(f)\n",
    "        print(\"Đọc file pkl thành công\")\n",
    "        return loaded_data\n",
    "\n",
    "    @staticmethod\n",
    "    def split_dict_to_parts(data, num_parts=5):\n",
    "        # Hàm chia một list thành các phần\n",
    "        def split_list(lst, num_parts):\n",
    "            avg_len = len(lst) // num_parts\n",
    "            parts = [lst[i * avg_len: (i + 1) * avg_len] for i in range(num_parts - 1)]\n",
    "            parts.append(lst[(num_parts - 1) * avg_len:])  # phần còn lại\n",
    "            return parts\n",
    "        \n",
    "        dict_parts = []\n",
    "        \n",
    "        # Duyệt qua tất cả các ngôn ngữ trong data\n",
    "        for lang, values in data.items():\n",
    "            # Duyệt qua tất cả các list trong mỗi ngôn ngữ\n",
    "            for key, value in values.items():\n",
    "                # Chia list thành các phần\n",
    "                parts = split_list(value, num_parts)\n",
    "                \n",
    "                # Tạo các dict con cho từng phần của mỗi list\n",
    "                for i in range(num_parts):\n",
    "                    if len(dict_parts) <= i:\n",
    "                        dict_parts.append(dict())  # Nếu chưa có phần thì tạo dict mới\n",
    "                    if dict_parts[i].get(lang) == None:\n",
    "                        dict_parts[i][lang] = dict()\n",
    "                    dict_parts[i][lang][f\"{key}\"] = parts[i]\n",
    "    \n",
    "        return dict_parts\n",
    "\n",
    "    @staticmethod\n",
    "    def get_dict_in_range(data, start, end):\n",
    "        result = {}\n",
    "        \n",
    "        for lang, values in data.items():\n",
    "            # Tạo một dict con chứa các phần tử trong khoảng từ start đến end\n",
    "            result[lang] = {}\n",
    "            for key, value in values.items():\n",
    "                # Lấy các phần tử trong khoảng (start, end) cho từng list\n",
    "                result[lang][key] = value[start:end+1]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2b05d",
   "metadata": {
    "papermill": {
     "duration": 0.006981,
     "end_time": "2025-04-19T13:04:38.105126",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.098145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bb38c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:38.120394Z",
     "iopub.status.busy": "2025-04-19T13:04:38.119805Z",
     "iopub.status.idle": "2025-04-19T13:04:38.125415Z",
     "shell.execute_reply": "2025-04-19T13:04:38.124730Z"
    },
    "papermill": {
     "duration": 0.014192,
     "end_time": "2025-04-19T13:04:38.126422",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.112230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    @staticmethod\n",
    "    def evaluate(predictions_path, qrels_path):\n",
    "        command = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_path, \"--run\", predictions_path]\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "\n",
    "        return Evaluate.extract_metrics(result)\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_metrics(result, language=\"en-en\"):\n",
    "        stdout = result.stdout\n",
    "        map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n",
    "        mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n",
    "        ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n",
    "        precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n",
    "        precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n",
    "        precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n",
    "    \n",
    "        metrics = {\n",
    "            \"map\": map_value,\n",
    "            \"mrr\": mrr,\n",
    "            \"ndcg\": ndcg,\n",
    "            \"precision@5\": precision_5,\n",
    "            \"precision@10\": precision_10,\n",
    "            \"precision@100\": precision_100\n",
    "        }\n",
    "        return metrics     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d24ceb",
   "metadata": {
    "papermill": {
     "duration": 0.00696,
     "end_time": "2025-04-19T13:04:38.140547",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.133587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ModelLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eee4b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:38.155619Z",
     "iopub.status.busy": "2025-04-19T13:04:38.155421Z",
     "iopub.status.idle": "2025-04-19T13:04:38.163592Z",
     "shell.execute_reply": "2025-04-19T13:04:38.162921Z"
    },
    "papermill": {
     "duration": 0.01684,
     "end_time": "2025-04-19T13:04:38.164595",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.147755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelLogger:\n",
    "    def __init__(self, model_name, loss_function, num_epochs, metrics, notes=\"\", training_time=None,\n",
    "                 folder=\"/kaggle/working/talent_clef/results\", file_name=\"model_info.csv\"):\n",
    "        self.model_name = model_name\n",
    "        self.loss = loss_function\n",
    "        self.epochs = num_epochs\n",
    "        self.metrics = metrics\n",
    "        self.notes = notes\n",
    "        self.training_time = training_time\n",
    "        self.folder = folder\n",
    "        self.file_path = os.path.join(folder, file_name)\n",
    "    \n",
    "    def compute_average_map(self):\n",
    "        map_values = [lang['map'] for lang in self.metrics.values() if 'map' in lang]\n",
    "        return sum(map_values) / len(map_values) if map_values else None\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"model_name\": [self.model_name],\n",
    "            \"Avg result\": [self.compute_average_map()],\n",
    "            \"en-en result\": [self.metrics.get(\"en-en\", \"\")],\n",
    "            \"es-es result\": [self.metrics.get(\"es-es\", \"\")],\n",
    "            \"de-de result\": [self.metrics.get(\"de-de\", \"\")],\n",
    "            \"zh-zh result\": [self.metrics.get(\"zh-zh\", \"\")],\n",
    "            \"en-es result\": [self.metrics.get(\"en-es\", \"\")],\n",
    "            \"en-de result\": [self.metrics.get(\"en-de\", \"\")],\n",
    "            \"en-zh result\": [self.metrics.get(\"en-zh\", \"\")],\n",
    "            \"loss\": [self.loss],\n",
    "            \"epochs\": [self.epochs],\n",
    "            \"training_time (s)\": [self.training_time],\n",
    "            \"date\": [Timer.get()],\n",
    "            \"notes\": [self.notes]\n",
    "        }\n",
    "\n",
    "    def save(self):\n",
    "        # Tạo thư mục nếu chưa tồn tại\n",
    "        os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "        # Tạo DataFrame từ dict\n",
    "        df_new = pd.DataFrame(self.to_dict())\n",
    "\n",
    "        if os.path.exists(self.file_path):\n",
    "            df_existing = pd.read_csv(self.file_path)\n",
    "            df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "            df_updated.to_csv(self.file_path, index=False)\n",
    "            print(f\"✅ Đã thêm dữ liệu vào file: {self.file_path}\")\n",
    "        else:\n",
    "            df_new.to_csv(self.file_path, index=False)\n",
    "            print(f\"✅ Đã tạo file mới: {self.file_path}\")\n",
    "\n",
    "    def show_log(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            print(f\"\\n📄 Nội dung file log:\")\n",
    "            log_df = utils.read_csv(self.file_path)\n",
    "            print(log_df)\n",
    "        else:\n",
    "            print(\"⚠️ Chưa có file log để hiển thị.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82add73f",
   "metadata": {
    "papermill": {
     "duration": 0.00704,
     "end_time": "2025-04-19T13:04:38.178801",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.171761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "babb853f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:38.194027Z",
     "iopub.status.busy": "2025-04-19T13:04:38.193633Z",
     "iopub.status.idle": "2025-04-19T13:04:38.229212Z",
     "shell.execute_reply": "2025-04-19T13:04:38.228614Z"
    },
    "papermill": {
     "duration": 0.044323,
     "end_time": "2025-04-19T13:04:38.230254",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.185931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-19_20-04-38\n"
     ]
    }
   ],
   "source": [
    "class Timer:\n",
    "    @staticmethod\n",
    "    def get():\n",
    "        # Lấy múi giờ Việt Nam (UTC+7)\n",
    "        vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n",
    "        \n",
    "        # Lấy thời gian hiện tại ở UTC\n",
    "        utc_now = datetime.now(pytz.utc)\n",
    "        \n",
    "        # Chuyển thời gian UTC sang múi giờ Việt Nam\n",
    "        vietnam_time = utc_now.astimezone(vietnam_timezone)\n",
    "        \n",
    "        # Trả về thời gian đã định dạng theo kiểu YYYY-MM-DD HH:MM:SS\n",
    "        return vietnam_time.strftime(\"%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Gọi hàm và in kết quả\n",
    "print(Timer.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e8999",
   "metadata": {
    "papermill": {
     "duration": 0.007128,
     "end_time": "2025-04-19T13:04:38.244683",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.237555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hàm thực thi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8be14d",
   "metadata": {
    "papermill": {
     "duration": 0.007007,
     "end_time": "2025-04-19T13:04:38.258916",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.251909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Clone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5508d4f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:04:38.274073Z",
     "iopub.status.busy": "2025-04-19T13:04:38.273901Z",
     "iopub.status.idle": "2025-04-19T13:05:13.094633Z",
     "shell.execute_reply": "2025-04-19T13:05:13.093579Z"
    },
    "papermill": {
     "duration": 34.829751,
     "end_time": "2025-04-19T13:05:13.095927",
     "exception": false,
     "start_time": "2025-04-19T13:04:38.266176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: fineGrained).\r\n",
      "The token `kaggle` has been saved to /root/.cache/huggingface/stored_tokens\r\n",
      "Your token has been saved to /root/.cache/huggingface/token\r\n",
      "Login successful.\r\n",
      "The current active token is: `kaggle`\r\n",
      "Cloning into '/kaggle/working/models'...\r\n",
      "remote: Enumerating objects: 30, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\r\n",
      "remote: Total 30 (delta 3), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\r\n",
      "Unpacking objects: 100% (30/30), 164.57 KiB | 3.36 MiB/s, done.\r\n",
      "Filtering content: 100% (6/6), 958.41 MiB | 157.96 MiB/s, done.\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoivinh20789\u001b[0m (\u001b[33mhoivinh20789-uit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clone thành công!\n",
      "Stdout: \n",
      "Stderr: Cloning into 'talent_clef'...\n",
      "Updating files:  53% (75/140)\n",
      "Updating files:  54% (76/140)\n",
      "Updating files:  55% (77/140)\n",
      "Updating files:  56% (79/140)\n",
      "Updating files:  57% (80/140)\n",
      "Updating files:  58% (82/140)\n",
      "Updating files:  59% (83/140)\n",
      "Updating files:  60% (84/140)\n",
      "Updating files:  60% (85/140)\n",
      "Updating files:  61% (86/140)\n",
      "Updating files:  62% (87/140)\n",
      "Updating files:  63% (89/140)\n",
      "Updating files:  64% (90/140)\n",
      "Updating files:  65% (91/140)\n",
      "Updating files:  66% (93/140)\n",
      "Updating files:  67% (94/140)\n",
      "Updating files:  68% (96/140)\n",
      "Updating files:  69% (97/140)\n",
      "Updating files:  70% (98/140)\n",
      "Updating files:  71% (100/140)\n",
      "Updating files:  72% (101/140)\n",
      "Updating files:  73% (103/140)\n",
      "Updating files:  74% (104/140)\n",
      "Updating files:  75% (105/140)\n",
      "Updating files:  76% (107/140)\n",
      "Updating files:  77% (108/140)\n",
      "Updating files:  78% (110/140)\n",
      "Updating files:  79% (111/140)\n",
      "Updating files:  80% (112/140)\n",
      "Updating files:  81% (114/140)\n",
      "Updating files:  82% (115/140)\n",
      "Updating files:  83% (117/140)\n",
      "Updating files:  84% (118/140)\n",
      "Updating files:  85% (119/140)\n",
      "Updating files:  86% (121/140)\n",
      "Updating files:  87% (122/140)\n",
      "Updating files:  87% (123/140)\n",
      "Updating files:  88% (124/140)\n",
      "Updating files:  89% (125/140)\n",
      "Updating files:  90% (126/140)\n",
      "Updating files:  91% (128/140)\n",
      "Updating files:  92% (129/140)\n",
      "Updating files:  93% (131/140)\n",
      "Updating files:  94% (132/140)\n",
      "Updating files:  95% (133/140)\n",
      "Updating files:  96% (135/140)\n",
      "Updating files:  97% (136/140)\n",
      "Updating files:  98% (138/140)\n",
      "Updating files:  99% (139/140)\n",
      "Updating files: 100% (140/140)\n",
      "Updating files: 100% (140/140), done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "huggingface_api = user_secrets.get_secret(\"huggingface\")\n",
    "\n",
    "!huggingface-cli login --token {huggingface_api}\n",
    "!git clone https://huggingface.co/hoivinh20789/talent_clef /kaggle/working/models\n",
    "load_git_workspace_wandb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10d0aa",
   "metadata": {
    "papermill": {
     "duration": 0.007792,
     "end_time": "2025-04-19T13:05:13.112648",
     "exception": false,
     "start_time": "2025-04-19T13:05:13.104856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GenerateNegativePair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0026fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:05:13.129387Z",
     "iopub.status.busy": "2025-04-19T13:05:13.129106Z",
     "iopub.status.idle": "2025-04-19T13:05:15.488173Z",
     "shell.execute_reply": "2025-04-19T13:05:15.487253Z"
    },
    "papermill": {
     "duration": 2.368951,
     "end_time": "2025-04-19T13:05:15.489455",
     "exception": false,
     "start_time": "2025-04-19T13:05:13.120504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device sử dụng: cuda\n",
      "Tải mô hình từ đường dẫn cục bộ: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6\n",
      "Mô hình đã được khởi tạo thành công!\n",
      "Load mô hình.....\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model_path = \"/kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6\"\n",
    "retrieval = RetrievalTrainData(model_name, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58cbc824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:05:15.507167Z",
     "iopub.status.busy": "2025-04-19T13:05:15.506938Z",
     "iopub.status.idle": "2025-04-19T13:05:16.686107Z",
     "shell.execute_reply": "2025-04-19T13:05:16.685351Z"
    },
    "papermill": {
     "duration": 1.189193,
     "end_time": "2025-04-19T13:05:16.687350",
     "exception": false,
     "start_time": "2025-04-19T13:05:15.498157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chuẩn bị data: ......\n",
      "['en-en']\n",
      "Chuẩn bị data en-en:.....\n",
      "Xuất query và corpus từ train:........\n",
      "Đã xuất dữ liệu ra queries_train.csv\n",
      "Đã xuất dữ liệu ra corpus_train.csv\n"
     ]
    }
   ],
   "source": [
    "data_file = {\n",
    "    \"source_file\": { \"en-en\": \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"}\n",
    "}\n",
    "langs, corpus_file, queries_file = retrieval.prepare_query_corpus(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96e53de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:05:16.705105Z",
     "iopub.status.busy": "2025-04-19T13:05:16.704620Z",
     "iopub.status.idle": "2025-04-19T13:05:34.366847Z",
     "shell.execute_reply": "2025-04-19T13:05:34.366204Z"
    },
    "papermill": {
     "duration": 17.672399,
     "end_time": "2025-04-19T13:05:34.368239",
     "exception": false,
     "start_time": "2025-04-19T13:05:16.695840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu inference.....\n",
      "Load data en-en:.....\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ corpus_train.csv thành công\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ queries_train.csv thành công\n",
      "Inference en-en:.....\n",
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3ff267212d43be8981c02999a8a248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/844 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc09a5975741450e8d7845225254cfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/844 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, queries, inferencer = retrieval.inference(langs, corpus_file, queries_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fc5c9ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:05:34.386775Z",
     "iopub.status.busy": "2025-04-19T13:05:34.386290Z",
     "iopub.status.idle": "2025-04-19T13:05:34.389879Z",
     "shell.execute_reply": "2025-04-19T13:05:34.389389Z"
    },
    "papermill": {
     "duration": 0.01358,
     "end_time": "2025-04-19T13:05:34.390833",
     "exception": false,
     "start_time": "2025-04-19T13:05:34.377253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_parts = utils.split_dict_to_parts(queries, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e02f027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:05:34.408804Z",
     "iopub.status.busy": "2025-04-19T13:05:34.408290Z",
     "iopub.status.idle": "2025-04-19T13:05:34.411266Z",
     "shell.execute_reply": "2025-04-19T13:05:34.410685Z"
    },
    "papermill": {
     "duration": 0.013342,
     "end_time": "2025-04-19T13:05:34.412371",
     "exception": false,
     "start_time": "2025-04-19T13:05:34.399029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "part = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03af7009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:05:34.429691Z",
     "iopub.status.busy": "2025-04-19T13:05:34.429484Z",
     "iopub.status.idle": "2025-04-19T15:41:48.041319Z",
     "shell.execute_reply": "2025-04-19T15:41:48.040509Z"
    },
    "papermill": {
     "duration": 9373.621782,
     "end_time": "2025-04-19T15:41:48.042480",
     "exception": false,
     "start_time": "2025-04-19T13:05:34.420698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu dự đoán:.....\n",
      "Dự đoán en-en:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 13502/13502 [2:36:13<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = retrieval.predict(langs, corpus, queries_parts[part], inferencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "181a3fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:41:49.112970Z",
     "iopub.status.busy": "2025-04-19T15:41:49.112460Z",
     "iopub.status.idle": "2025-04-19T15:41:49.531050Z",
     "shell.execute_reply": "2025-04-19T15:41:49.530247Z"
    },
    "papermill": {
     "duration": 0.950642,
     "end_time": "2025-04-19T15:41:49.532216",
     "exception": false,
     "start_time": "2025-04-19T15:41:48.581574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ghi file pkl:........\n",
      "Ghi file thành công\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/negative_pair_new/prediction_p2.pkl'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = \"/kaggle/working/negative_pair_new\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "prediction_path = f\"/kaggle/working/negative_pair_new/prediction_p{part+1}.pkl\"\n",
    "utils.write_pkl(predictions, prediction_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9474.259719,
   "end_time": "2025-04-19T15:41:53.645058",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-19T13:03:59.385339",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b99267b9a8a4a3193e835cb2329b24f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2adeae2cacf8426b9940db04e32fda1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35253ba390174997b5154010f9609238": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac68fde64d9e4d1f9d8cf9e8646fe9c6",
       "placeholder": "​",
       "style": "IPY_MODEL_d80569ad8f9d423aa9b69d60c0ec7d2a",
       "tabbable": null,
       "tooltip": null,
       "value": "Batches: 100%"
      }
     },
     "4618a9cc1e80481696fd542d4dda4293": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd61f471c2f54b7ebb99257b00cbf94d",
       "max": 844.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e0a3584dd6d04e5382bb9f42f3b88763",
       "tabbable": null,
       "tooltip": null,
       "value": 844.0
      }
     },
     "5761d3bdb2ec4aa28f65925b05da56be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "626a18a8c29a4838872a1d7a4b176cce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_abce7d54dbaf451bba5fa446f7db6376",
       "placeholder": "​",
       "style": "IPY_MODEL_f896f3e3723348ea9ebd4709037931ff",
       "tabbable": null,
       "tooltip": null,
       "value": " 844/844 [00:07&lt;00:00, 109.81it/s]"
      }
     },
     "64f0f41ddf304080b4e0ceffdbe27072": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6a03e648b3ea411c920cf3aed3d79e84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8e9b580478ef406f91438ea07c4bff6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c66e62f1c6e4d4c9345aabd928eaa7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abce7d54dbaf451bba5fa446f7db6376": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac68fde64d9e4d1f9d8cf9e8646fe9c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3d51abfed0e4aa3b1272f95b7d31861": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c66e62f1c6e4d4c9345aabd928eaa7a",
       "placeholder": "​",
       "style": "IPY_MODEL_6a03e648b3ea411c920cf3aed3d79e84",
       "tabbable": null,
       "tooltip": null,
       "value": "Batches: 100%"
      }
     },
     "bc09a5975741450e8d7845225254cfe8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_35253ba390174997b5154010f9609238",
        "IPY_MODEL_ff3b332679c74214862c5f6cc12a3b10",
        "IPY_MODEL_626a18a8c29a4838872a1d7a4b176cce"
       ],
       "layout": "IPY_MODEL_8e9b580478ef406f91438ea07c4bff6b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c352d67446e4446c9b28ac25ced6158f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd3f119c8e3d4b23b9c2004f80e281cf",
       "placeholder": "​",
       "style": "IPY_MODEL_64f0f41ddf304080b4e0ceffdbe27072",
       "tabbable": null,
       "tooltip": null,
       "value": " 844/844 [00:08&lt;00:00, 107.95it/s]"
      }
     },
     "d80569ad8f9d423aa9b69d60c0ec7d2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dd3f119c8e3d4b23b9c2004f80e281cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd61f471c2f54b7ebb99257b00cbf94d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0a3584dd6d04e5382bb9f42f3b88763": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eb3ff267212d43be8981c02999a8a248": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b3d51abfed0e4aa3b1272f95b7d31861",
        "IPY_MODEL_4618a9cc1e80481696fd542d4dda4293",
        "IPY_MODEL_c352d67446e4446c9b28ac25ced6158f"
       ],
       "layout": "IPY_MODEL_2adeae2cacf8426b9940db04e32fda1f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f896f3e3723348ea9ebd4709037931ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ff3b332679c74214862c5f6cc12a3b10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0b99267b9a8a4a3193e835cb2329b24f",
       "max": 844.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5761d3bdb2ec4aa28f65925b05da56be",
       "tabbable": null,
       "tooltip": null,
       "value": 844.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
