{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209036ad",
   "metadata": {
    "papermill": {
     "duration": 0.007716,
     "end_time": "2025-04-24T06:05:18.929960",
     "exception": false,
     "start_time": "2025-04-24T06:05:18.922244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d07efb2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:18.945081Z",
     "iopub.status.busy": "2025-04-24T06:05:18.944773Z",
     "iopub.status.idle": "2025-04-24T06:05:47.241349Z",
     "shell.execute_reply": "2025-04-24T06:05:47.240647Z"
    },
    "papermill": {
     "duration": 28.305971,
     "end_time": "2025-04-24T06:05:47.243017",
     "exception": false,
     "start_time": "2025-04-24T06:05:18.937046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchmetrics.retrieval import RetrievalMAP\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import wandb\n",
    "import ast\n",
    "import subprocess\n",
    "import pickle\n",
    "import shutil\n",
    "import datetime\n",
    "import pytz\n",
    "from huggingface_hub import HfApi, upload_folder\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a95bb68",
   "metadata": {
    "papermill": {
     "duration": 0.006611,
     "end_time": "2025-04-24T06:05:47.257187",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.250576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PositiveExampleMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe893a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.271598Z",
     "iopub.status.busy": "2025-04-24T06:05:47.271339Z",
     "iopub.status.idle": "2025-04-24T06:05:47.276841Z",
     "shell.execute_reply": "2025-04-24T06:05:47.276052Z"
    },
    "papermill": {
     "duration": 0.01412,
     "end_time": "2025-04-24T06:05:47.278006",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.263886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MiningPosExample:\n",
    "    def __init__(self):\n",
    "        self.data = None  # Khởi tạo thuộc tính self.data là None\n",
    "\n",
    "     # Phương thức __len__ để trả về số dòng của data\n",
    "    def __len__(self):\n",
    "        if self.data is not None:\n",
    "            return len(self.data)\n",
    "        return 0  # Nếu self.data chưa được gán (None), trả về 0\n",
    "    \n",
    "    # Phương thức __getitem__ để truy xuất một dòng trong data theo chỉ số\n",
    "    def __getitem__(self, index):\n",
    "        if self.data is not None:\n",
    "            return self.data.iloc[index]\n",
    "        raise IndexError(\"Index out of range\")  # Nếu self.data là None, raise lỗi\n",
    "        \n",
    "    def mining_pos_example(self, data_file):\n",
    "        # Đọc dữ liệu từ file (giả sử là file CSV)\n",
    "        df = pd.read_csv(data_file)\n",
    "        df['jobtitles'] = df['jobtitles'].apply(ast.literal_eval)\n",
    "        # Lấy các cột 'jobtitles' và 'skills_gen', sau đó \"phân nổ\" danh sách trong cột 'jobtitles'\n",
    "        new_df = df[['jobtitles', 'skills_gen']].explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill'})\n",
    "        \n",
    "        # Thêm cột 'label' với giá trị toàn bộ là 1\n",
    "        new_df['label'] = 1\n",
    "        \n",
    "        # Lưu kết quả vào self.data\n",
    "        self.data = new_df\n",
    "        \n",
    "        return new_df\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167e682",
   "metadata": {
    "papermill": {
     "duration": 0.006594,
     "end_time": "2025-04-24T06:05:47.291628",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.285034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NegativeExampleMining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cce05d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.306049Z",
     "iopub.status.busy": "2025-04-24T06:05:47.305806Z",
     "iopub.status.idle": "2025-04-24T06:05:47.312702Z",
     "shell.execute_reply": "2025-04-24T06:05:47.311877Z"
    },
    "papermill": {
     "duration": 0.015443,
     "end_time": "2025-04-24T06:05:47.313852",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.298409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MiningNegExample:\n",
    "    def __init__(self):\n",
    "        self.data = None  # Khởi tạo thuộc tính self.data là None\n",
    "    \n",
    "     # Phương thức __len__ để trả về số dòng của data\n",
    "    def __len__(self):\n",
    "        if self.data is not None:\n",
    "            return len(self.data)\n",
    "        return 0  # Nếu self.data chưa được gán (None), trả về 0\n",
    "    \n",
    "    # Phương thức __getitem__ để truy xuất một dòng trong data theo chỉ số\n",
    "    def __getitem__(self, index):\n",
    "        if self.data is not None:\n",
    "            return self.data.iloc[index]\n",
    "        raise IndexError(\"Index out of range\")  # Nếu self.data là None, raise lỗi\n",
    "\n",
    "    def prepare_source_file(self, source_file):\n",
    "        source_df = pd.read_csv(source_file)\n",
    "        source_df['jobtitles'] = source_df['jobtitles'].apply(ast.literal_eval)\n",
    "        # Lấy các cột 'jobtitles' và 'skills_gen', sau đó \"phân nổ\" danh sách trong cột 'jobtitles'\n",
    "        source_df = source_df.explode('jobtitles').rename(columns={'jobtitles': 'jobtitle', 'skills_gen': 'skill', 'tid': 'gid'})\n",
    "        source_df = source_df.reset_index(drop=True).reset_index(names='tid')\n",
    "\n",
    "        return source_df\n",
    "        \n",
    "    def mining_neg_example(self, pair_file, source_file):\n",
    "        # Đọc dữ liệu từ file (giả sử là file CSV)\n",
    "        \n",
    "        source_df = self.prepare_source_file(source_file)\n",
    "        pair_df = pd.read_csv(pair_file)\n",
    "        pair_df = pair_df.merge(source_df, left_on='q_id', right_on='tid')                \n",
    "        pair_df = pair_df.merge(source_df, left_on='c_id', right_on='tid')\n",
    "        pair_df = pair_df.rename(columns={'jobtitle_x': 'q_jobtitle', 'skill_x': 'q_skill', 'jobtitle_y': 'c_jobtitle', 'skill_y': 'c_skill'})\n",
    "        query_pair = pair_df[['q_jobtitle', 'c_skill', 'label']].rename(columns={'q_jobtitle': 'jobtitle', 'c_skill': 'skill'})\n",
    "        corpus_pair = pair_df[['c_jobtitle', 'q_skill', 'label']].rename(columns={'c_jobtitle': 'jobtitle', 'q_skill': 'skill'})\n",
    "        neg_pair = pd.concat([query_pair, corpus_pair], axis=0)\n",
    "\n",
    "        self.data = neg_pair\n",
    "        return neg_pair\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f370a8",
   "metadata": {
    "papermill": {
     "duration": 0.006851,
     "end_time": "2025-04-24T06:05:47.327748",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.320897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataPrepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcce8848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.342102Z",
     "iopub.status.busy": "2025-04-24T06:05:47.341835Z",
     "iopub.status.idle": "2025-04-24T06:05:47.347529Z",
     "shell.execute_reply": "2025-04-24T06:05:47.346750Z"
    },
    "papermill": {
     "duration": 0.014279,
     "end_time": "2025-04-24T06:05:47.348709",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.334430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreparer:\n",
    "    def prepare_train_data(self, neg_pair_file, source_file):\n",
    "        print(\"Đọc dữ liệu train_org:\")\n",
    "        \n",
    "        pos_miner = MiningPosExample()\n",
    "        pos_df = pos_miner.mining_pos_example(source_file)\n",
    "        print(pos_df.head())\n",
    "\n",
    "        neg_miner = MiningNegExample()\n",
    "        neg_df = neg_miner.mining_neg_example(neg_pair_file, source_file)\n",
    "        print(neg_df.head())\n",
    "\n",
    "        train_df = pd.concat([pos_df, neg_df], axis=0)\n",
    "        train_df = train_df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "\n",
    "        print(train_df.head())\n",
    "        print(f\"Cột dữ liệu: {train_df.columns}\")\n",
    "        print(\"Xuất dữ liệu train sau khi chuẩn bị:\")\n",
    "        train_file = \"/kaggle/working/train.csv\"\n",
    "        utils.write_csv(train_df, train_file)\n",
    "        return train_df, train_file\n",
    "\n",
    "    def prepare_inference_data(self, corpus_path, queries_path, lang):\n",
    "        print(\"Đọc dữ liệu inference:\")\n",
    "        corpus_df = utils.read_tsv(corpus_path)\n",
    "        queries_df = utils.read_tsv(queries_path)\n",
    "        \n",
    "        print(\"Xuất dữ liệu inference:\")\n",
    "        corpus_out_path = f\"/kaggle/working/corpus_{lang}.csv\"\n",
    "        queries_out_path = f\"/kaggle/working/queries_{lang}.csv\"\n",
    "        utils.write_csv(corpus_df, corpus_out_path)\n",
    "        utils.write_csv(queries_df, queries_out_path)\n",
    "        return corpus_out_path, queries_out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9683f5",
   "metadata": {
    "papermill": {
     "duration": 0.006607,
     "end_time": "2025-04-24T06:05:47.362148",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.355541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4af3ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.376486Z",
     "iopub.status.busy": "2025-04-24T06:05:47.376264Z",
     "iopub.status.idle": "2025-04-24T06:05:47.382511Z",
     "shell.execute_reply": "2025-04-24T06:05:47.381758Z"
    },
    "papermill": {
     "duration": 0.014711,
     "end_time": "2025-04-24T06:05:47.383616",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.368905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = []\n",
    "        for jobtitle, skill, label in data:\n",
    "            self.data.append(InputExample(texts = [jobtitle, skill], label=label))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Trả về số lượng mẫu trong dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def load_train_data(train_path, train_data = None):\n",
    "        if train_data is None:\n",
    "            train_df = utils.read_csv(train_path)\n",
    "        else: \n",
    "            train_df = train_data\n",
    "        jobtitles =  train_df['jobtitle'].tolist()\n",
    "        skills =  train_df['skill'].tolist()\n",
    "        labels = train_df['label'].tolist()\n",
    "\n",
    "        data = []\n",
    "        for idx, jobtitle in enumerate(jobtitles):\n",
    "            data.append((jobtitle, skills[idx], labels[idx]))\n",
    "        return data\n",
    "        \n",
    "    @staticmethod  \n",
    "    def load_inference_data(corpus_path, queries_path):\n",
    "        corpus_df = utils.read_csv(corpus_path)\n",
    "        queries_df = utils.read_csv(queries_path)\n",
    "        \n",
    "        cids_l = corpus_df['c_id'].tolist()\n",
    "        corpus_l = corpus_df['jobtitle'].tolist()\n",
    "        qids_l = queries_df['q_id'].tolist()\n",
    "        queries_l = queries_df['jobtitle'].tolist()\n",
    "\n",
    "        corpus = {\"cid\": cids_l,\n",
    "                \"jobtitle\": corpus_l\n",
    "                }\n",
    "\n",
    "        queries = {\"qid\": qids_l,\n",
    "                \"jobtitle\": queries_l\n",
    "                }\n",
    "        return corpus, queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebbda83",
   "metadata": {
    "papermill": {
     "duration": 0.006476,
     "end_time": "2025-04-24T06:05:47.396711",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.390235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BiEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f108e7a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.410854Z",
     "iopub.status.busy": "2025-04-24T06:05:47.410590Z",
     "iopub.status.idle": "2025-04-24T06:05:47.415329Z",
     "shell.execute_reply": "2025-04-24T06:05:47.414563Z"
    },
    "papermill": {
     "duration": 0.013334,
     "end_time": "2025-04-24T06:05:47.416632",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.403298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiEncoder:\n",
    "    def __init__(self, model_name=None, model_path=None):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Device sử dụng:\", device)\n",
    "        \n",
    "        try:\n",
    "            if model_path is None:\n",
    "                print(f\"Tải mô hình từ Hugging Face với tên: {model_name}\")\n",
    "                self.model = SentenceTransformer(model_name)\n",
    "            else:\n",
    "                print(f\"Tải mô hình từ đường dẫn cục bộ: {model_path}\")\n",
    "                self.model = SentenceTransformer(model_path)\n",
    "            \n",
    "            # Đặt mô hình lên thiết bị\n",
    "            self.model = self.model.to(device)\n",
    "            print(\"Mô hình đã được khởi tạo thành công!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi khởi tạo mô hình: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b11d09",
   "metadata": {
    "papermill": {
     "duration": 0.006598,
     "end_time": "2025-04-24T06:05:47.429997",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.423399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BiTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eaf04cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.443974Z",
     "iopub.status.busy": "2025-04-24T06:05:47.443747Z",
     "iopub.status.idle": "2025-04-24T06:05:47.448743Z",
     "shell.execute_reply": "2025-04-24T06:05:47.447980Z"
    },
    "papermill": {
     "duration": 0.01347,
     "end_time": "2025-04-24T06:05:47.449965",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.436495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.bi_encoder = BiEncoder(model_name, model_path)\n",
    "\n",
    "    def train(self, dataset, loss, params):\n",
    "        print(\"Khởi tạo dataset:\")\n",
    "        train_dataloader = DataLoader(dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "        print(\"Bắt đầu train: \")\n",
    "\n",
    "         # Khởi tạo hàm mất mát\n",
    "        train_loss = loss(self.bi_encoder.model)\n",
    "        \n",
    "        # Tạo thư mục nếu chưa có\n",
    "        os.makedirs(params['output_path'], exist_ok=True)\n",
    "        \n",
    "        # Huấn luyện với callback\n",
    "        self.bi_encoder.model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=params['num_epochs'],\n",
    "            warmup_steps=params['warmup_steps'],\n",
    "            output_path=params[\"output_path\"],\n",
    "            scheduler=params['scheduler'],  # ← thay đổi ở đây\n",
    "            optimizer_params=params['optimizer_params'],\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        return self.bi_encoder.model, params[\"output_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83b3ac",
   "metadata": {
    "papermill": {
     "duration": 0.006512,
     "end_time": "2025-04-24T06:05:47.463084",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.456572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0376c993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.477287Z",
     "iopub.status.busy": "2025-04-24T06:05:47.477007Z",
     "iopub.status.idle": "2025-04-24T06:05:47.484982Z",
     "shell.execute_reply": "2025-04-24T06:05:47.484220Z"
    },
    "papermill": {
     "duration": 0.016596,
     "end_time": "2025-04-24T06:05:47.486269",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.469673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed(self, texts):\n",
    "        print(\"Bắt đầu chạy embeddings...\")\n",
    "        texts_embedding = self.model.encode(texts)\n",
    "        texts_embedding = torch.tensor(texts_embedding)\n",
    "\n",
    "        return texts_embedding\n",
    "\n",
    "    def infer(self, corpus, queries):    \n",
    "        class SimilarityModel(nn.Module):\n",
    "            def __init__(self, corpus_embeddings, corpus_cids):\n",
    "                super(SimilarityModel, self).__init__()\n",
    "                self.corpus_embeddings = corpus_embeddings  # 2D tensor of corpus embeddings\n",
    "                self.corpus_cids = corpus_cids              # List of CIDs\n",
    "        \n",
    "            def forward(self, question_embedding):\n",
    "                # Expand the question_embedding to match corpus_embeddings shape for cosine similarity calculation\n",
    "                question_embedding = question_embedding.unsqueeze(0).expand(self.corpus_embeddings.size(0), -1)\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarities = F.cosine_similarity(question_embedding, self.corpus_embeddings)\n",
    "                similarities[similarities == 1] = float('-inf')\n",
    "\n",
    "                # Get the top_n indices with the highest cosine similarity values\n",
    "                sorted_similarities, sorted_indices = torch.sort(similarities, descending=True)\n",
    "                \n",
    "                \n",
    "                # Return top_n_ids, sorted similarities, and sorted indices\n",
    "                return sorted_similarities, sorted_indices\n",
    "                \n",
    "        # Example device setup\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        # Initialize the similarity model\n",
    "        corpus_embeddings = corpus[\"embedding\"].to(device)\n",
    "        cids = corpus['cid']\n",
    "\n",
    "        query_embeddings = queries['embedding'].to(device)\n",
    "        qids = queries['qid']\n",
    "        \n",
    "        similarity_model = SimilarityModel(corpus_embeddings, cids).to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            similarity_model = nn.DataParallel(similarity_model)\n",
    "\n",
    "        self.predictions = []\n",
    "        for qid, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"Processing queries\"):\n",
    "            # Convert question_embedding to tensor and move to the device\n",
    "            query_embedding = query_embedding.to(device)\n",
    "            \n",
    "            # Get the top_n most relevant CIDs\n",
    "            sorted_similarities, sorted_indices = similarity_model(query_embedding)\n",
    "            results = []\n",
    "            for idx in range(len(sorted_similarities)):\n",
    "                doc_id = sorted_indices[idx].item()\n",
    "                score = sorted_similarities[idx].item()\n",
    "                rank = idx\n",
    "                row = (qid + 1, \"Q0\", doc_id + 1, rank + 1, score, \"4Huiter\")\n",
    "                results.append(row)\n",
    "            self.predictions.append(results)\n",
    "        return self.predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f12e6",
   "metadata": {
    "papermill": {
     "duration": 0.006514,
     "end_time": "2025-04-24T06:05:47.499320",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.492806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RetrievalApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d6db73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.513745Z",
     "iopub.status.busy": "2025-04-24T06:05:47.513514Z",
     "iopub.status.idle": "2025-04-24T06:05:47.525192Z",
     "shell.execute_reply": "2025-04-24T06:05:47.524434Z"
    },
    "papermill": {
     "duration": 0.020624,
     "end_time": "2025-04-24T06:05:47.526521",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.505897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "class RetrievalApp:\n",
    "    def __init__(self, model_name, model_path=None):\n",
    "        self.model = BiEncoder(model_name, model_path).model\n",
    "        print(\"Load mô hình.....\")\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "    \n",
    "    def prepare_data(self, data_file):\n",
    "        \"\"\"\n",
    "        Chuẩn bị dữ liệu: chuẩn bị các corpus và queries cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Chuẩn bị data: ......\")\n",
    "        preparer = DataPreparer()\n",
    "        corpus_file = dict()\n",
    "        queries_file = dict()\n",
    "        langs = list(data_file['corpus'].keys())\n",
    "        \n",
    "        for lang in langs:\n",
    "            print(f\"Chuẩn bị data {lang}:.....\")\n",
    "            corpus_file_org = data_file['corpus'][lang]\n",
    "            queries_file_org = data_file['queries'][lang]\n",
    "            corpus_file[lang], queries_file[lang] = preparer.prepare_inference_data(corpus_file_org, queries_file_org, lang)\n",
    "        \n",
    "        return langs, corpus_file, queries_file\n",
    "\n",
    "    def inference(self, langs, corpus_file, queries_file):\n",
    "        \"\"\"\n",
    "        Thực hiện inference cho từng ngôn ngữ.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu inference.....\")\n",
    "        corpus, queries = dict(), dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Load data {lang}:.....\")\n",
    "            corpus_file_cur = corpus_file[lang]\n",
    "            queries_file_cur = queries_file[lang]\n",
    "            corpus[lang], queries[lang] = Dataset.load_inference_data(corpus_file_cur, queries_file_cur)\n",
    "\n",
    "        inferencer = Inference(self.model)\n",
    "        for lang in langs:\n",
    "            print(f\"Inference {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang]\n",
    "            corpus_cur['embedding'], queries_cur['embedding'] = inferencer.embed(corpus_cur['jobtitle']), inferencer.embed(queries_cur['jobtitle'])\n",
    "\n",
    "        return corpus, queries, inferencer\n",
    "\n",
    "    def predict(self, langs, corpus, queries, inferencer):\n",
    "        \"\"\"\n",
    "        Thực hiện dự đoán.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu dự đoán:.....\")\n",
    "        predictions = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Dự đoán {lang}:.....\")\n",
    "            corpus_cur, queries_cur = corpus[lang], queries[lang] \n",
    "            predictions[lang] = inferencer.infer(corpus_cur, queries_cur)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def zip_directory(self, zip_filename, dir_name):\n",
    "        \"\"\"\n",
    "        Nén thư mục thành file zip mà không sử dụng đa luồng.\n",
    "        \"\"\"\n",
    "        print(f\"Đang nén thư mục {dir_name} thành {zip_filename}...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Duyệt qua tất cả các file trong thư mục và nén chúng tuần tự\n",
    "            for root, dirs, files in os.walk(dir_name):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, dir_name)  # Lưu lại cấu trúc thư mục gốc\n",
    "                    zipf.write(file_path, arcname)\n",
    "\n",
    "        print(f\"File zip đã được tạo: {zip_filename}\")\n",
    "\n",
    "    def save_predictions(self, langs, predictions):\n",
    "        \"\"\"\n",
    "        Lưu kết quả dự đoán vào file và nén thư mục.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu xuất file:....\")\n",
    "        predictions_file = dict()\n",
    "        folder_name = f\"/kaggle/working/talent_clef/predict/{self.model_name}/{Timer.get()}\"\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        for lang in langs:\n",
    "            predictions_file[lang] = utils.write_predictions(predictions[lang], folder_name, lang)\n",
    "        \n",
    "        # Nén thư mục sau khi xuất file\n",
    "        zip_filename = folder_name + \".zip\"\n",
    "        self.zip_directory(zip_filename, folder_name)\n",
    "        \n",
    "        return predictions_file, zip_filename\n",
    "\n",
    "    def evaluate(self, langs, predictions_file, data):\n",
    "        \"\"\"\n",
    "        Đánh giá kết quả dự đoán.\n",
    "        \"\"\"\n",
    "        print(\"Bắt đầu đánh giá:.....\")\n",
    "        ratings = dict()\n",
    "        for lang in langs:\n",
    "            print(f\"Đánh giá {lang}:.....\")\n",
    "            run_file, qrels_file = predictions_file[lang], data['qrels'][lang]\n",
    "            ratings[lang] = Evaluate.evaluate(run_file, qrels_file)\n",
    "        return ratings\n",
    "\n",
    "    def __call__(self, data_file):\n",
    "        \"\"\"\n",
    "        Nối các hàm lại với nhau và chạy toàn bộ quy trình.\n",
    "        \"\"\"\n",
    "        langs, corpus_file, queries_file = self.prepare_data(data_file)\n",
    "        corpus, queries, inferencer = self.inference(langs, corpus_file, queries_file)\n",
    "        predictions = self.predict(langs, corpus, queries, inferencer)\n",
    "        predictions_file, zip_filename = self.save_predictions(langs, predictions)\n",
    "        ratings = self.evaluate(langs, predictions_file, data_file)\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226a94b",
   "metadata": {
    "papermill": {
     "duration": 0.006441,
     "end_time": "2025-04-24T06:05:47.539648",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.533207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SetupEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a143202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.553833Z",
     "iopub.status.busy": "2025-04-24T06:05:47.553597Z",
     "iopub.status.idle": "2025-04-24T06:05:47.562448Z",
     "shell.execute_reply": "2025-04-24T06:05:47.561799Z"
    },
    "papermill": {
     "duration": 0.017454,
     "end_time": "2025-04-24T06:05:47.563735",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.546281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "def load_git_workspace_wandb():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    git_token = user_secrets.get_secret(\"github\")\n",
    "    wandp_api = user_secrets.get_secret(\"wandb\")\n",
    "\n",
    "    import subprocess\n",
    "\n",
    "    # Thay {git_token} bằng token thực tế của bạn\n",
    "    repo_url = f\"https://hoivd:{git_token}@github.com/hoivd/talent_clef\"\n",
    "    \n",
    "    # Lệnh git clone\n",
    "    command = [\"git\", \"clone\", repo_url]\n",
    "    \n",
    "    try:\n",
    "        # Chạy lệnh và đợi hoàn tất\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        print(\"Clone thành công!\")\n",
    "        print(\"Stdout:\", result.stdout)  # In stdout nếu có\n",
    "        print(\"Stderr:\", result.stderr)  # In stderr để thấy tiến trình\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Lỗi khi clone repository:\")\n",
    "        print(e.stderr)  # In thông báo lỗi nếu có\n",
    "        # Đăng nhập W&B\n",
    "    \n",
    "    wandb.login(key=wandp_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac15ec0",
   "metadata": {
    "papermill": {
     "duration": 0.006574,
     "end_time": "2025-04-24T06:05:47.577222",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.570648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca923447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.591559Z",
     "iopub.status.busy": "2025-04-24T06:05:47.591325Z",
     "iopub.status.idle": "2025-04-24T06:05:47.599003Z",
     "shell.execute_reply": "2025-04-24T06:05:47.598379Z"
    },
    "papermill": {
     "duration": 0.01635,
     "end_time": "2025-04-24T06:05:47.600203",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.583853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class utils:\n",
    "    @staticmethod\n",
    "    def read_csv(input_path, columns=None):\n",
    "        print(\"Đọc csv file:\")\n",
    "        # Kiểm tra input_path ngay từ đầu\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file CSV.\")\n",
    "        \n",
    "        try:  \n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8')\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, encoding='utf-8', names=columns)\n",
    "            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_tsv(input_path, columns=None):\n",
    "        print(\"Đọc tsv file:\")\n",
    "        # Kiểm tra input_path ngay từ đầu\n",
    "        if input_path is None:\n",
    "            raise ValueError(\"input_path không được để trống (None). Vui lòng cung cấp đường dẫn file TSV.\")\n",
    "        \n",
    "        try:  \n",
    "            df = None\n",
    "            if columns is None:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')  # Thêm sep='\\t' cho TSV\n",
    "            else:\n",
    "                df = pd.read_csv(input_path, sep='\\t', encoding='utf-8', names=columns)\n",
    "            \n",
    "            print(f\"Đọc dữ liệu từ {input_path} thành công\")\n",
    "            print(df.head())\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc dữ liệu từ {input_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def write_csv(df, output_path):\n",
    "        try:\n",
    "            # Xuất ra file CSV\n",
    "            df.to_csv(output_path, sep=',', encoding='utf-8', index=False)\n",
    "            print(f\"Đã xuất dữ liệu ra {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xuất file CSV: {e}\")\n",
    "            raise\n",
    "        return output_path\n",
    "\n",
    "    @staticmethod\n",
    "    def write_predictions(predictions, folder_name, lang):\n",
    "        \n",
    "        output_path = f\"{folder_name}/run_{lang}.trec\"\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                for query_predict in predictions: \n",
    "                    for line in query_predict:  # rank bắt đầu từ 1\n",
    "                        f.write(' '.join(str(x) for x in line) + '\\n')\n",
    "            print(f\"Đã xuất file TREC ra {output_path}\")  \n",
    "            return output_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xuất file TREC: {e}\")\n",
    "            raise\n",
    "\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083cef5",
   "metadata": {
    "papermill": {
     "duration": 0.00677,
     "end_time": "2025-04-24T06:05:47.613898",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.607128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9227d700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.628921Z",
     "iopub.status.busy": "2025-04-24T06:05:47.628656Z",
     "iopub.status.idle": "2025-04-24T06:05:47.634433Z",
     "shell.execute_reply": "2025-04-24T06:05:47.633645Z"
    },
    "papermill": {
     "duration": 0.01508,
     "end_time": "2025-04-24T06:05:47.635653",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.620573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    @staticmethod\n",
    "    def evaluate(predictions_path, qrels_path):\n",
    "        command = [\"python\", \"/kaggle/working/talentclef25_evaluation_script/talentclef_evaluate.py\", \"--qrels\", qrels_path, \"--run\", predictions_path]\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "\n",
    "        return Evaluate.extract_metrics(result)\n",
    "        \n",
    "    @staticmethod\n",
    "    def extract_metrics(result, language=\"en-en\"):\n",
    "        stdout = result.stdout\n",
    "        map_value = float(stdout.split(\"map: \")[1].split(\"\\n\")[0])\n",
    "        mrr = float(stdout.split(\"mrr: \")[1].split(\"\\n\")[0])\n",
    "        ndcg = float(stdout.split(\"ndcg: \")[1].split(\"\\n\")[0])\n",
    "        precision_5 = float(stdout.split(\"precision@5: \")[1].split(\"\\n\")[0])\n",
    "        precision_10 = float(stdout.split(\"precision@10: \")[1].split(\"\\n\")[0])\n",
    "        precision_100 = float(stdout.split(\"precision@100: \")[1].split(\"\\n\")[0])\n",
    "    \n",
    "        metrics = {\n",
    "            \"map\": map_value,\n",
    "            \"mrr\": mrr,\n",
    "            \"ndcg\": ndcg,\n",
    "            \"precision@5\": precision_5,\n",
    "            \"precision@10\": precision_10,\n",
    "            \"precision@100\": precision_100\n",
    "        }\n",
    "        return metrics     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa663daf",
   "metadata": {
    "papermill": {
     "duration": 0.006801,
     "end_time": "2025-04-24T06:05:47.649113",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.642312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "272cd810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.663915Z",
     "iopub.status.busy": "2025-04-24T06:05:47.663683Z",
     "iopub.status.idle": "2025-04-24T06:05:47.700045Z",
     "shell.execute_reply": "2025-04-24T06:05:47.699215Z"
    },
    "papermill": {
     "duration": 0.045197,
     "end_time": "2025-04-24T06:05:47.701421",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.656224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-24_13-05-47\n"
     ]
    }
   ],
   "source": [
    "class Timer:\n",
    "    @staticmethod\n",
    "    def get():\n",
    "        # Lấy múi giờ Việt Nam (UTC+7)\n",
    "        vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n",
    "        \n",
    "        # Lấy thời gian hiện tại ở UTC\n",
    "        utc_now = datetime.now(pytz.utc)\n",
    "        \n",
    "        # Chuyển thời gian UTC sang múi giờ Việt Nam\n",
    "        vietnam_time = utc_now.astimezone(vietnam_timezone)\n",
    "        \n",
    "        # Trả về thời gian đã định dạng theo kiểu YYYY-MM-DD HH:MM:SS\n",
    "        return vietnam_time.strftime(\"%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Gọi hàm và in kết quả\n",
    "print(Timer.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963b6c5",
   "metadata": {
    "papermill": {
     "duration": 0.00667,
     "end_time": "2025-04-24T06:05:47.715454",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.708784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ModelLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23674d10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.730523Z",
     "iopub.status.busy": "2025-04-24T06:05:47.730266Z",
     "iopub.status.idle": "2025-04-24T06:05:47.739578Z",
     "shell.execute_reply": "2025-04-24T06:05:47.738710Z"
    },
    "papermill": {
     "duration": 0.018381,
     "end_time": "2025-04-24T06:05:47.740780",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.722399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelLogger:\n",
    "    def __init__(self, model_name, loss_function, num_epochs, metrics, notes=\"\", training_time=None,\n",
    "                 folder=\"/kaggle/working/talent_clef/results\", file_name=f\"model_results.csv\"):\n",
    "        self.model_name = model_name\n",
    "        self.loss = loss_function\n",
    "        self.epochs = num_epochs\n",
    "        self.metrics = metrics\n",
    "        self.notes = notes\n",
    "        self.training_time = training_time\n",
    "        self.folder = folder\n",
    "        self.file_path = os.path.join(folder, file_name)\n",
    "    \n",
    "    def compute_average_map(self):\n",
    "        map_values = [lang['map'] for lang in self.metrics.values() if 'map' in lang]\n",
    "        return sum(map_values) / len(map_values) if map_values else None\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"model_name\": [self.model_name],\n",
    "            \"Avg result\": [self.compute_average_map()],\n",
    "            \"en-en result\": [self.metrics.get(\"en-en\", \"\")],\n",
    "            \"es-es result\": [self.metrics.get(\"es-es\", \"\")],\n",
    "            \"de-de result\": [self.metrics.get(\"de-de\", \"\")],\n",
    "            \"zh-zh result\": [self.metrics.get(\"zh-zh\", \"\")],\n",
    "            \"en-es result\": [self.metrics.get(\"en-es\", \"\")],\n",
    "            \"en-de result\": [self.metrics.get(\"en-de\", \"\")],\n",
    "            \"en-zh result\": [self.metrics.get(\"en-zh\", \"\")],\n",
    "            \"loss\": [self.loss],\n",
    "            \"epochs\": [self.epochs],\n",
    "            \"training_time (s)\": [self.training_time],\n",
    "            \"date\": [Timer.get()],\n",
    "            \"notes\": [self.notes]\n",
    "        }\n",
    "\n",
    "    def save(self):\n",
    "        # Tạo thư mục nếu chưa tồn tại\n",
    "        os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "        # Tạo DataFrame từ dict\n",
    "        df_new = pd.DataFrame(self.to_dict())\n",
    "\n",
    "        if os.path.exists(self.file_path):\n",
    "            df_existing = pd.read_csv(self.file_path)\n",
    "            df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "            df_updated.to_csv(self.file_path, index=False)\n",
    "            print(f\"✅ Đã thêm dữ liệu vào file: {self.file_path}\")\n",
    "        else:\n",
    "            df_new.to_csv(self.file_path, index=False)\n",
    "            print(f\"✅ Đã tạo file mới: {self.file_path}\")\n",
    "\n",
    "    def show_log(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            print(f\"\\n📄 Nội dung file log:\")\n",
    "            log_df = utils.read_csv(self.file_path)\n",
    "            print(log_df)\n",
    "        else:\n",
    "            print(\"⚠️ Chưa có file log để hiển thị.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944fdf4",
   "metadata": {
    "papermill": {
     "duration": 0.006528,
     "end_time": "2025-04-24T06:05:47.754322",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.747794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hàm thực thi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b804c",
   "metadata": {
    "papermill": {
     "duration": 0.006569,
     "end_time": "2025-04-24T06:05:47.767527",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.760958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Clone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d610740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:05:47.781761Z",
     "iopub.status.busy": "2025-04-24T06:05:47.781503Z",
     "iopub.status.idle": "2025-04-24T06:06:39.711858Z",
     "shell.execute_reply": "2025-04-24T06:06:39.710939Z"
    },
    "papermill": {
     "duration": 51.939205,
     "end_time": "2025-04-24T06:06:39.713475",
     "exception": false,
     "start_time": "2025-04-24T06:05:47.774270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\r\n",
      "Token is valid (permission: fineGrained).\r\n",
      "The token `kaggle` has been saved to /root/.cache/huggingface/stored_tokens\r\n",
      "Your token has been saved to /root/.cache/huggingface/token\r\n",
      "Login successful.\r\n",
      "The current active token is: `kaggle`\r\n",
      "Cloning into '/kaggle/working/models'...\r\n",
      "remote: Enumerating objects: 76, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (71/71), done.\u001b[K\r\n",
      "remote: Total 76 (delta 21), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\r\n",
      "Unpacking objects: 100% (76/76), 507.19 KiB | 3.76 MiB/s, done.\r\n",
      "Filtering content: 100% (9/9), 1.40 GiB | 184.80 MiB/s, done.\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clone thành công!\n",
      "Stdout: \n",
      "Stderr: Cloning into 'talent_clef'...\n",
      "Updating files:  70% (77/109)\n",
      "Updating files:  71% (78/109)\n",
      "Updating files:  72% (79/109)\n",
      "Updating files:  73% (80/109)\n",
      "Updating files:  74% (81/109)\n",
      "Updating files:  75% (82/109)\n",
      "Updating files:  76% (83/109)\n",
      "Updating files:  77% (84/109)\n",
      "Updating files:  78% (86/109)\n",
      "Updating files:  79% (87/109)\n",
      "Updating files:  80% (88/109)\n",
      "Updating files:  81% (89/109)\n",
      "Updating files:  82% (90/109)\n",
      "Updating files:  83% (91/109)\n",
      "Updating files:  84% (92/109)\n",
      "Updating files:  85% (93/109)\n",
      "Updating files:  86% (94/109)\n",
      "Updating files:  87% (95/109)\n",
      "Updating files:  88% (96/109)\n",
      "Updating files:  89% (98/109)\n",
      "Updating files:  90% (99/109)\n",
      "Updating files:  91% (100/109)\n",
      "Updating files:  92% (101/109)\n",
      "Updating files:  93% (102/109)\n",
      "Updating files:  94% (103/109)\n",
      "Updating files:  95% (104/109)\n",
      "Updating files:  96% (105/109)\n",
      "Updating files:  97% (106/109)\n",
      "Updating files:  98% (107/109)\n",
      "Updating files:  99% (108/109)\n",
      "Updating files: 100% (109/109)\n",
      "Updating files: 100% (109/109), done.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoivinh20789\u001b[0m (\u001b[33mhoivinh20789-uit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'talentclef25_evaluation_script'...\r\n",
      "remote: Enumerating objects: 27, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\r\n",
      "remote: Total 27 (delta 10), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (27/27), 10.10 KiB | 2.02 MiB/s, done.\r\n",
      "Resolving deltas: 100% (10/10), done.\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.2.3)\r\n",
      "Collecting ranx (from -r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading ranx-0.3.20-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.1)\r\n",
      "Requirement already satisfied: numba>=0.54.1 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.60.0)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.67.1)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.13.1)\r\n",
      "Collecting ir-datasets (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading ir_datasets-0.5.10-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (13.9.4)\r\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10.12)\r\n",
      "Collecting lz4 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting cbor2 (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\r\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.2)\r\n",
      "Collecting fastparquet (from ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54.1->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.43.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.17.0)\r\n",
      "Collecting cramjam>=2.3 (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2024.12.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (24.2)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.3)\r\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading inscriptis-2.6.0-py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (5.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.32.3)\r\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\r\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting zlib-state>=0.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting ijson>=3.1.3 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\r\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: pyarrow>=16.1.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (19.0.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.19.1)\r\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.12.2)\r\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.7.5)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.6)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.1.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (1.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2)) (2025.1.31)\r\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->ranx->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 2))\r\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.22.4->pandas->-r /kaggle/working/talentclef25_evaluation_script/requirements.txt (line 1)) (2024.2.0)\r\n",
      "Downloading ranx-0.3.20-py3-none-any.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ir_datasets-0.5.10-py3-none-any.whl (859 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.0/859.0 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading inscriptis-2.6.0-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\r\n",
      "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\r\n",
      "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\r\n",
      "Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\r\n",
      "Building wheels for collected packages: warc3-wet-clueweb09, cbor\r\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18920 sha256=2b8e465bc4d1783b90c34ecdd4545dd0eb5fd135ea2b580505f64028e4cdd409\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\r\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53431 sha256=e02f4ad5d78f49f495979d2101b9a87c6ffa79ab2b7f44242fd8f96410f30cfe\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\r\n",
      "Successfully built warc3-wet-clueweb09 cbor\r\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, lz4, cramjam, cbor2, inscriptis, trec-car-tools, ir-datasets, fastparquet, ranx\r\n",
      "Successfully installed cbor-1.0.0 cbor2-5.6.5 cramjam-2.10.0 fastparquet-2024.11.0 ijson-3.3.0 inscriptis-2.6.0 ir-datasets-0.5.10 lz4-4.4.4 ranx-0.3.20 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9\r\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "huggingface_api = user_secrets.get_secret(\"huggingface\")\n",
    "\n",
    "!huggingface-cli login --token {huggingface_api}\n",
    "!git clone https://huggingface.co/hoivinh20789/talent_clef /kaggle/working/models\n",
    "load_git_workspace_wandb()\n",
    "\n",
    "!git clone https://github.com/TalentCLEF/talentclef25_evaluation_script.git\n",
    "!pip install -r \"/kaggle/working/talentclef25_evaluation_script/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269848c",
   "metadata": {
    "papermill": {
     "duration": 0.009593,
     "end_time": "2025-04-24T06:06:39.733646",
     "exception": false,
     "start_time": "2025-04-24T06:06:39.724053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2ee02ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:06:39.754700Z",
     "iopub.status.busy": "2025-04-24T06:06:39.754393Z",
     "iopub.status.idle": "2025-04-24T06:07:59.482110Z",
     "shell.execute_reply": "2025-04-24T06:07:59.481070Z"
    },
    "papermill": {
     "duration": 79.759348,
     "end_time": "2025-04-24T06:07:59.502774",
     "exception": false,
     "start_time": "2025-04-24T06:06:39.743426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đọc dữ liệu train_org:\n",
      "                       jobtitle  \\\n",
      "0    director of technical arts   \n",
      "0          technical supervisor   \n",
      "0             technical manager   \n",
      "0  head of technical department   \n",
      "0            technical director   \n",
      "\n",
      "                                               skill  label  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "                     jobtitle  \\\n",
      "0  director of technical arts   \n",
      "1  director of technical arts   \n",
      "2  director of technical arts   \n",
      "3  director of technical arts   \n",
      "4  director of technical arts   \n",
      "\n",
      "                                               skill  label  \n",
      "0  Overview: The skills landscape encompasses a r...      0  \n",
      "1  Overview: The performing arts demand a diverse...      0  \n",
      "2  Overview: The essential skills for success inc...      0  \n",
      "3  Overview: The skills listed cover a broad rang...      0  \n",
      "4  Overview: The performing arts encompass a wide...      0  \n",
      "                       jobtitle  \\\n",
      "0    director of technical arts   \n",
      "0          technical supervisor   \n",
      "0             technical manager   \n",
      "0  head of technical department   \n",
      "0            technical director   \n",
      "\n",
      "                                               skill  label  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "0  Overview: The essential skills for performing ...      1  \n",
      "Cột dữ liệu: Index(['jobtitle', 'skill', 'label'], dtype='object')\n",
      "Xuất dữ liệu train sau khi chuẩn bị:\n",
      "Đã xuất dữ liệu ra /kaggle/working/train.csv\n"
     ]
    }
   ],
   "source": [
    "source_file = \"/kaggle/working/talent_clef/data/gen_data/train_data_gen.csv\"\n",
    "neg_pair_file = \"/kaggle/working/talent_clef/data/random_neg_sample/random_neg_example.csv\"\n",
    "preparer = DataPreparer()\n",
    "train_df, train_file = preparer.prepare_train_data(neg_pair_file, source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e52e06a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:07:59.526080Z",
     "iopub.status.busy": "2025-04-24T06:07:59.525674Z",
     "iopub.status.idle": "2025-04-24T08:44:49.020076Z",
     "shell.execute_reply": "2025-04-24T08:44:49.019058Z"
    },
    "papermill": {
     "duration": 9409.50769,
     "end_time": "2025-04-24T08:44:49.021847",
     "exception": false,
     "start_time": "2025-04-24T06:07:59.514157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device sử dụng: cuda\n",
      "Tải mô hình từ đường dẫn cục bộ: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6\n",
      "Mô hình đã được khởi tạo thành công!\n",
      "Khởi tạo dataset:\n",
      "Bắt đầu train: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to \u001b[34m\u001b[4mhttps://wandb.me/wandb-init\u001b[0m.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250424_060849-2ujhik48\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcheckpoints/model\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/hoivinh20789-uit/sentence-transformers\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/hoivinh20789-uit/sentence-transformers/runs/2ujhik48\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29100' max='29100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29100/29100 2:35:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.809000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.713600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.682500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.663700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.649200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.646800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.557800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.557800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.525500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.522600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.521900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.465100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.462900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.453100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.440200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.434900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.434300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.431400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.400600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.398300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.390700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.401500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.402800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.406400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.392300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.400900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aa68f078874205aff3587e0eb2be1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = Dataset.load_train_data(train_file, train_df)\n",
    "dataset = Dataset(train_data)\n",
    "\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model_path = '/kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/epoch6'\n",
    "loss = losses.MultipleNegativesSymmetricRankingLoss\n",
    "detail = \"pos_epoch6_random_neg_pair_epoch4_symetric_loss\"\n",
    "params = {\n",
    "    \"num_epochs\": 4,\n",
    "    \"output_path\": f\"/kaggle/working/models/{model_name}/{detail}\",\n",
    "    \"warmup_steps\": 100,\n",
    "    \"scheduler\":'WarmupCosine',  # ← thay đổi ở đây\n",
    "    \"optimizer_params\":{'lr': 5e-5},  # ← tăng nhẹ learning rate\n",
    "}\n",
    "\n",
    "trainer = Trainer(model_name, model_path)\n",
    "model, model_path = trainer.train(dataset.data, loss, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066837e7",
   "metadata": {
    "papermill": {
     "duration": 0.010669,
     "end_time": "2025-04-24T08:44:49.044239",
     "exception": false,
     "start_time": "2025-04-24T08:44:49.033570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Push Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2df3eaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:44:49.066992Z",
     "iopub.status.busy": "2025-04-24T08:44:49.066713Z",
     "iopub.status.idle": "2025-04-24T08:44:49.071433Z",
     "shell.execute_reply": "2025-04-24T08:44:49.070495Z"
    },
    "papermill": {
     "duration": 0.017517,
     "end_time": "2025-04-24T08:44:49.072692",
     "exception": false,
     "start_time": "2025-04-24T08:44:49.055175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/pos_epoch6_random_neg_pair_epoch4_symetric_loss\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "270f9e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:44:49.095872Z",
     "iopub.status.busy": "2025-04-24T08:44:49.095612Z",
     "iopub.status.idle": "2025-04-24T08:45:13.429884Z",
     "shell.execute_reply": "2025-04-24T08:45:13.429010Z"
    },
    "papermill": {
     "duration": 24.347463,
     "end_time": "2025-04-24T08:45:13.431234",
     "exception": false,
     "start_time": "2025-04-24T08:44:49.083771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89029b1f34be458c883e525a6bf2431d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/hoivinh20789/talent_clef/commit/2363e702064cebfe7f00a86c46d98d5d33db2fea', commit_message='Upload model version 1', commit_description='', oid='2363e702064cebfe7f00a86c46d98d5d33db2fea', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hoivinh20789/talent_clef', endpoint='https://huggingface.co', repo_type='model', repo_id='hoivinh20789/talent_clef'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id = \"hoivinh20789/talent_clef\"  # Đường dẫn tới repo của bạn trên Hugging Face\n",
    "folder_path = params['output_path']  # Đường dẫn tới thư mục chứa mô hình của bạn\n",
    "target_folder = f\"{model_name}/{detail}\"  # Thư mục con mà bạn muốn đẩy mô hình vào trong repo\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Đẩy model vào thư mục 'model' trong repository\n",
    "api.upload_folder(\n",
    "    repo_id=repo_id,\n",
    "    folder_path=folder_path,  # Thư mục chứa các file model\n",
    "    path_in_repo=target_folder,  # Thư mục con 'model' trong repo\n",
    "    commit_message=\"Upload model version 1\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3de7de",
   "metadata": {
    "papermill": {
     "duration": 0.010859,
     "end_time": "2025-04-24T08:45:13.453892",
     "exception": false,
     "start_time": "2025-04-24T08:45:13.443033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. RetrievalApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "013debf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:45:13.476724Z",
     "iopub.status.busy": "2025-04-24T08:45:13.476475Z",
     "iopub.status.idle": "2025-04-24T08:45:13.481070Z",
     "shell.execute_reply": "2025-04-24T08:45:13.480392Z"
    },
    "papermill": {
     "duration": 0.017564,
     "end_time": "2025-04-24T08:45:13.482371",
     "exception": false,
     "start_time": "2025-04-24T08:45:13.464807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/pos_epoch6_random_neg_pair_epoch4_symetric_loss\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b3597fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:45:13.505859Z",
     "iopub.status.busy": "2025-04-24T08:45:13.505606Z",
     "iopub.status.idle": "2025-04-24T08:46:17.833207Z",
     "shell.execute_reply": "2025-04-24T08:46:17.832277Z"
    },
    "papermill": {
     "duration": 64.355247,
     "end_time": "2025-04-24T08:46:17.849071",
     "exception": false,
     "start_time": "2025-04-24T08:45:13.493824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device sử dụng: cuda\n",
      "Tải mô hình từ đường dẫn cục bộ: /kaggle/working/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/pos_epoch6_random_neg_pair_epoch4_symetric_loss\n",
      "Mô hình đã được khởi tạo thành công!\n",
      "Load mô hình.....\n",
      "Chuẩn bị data: ......\n",
      "Chuẩn bị data en-en:.....\n",
      "Đọc dữ liệu inference:\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements thành công\n",
      "   c_id                          jobtitle\n",
      "0     1                recording engineer\n",
      "1     2              director of taxation\n",
      "2     3  technical support representative\n",
      "3     4                        hr manager\n",
      "4     5           computer graphic artist\n",
      "Đọc tsv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/data/TaskA/validation/english/queries thành công\n",
      "   q_id             jobtitle\n",
      "0     1                nanny\n",
      "1     2    food technologist\n",
      "2     3   broadcast engineer\n",
      "3     4  automation engineer\n",
      "4     5         veterinarian\n",
      "Xuất dữ liệu inference:\n",
      "Đã xuất dữ liệu ra /kaggle/working/corpus_en-en.csv\n",
      "Đã xuất dữ liệu ra /kaggle/working/queries_en-en.csv\n",
      "Bắt đầu inference.....\n",
      "Load data en-en:.....\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/corpus_en-en.csv thành công\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/queries_en-en.csv thành công\n",
      "Inference en-en:.....\n",
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1359f249ddbd4e9aa1be86b374f8f6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu chạy embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94881ed34b384d709cb2c9448c2a9d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu dự đoán:.....\n",
      "Dự đoán en-en:.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 105/105 [00:07<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu xuất file:....\n",
      "Đã xuất file TREC ra /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22/run_en-en.trec\n",
      "Đang nén thư mục /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22 thành /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22.zip...\n",
      "File zip đã được tạo: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22.zip\n",
      "Bắt đầu đánh giá:.....\n",
      "Đánh giá en-en:.....\n",
      "Received parameters:\n",
      "  qrels: /kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\n",
      "  run: /kaggle/working/talent_clef/predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22/run_en-en.trec\n",
      "Loading qrels...\n",
      "Loading run...\n",
      "Running evaluation...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "map: 0.5308\n",
      "mrr: 0.8593\n",
      "ndcg: 0.7977\n",
      "precision@5: 0.6914\n",
      "precision@10: 0.5943\n",
      "precision@100: 0.1745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"corpus\": {\n",
    "        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/corpus_elements\"\n",
    "        # \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/corpus_elements\",\n",
    "        # \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/corpus_elements\",\n",
    "        # \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/corpus_elements\"\n",
    "    },\n",
    "    \n",
    "    \"queries\":{\n",
    "        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/queries\"\n",
    "        # \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/queries\",\n",
    "        # \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/queries\",\n",
    "        # \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/queries\"\n",
    "    },\n",
    "    \n",
    "    \"qrels\": {\n",
    "        \"en-en\": \"/kaggle/working/talent_clef/data/TaskA/validation/english/qrels.tsv\"\n",
    "    #     \"de-de\": \"/kaggle/working/talent_clef/data/TaskA/validation/german/qrels.tsv\",\n",
    "    #     \"es-es\": \"/kaggle/working/talent_clef/data/TaskA/validation/spanish/qrels.tsv\",\n",
    "    #     \"zh-zh\": \"/kaggle/working/talent_clef/data/TaskA/validation/chinese/qrels.tsv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "app = RetrievalApp(model_name, model_path)\n",
    "ratings = app(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "363a793b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:46:17.878982Z",
     "iopub.status.busy": "2025-04-24T08:46:17.878706Z",
     "iopub.status.idle": "2025-04-24T08:46:17.883385Z",
     "shell.execute_reply": "2025-04-24T08:46:17.882555Z"
    },
    "papermill": {
     "duration": 0.020858,
     "end_time": "2025-04-24T08:46:17.884544",
     "exception": false,
     "start_time": "2025-04-24T08:46:17.863686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en-en': {'map': 0.5308,\n",
       "  'mrr': 0.8593,\n",
       "  'ndcg': 0.7977,\n",
       "  'precision@5': 0.6914,\n",
       "  'precision@10': 0.5943,\n",
       "  'precision@100': 0.1745}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48798bd",
   "metadata": {
    "papermill": {
     "duration": 0.01413,
     "end_time": "2025-04-24T08:46:17.912947",
     "exception": false,
     "start_time": "2025-04-24T08:46:17.898817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Log Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6081603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:46:17.942353Z",
     "iopub.status.busy": "2025-04-24T08:46:17.942058Z",
     "iopub.status.idle": "2025-04-24T08:46:17.962638Z",
     "shell.execute_reply": "2025-04-24T08:46:17.961690Z"
    },
    "papermill": {
     "duration": 0.036912,
     "end_time": "2025-04-24T08:46:17.964037",
     "exception": false,
     "start_time": "2025-04-24T08:46:17.927125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã tạo file mới: /kaggle/working/talent_clef/results/model_results.csv\n",
      "\n",
      "📄 Nội dung file log:\n",
      "Đọc csv file:\n",
      "Đọc dữ liệu từ /kaggle/working/talent_clef/results/model_results.csv thành công\n",
      "                                          model_name  Avg result  \\\n",
      "0  sentence-transformers/paraphrase-multilingual-...      0.5308   \n",
      "\n",
      "                                        en-en result  es-es result  \\\n",
      "0  {'map': 0.5308, 'mrr': 0.8593, 'ndcg': 0.7977,...           NaN   \n",
      "\n",
      "   de-de result  zh-zh result  en-es result  en-de result  en-zh result  loss  \\\n",
      "0           NaN           NaN           NaN           NaN           NaN   NaN   \n",
      "\n",
      "   epochs  training_time (s)            date  \\\n",
      "0     NaN                NaN  04-24_15-46-17   \n",
      "\n",
      "                                            notes  \n",
      "0  thêm negative pair và finetune tiếp từ epoch 5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "logger = ModelLogger(\n",
    "    model_name=model_name,\n",
    "    loss_function=None,\n",
    "    num_epochs=None,\n",
    "    metrics=ratings,\n",
    "    notes=\"thêm negative pair và finetune tiếp từ epoch 5\"\n",
    ")\n",
    "\n",
    "logger.save()\n",
    "logger.show_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d91a7f",
   "metadata": {
    "papermill": {
     "duration": 0.01419,
     "end_time": "2025-04-24T08:46:17.993309",
     "exception": false,
     "start_time": "2025-04-24T08:46:17.979119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Git Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffe997ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:46:18.023341Z",
     "iopub.status.busy": "2025-04-24T08:46:18.023010Z",
     "iopub.status.idle": "2025-04-24T08:46:18.029017Z",
     "shell.execute_reply": "2025-04-24T08:46:18.028251Z"
    },
    "papermill": {
     "duration": 0.022424,
     "end_time": "2025-04-24T08:46:18.030180",
     "exception": false,
     "start_time": "2025-04-24T08:46:18.007756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/talent_clef\n"
     ]
    }
   ],
   "source": [
    "cd talent_clef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5e990c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:46:18.060294Z",
     "iopub.status.busy": "2025-04-24T08:46:18.060010Z",
     "iopub.status.idle": "2025-04-24T08:46:18.063566Z",
     "shell.execute_reply": "2025-04-24T08:46:18.062754Z"
    },
    "papermill": {
     "duration": 0.020036,
     "end_time": "2025-04-24T08:46:18.064838",
     "exception": false,
     "start_time": "2025-04-24T08:46:18.044802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brand_name = model_name + \"/\" +Timer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4533766e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:46:18.094702Z",
     "iopub.status.busy": "2025-04-24T08:46:18.094489Z",
     "iopub.status.idle": "2025-04-24T08:46:18.098566Z",
     "shell.execute_reply": "2025-04-24T08:46:18.097928Z"
    },
    "papermill": {
     "duration": 0.020366,
     "end_time": "2025-04-24T08:46:18.099715",
     "exception": false,
     "start_time": "2025-04-24T08:46:18.079349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "527eef66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:46:18.129573Z",
     "iopub.status.busy": "2025-04-24T08:46:18.129318Z",
     "iopub.status.idle": "2025-04-24T08:46:23.447300Z",
     "shell.execute_reply": "2025-04-24T08:46:23.446196Z"
    },
    "papermill": {
     "duration": 5.334529,
     "end_time": "2025-04-24T08:46:23.448864",
     "exception": false,
     "start_time": "2025-04-24T08:46:18.114335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18'\r\n",
      "On branch sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\t\u001b[31mpredict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22.zip\u001b[m\r\n",
      "\t\u001b[31mpredict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22/\u001b[m\r\n",
      "\t\u001b[31mresults/\u001b[m\r\n",
      "\r\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\r\n",
      "[sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18 9c460cb] updated\r\n",
      " 3 files changed, 274997 insertions(+)\r\n",
      " create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22.zip\r\n",
      " create mode 100644 predict/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-45-22/run_en-en.trec\r\n",
      " create mode 100644 results/model_results.csv\r\n",
      "Enumerating objects: 14, done.\r\n",
      "Counting objects: 100% (14/14), done.\r\n",
      "Delta compression using up to 4 threads\r\n",
      "Compressing objects: 100% (8/8), done.\r\n",
      "Writing objects: 100% (10/10), 7.62 MiB | 7.04 MiB/s, done.\r\n",
      "Total 10 (delta 4), reused 0 (delta 0), pack-reused 0\r\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\r\n",
      "remote: \r\n",
      "remote: Create a pull request for 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18' on GitHub by visiting:\u001b[K\r\n",
      "remote:      https://github.com/hoivd/talent_clef/pull/new/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18\u001b[K\r\n",
      "remote: \r\n",
      "To https://github.com/hoivd/talent_clef\r\n",
      " * [new branch]      sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18 -> sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18\r\n",
      "Branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18' set up to track remote branch 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/04-24_15-46-18' from 'origin'.\r\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"hoivd79@gmail.com\"\n",
    "!git config --global user.name \"Dang Vinh Hoi\"\n",
    "!git checkout -b {brand_name}      # Tạo và chuyển sang nhánh dev\n",
    "!git status\n",
    "!git add .\n",
    "!git commit -m \"updated\"\n",
    "!git push -u origin {brand_name}    # Push lần đầu, thiết lập tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3739f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T08:46:23.480869Z",
     "iopub.status.busy": "2025-04-24T08:46:23.480550Z",
     "iopub.status.idle": "2025-04-24T08:46:23.486922Z",
     "shell.execute_reply": "2025-04-24T08:46:23.486154Z"
    },
    "papermill": {
     "duration": 0.023613,
     "end_time": "2025-04-24T08:46:23.488231",
     "exception": false,
     "start_time": "2025-04-24T08:46:23.464618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9671.111109,
   "end_time": "2025-04-24T08:46:27.382308",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-24T06:05:16.271199",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04319f14efc340eb8634b20695eafd49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b4b42679b278428783f68de1f1c3bb31",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e1ac7419ae44f418fe5b0119632e771",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "0c8482773642410f921913d8e3524a27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1359f249ddbd4e9aa1be86b374f8f6cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_91942d3fe36840bfb27255dbfb4496ae",
        "IPY_MODEL_32e6d3a93b7149e0912e4441e4505b71",
        "IPY_MODEL_a4b5a25352c0402aaaac0f4e88a9f683"
       ],
       "layout": "IPY_MODEL_6427a47b260b4584be1a289355d477d7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "15e42737f55b4dffbf0fad16d1b40932": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "18cea8db6e8b4acdbbcae6fe4a52e44b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28e227033b1348158a5c7f49cadbacff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c8482773642410f921913d8e3524a27",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_69573fb2c72d421286b50fe8e4799238",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "32e6d3a93b7149e0912e4441e4505b71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18cea8db6e8b4acdbbcae6fe4a52e44b",
       "max": 82.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ab54f3b5b1414b2b9dc0836362d31b86",
       "tabbable": null,
       "tooltip": null,
       "value": 82.0
      }
     },
     "353d6b73386c40acb2757fb37296090a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3aea17f66b2745f1aaa941140e257bf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "3e1ac7419ae44f418fe5b0119632e771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "43aa68f078874205aff3587e0eb2be1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_afb5125c82ba453d9ccc9da3a36ef37d",
        "IPY_MODEL_04319f14efc340eb8634b20695eafd49",
        "IPY_MODEL_e3a3df0717a24a87bc1251492aa1ac74"
       ],
       "layout": "IPY_MODEL_3aea17f66b2745f1aaa941140e257bf5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "479780c3ea424be7b5c680fe81cc1aa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_96cdcaeeab3c4264a5cdce26f01dcb5e",
       "placeholder": "​",
       "style": "IPY_MODEL_b136031460214c34a68fd682906b3a20",
       "tabbable": null,
       "tooltip": null,
       "value": " 471M/471M [00:11&lt;00:00, 50.8MB/s]"
      }
     },
     "4d7e0a702c134d74baeed36cc55327bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e7b4d5d2b524e458c354fc1e6a65534": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6427a47b260b4584be1a289355d477d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68f27bcc285d436881ef6fd9fa067f13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69573fb2c72d421286b50fe8e4799238": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6982121efc6349309e01c1bbdcffde86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c6cac1d1ad24d3da0986921837a4e03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f4c0d8d3c794eca9c607e7d7b032abf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fb9be08bfb4c4306aa8d49fdab5bef65",
       "placeholder": "​",
       "style": "IPY_MODEL_353d6b73386c40acb2757fb37296090a",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [00:00&lt;00:00, 76.02it/s]"
      }
     },
     "74918fad91fa4b35a50a7faa87d6b8b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "795cb5084e0f46e9ae55575015c3081e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89029b1f34be458c883e525a6bf2431d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dc14ad7915d34ed19c31d802c541542e",
        "IPY_MODEL_f679a4e6af884a5dac0313af984a9437",
        "IPY_MODEL_479780c3ea424be7b5c680fe81cc1aa5"
       ],
       "layout": "IPY_MODEL_4d7e0a702c134d74baeed36cc55327bf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "91942d3fe36840bfb27255dbfb4496ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ae4bc730e26c482b856a43dbadd4376a",
       "placeholder": "​",
       "style": "IPY_MODEL_74918fad91fa4b35a50a7faa87d6b8b7",
       "tabbable": null,
       "tooltip": null,
       "value": "Batches: 100%"
      }
     },
     "94881ed34b384d709cb2c9448c2a9d39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_af1ebce2f3284365b722328d79b8e896",
        "IPY_MODEL_28e227033b1348158a5c7f49cadbacff",
        "IPY_MODEL_6f4c0d8d3c794eca9c607e7d7b032abf"
       ],
       "layout": "IPY_MODEL_795cb5084e0f46e9ae55575015c3081e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "96cdcaeeab3c4264a5cdce26f01dcb5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4b5a25352c0402aaaac0f4e88a9f683": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6c6cac1d1ad24d3da0986921837a4e03",
       "placeholder": "​",
       "style": "IPY_MODEL_f4e0506f5b5e44f9930e223eccea2f14",
       "tabbable": null,
       "tooltip": null,
       "value": " 82/82 [00:00&lt;00:00, 103.95it/s]"
      }
     },
     "a6edc09d2f4049ff8b1c9b0cc4e2fd27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab54f3b5b1414b2b9dc0836362d31b86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ad6be13eab3c436796470be032382c2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ae4bc730e26c482b856a43dbadd4376a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af1ebce2f3284365b722328d79b8e896": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ed6cc1a11715472ab1410b826b435f4a",
       "placeholder": "​",
       "style": "IPY_MODEL_15e42737f55b4dffbf0fad16d1b40932",
       "tabbable": null,
       "tooltip": null,
       "value": "Batches: 100%"
      }
     },
     "afb5125c82ba453d9ccc9da3a36ef37d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6982121efc6349309e01c1bbdcffde86",
       "placeholder": "​",
       "style": "IPY_MODEL_c3b9ca1adde646e0b74561f9a0e218b2",
       "tabbable": null,
       "tooltip": null,
       "value": "Computing widget examples:   0%"
      }
     },
     "b136031460214c34a68fd682906b3a20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b4b42679b278428783f68de1f1c3bb31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3b9ca1adde646e0b74561f9a0e218b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d1319607c3714bd6b35bbb00b06936b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc14ad7915d34ed19c31d802c541542e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68f27bcc285d436881ef6fd9fa067f13",
       "placeholder": "​",
       "style": "IPY_MODEL_a6edc09d2f4049ff8b1c9b0cc4e2fd27",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "e305531290764456891aafb48eb7b94c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3a3df0717a24a87bc1251492aa1ac74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e305531290764456891aafb48eb7b94c",
       "placeholder": "​",
       "style": "IPY_MODEL_ad6be13eab3c436796470be032382c2b",
       "tabbable": null,
       "tooltip": null,
       "value": " 0/1 [00:00&lt;?, ?example/s]"
      }
     },
     "ed6cc1a11715472ab1410b826b435f4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4e0506f5b5e44f9930e223eccea2f14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f679a4e6af884a5dac0313af984a9437": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d1319607c3714bd6b35bbb00b06936b3",
       "max": 470637416.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5e7b4d5d2b524e458c354fc1e6a65534",
       "tabbable": null,
       "tooltip": null,
       "value": 470637416.0
      }
     },
     "fb9be08bfb4c4306aa8d49fdab5bef65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
